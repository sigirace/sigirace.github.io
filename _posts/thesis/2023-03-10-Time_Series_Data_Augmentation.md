---
layout: single
title:  'Time Series Data Augmentation for Neural Networks by Time Warping with a Discriminative Teacher'
toc: true
categories: [Thesis]
tags: [Data Augmentation, Timeseires]

---

ë³¸ ê²Œì‹œë¬¼ì€ ì‹œê³„ì—´ ë°ì´í„°ì˜ ì¦ê°•ë²•ì— ëŒ€í•´ [í•´ë‹¹ ë…¼ë¬¸](https://paperswithcode.com/paper/time-series-data-augmentation-for-neural)ì„ ì½ê³  ì •ë¦¬í•˜ëŠ” ê¸€ì´ë‹¤.
{: .notice}

## 0. Abstract

Neural networksëŠ” íŒ¨í„´ ì¸ì‹ì—ì„œ ê°•ë ¥í•œ ë„êµ¬ê°€ ë˜ì—ˆìœ¼ë©° ì´ëŠ” large datasetì˜ ì¼ë°˜í™” ë•ë¶„ì´ë‹¤. í•˜ì§€ë§Œ ë‹¤ë¥¸ ë„ë©”ì¸ë“¤ê³¼ ë‹¬ë¦¬ ì‹œê³„ì—´ ë¶„ë¥˜ ë°ì´í„° ì„¸íŠ¸ëŠ” ëŒ€ë¶€ë¶„ ìŠ¤ì¼€ì¼ì´ ì‘ë‹¤. ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, í•´ë‹¹ ë…¼ë¬¸ì€ guided warpingì´ë¼ê³  ë¶ˆë¦¬ëŠ” ë°ì´í„° ì¦ê°•ë²•ì„ ì œì•ˆí•œë‹¤. ë§ì€ ë°ì´í„° ì¦ê°• ë°©ë²•ì´ randomí•œ ë³€í™˜ì— ê¸°ì´ˆë¥¼ ë‘ê³  ìˆëŠ” ë°˜ë©´, guided warpingì€ Dynamic Time Warpingì˜ ìš”ì†Œì˜ ì •ë ¬ íŠ¹ì„±ê³¼ ê·¸ ëª¨ì–‘ì„ í™œìš©í•˜ì—¬ ê²°ì •ì ì¸ ìƒ˜í”Œì˜ íŒ¨í„´ì„ warping í•œë‹¤.

### ğŸ“Œ Warping?

> warpingì˜ ì‚¬ì „ì  ì˜ë¯¸ëŠ” íœ˜ì–´ì§€ê²Œ í•˜ë‹¤, ì™œê³¡í•˜ë‹¤ë¼ëŠ” ëœ»ì„ ê°€ì§€ê³  ìˆë‹¤. ì´ë¯¸ì§€, ì˜ìƒì—ì„œì˜ warpingì€ xì¶•, yì¶•, íšŒì „ scale ë“±ì„ ì´ìš©í•˜ì—¬, ë³´ì •ì´ë‚˜ ì°Œê·¸ëŸ¬ì§„ ì´ë¯¸ì§€ë¥¼ ì •ê·œí™” í•˜ê¸° ìœ„í•œ ì²˜ë¦¬ ê¸°ë²•ì„ ì˜ë¯¸í•œë‹¤.

ì´ëŸ¬í•œ ë°©ì‹ìœ¼ë¡œ, time seriesëŠ” ê¸°ì¤€ì´ ë˜ëŠ” íŒ¨í„´ì˜ ì‹œê°„ ë‹¨ê³„ì™€ ì¼ì¹˜í•˜ë„ë¡ ìƒ˜í”Œ íŒ¨í„´ì„ warpingí•˜ì—¬ í˜¼í•©ë˜ì–´ êµ¬ì„±ëœë‹¤. ë”í•˜ì—¬, ë³¸ ë…¼ë¬¸ì€ guided warpingì— ëŒ€í•œ ì§ì ‘ì ì¸ ì°¸ì¡°ì ì—­í• ì„ ì œê³µí•˜ê¸° ìœ„í•´ discriminative teacherë¥¼ ì†Œê°œí•œë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ CNNê³¼ RNNì„ ì‚¬ìš©í•˜ì—¬ 2015ë…„ UCR UCR ì‹œê³„ì—´ ì•„ì¹´ì´ë¸Œì˜ 85ê°œ ë°ì´í„° ì„¸íŠ¸ ëª¨ë‘ì— ëŒ€í•œ ë°©ë²•ì„ í‰ê°€í•œë‹¤. êµ¬í˜„ëœ ì½”ë“œëŠ” [ì—¬ê¸°]( https://github.com/uchidalab/time )ì—ì„œ ì°¾ì„ ìˆ˜ ìˆë‹¤.

### ğŸ“Œ discriminative teacher?

> Dataì— ëŒ€í•œ Labelì„ í†µí•´ í•™ìŠµì‹œí‚¨ë‹¤ëŠ” ì˜ë¯¸ë¡œ, [í•´ë‹¹ í¬ìŠ¤íŠ¸](https://sigirace.github.io/knowledge/discriminative_generative/)ë¥¼ í†µí•´ discriminativeì˜ ì˜ë¯¸ë¥¼ í™•ì¸ í•  ìˆ˜ ìˆë‹¤.



## 1. Introduction

ë°ì´í„°ì˜ ì–‘ì„ ëŠ˜ë¦¬ë©´ ì¼ë°˜í™”ì— ë„ì›€ì´ ë˜ê³ , ê²°ê³¼ì ìœ¼ë¡œ ë§ì€ ê¸°ê³„ í•™ìŠµ ëª¨ë¸ì˜ ì •í™•ì„±ì— ë„ì›€ì´ ëœë‹¤ëŠ” ê²ƒì€ ì˜ ì•Œë ¤ì ¸ ìˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ë¯¸ì§€ ë„ë©”ì¸ê³¼ ë‹¬ë¦¬ ì‹œê³„ì—´ ë°ì´í„° ì„¸íŠ¸ëŠ” ë¹„êµì  ì‘ì€ ë°ì´í„°ì…‹ì„ êµ¬ì„±í•˜ëŠ” ê²½í–¥ì´ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê°€ì¥ ë§ì´



In fact, it is well-known that increasing the amount ofdata helps with generalization and, in turn, the accuracy ofmany machine learning models [5]â€“[7].However, unlike the image domain, time series datasets tendto be tiny in comparison.

For example, one of the most usedsources of time series classification datasets, the University ofCalifornia Riverside (UCR) Time Series Archive [8], contains85 time series datasets but only 10 have more than 1,000training samples and the largest, ElectricDevices, only has8,926.

By comparison, the popular image datasets, ImageNetLarge Scale Visual Recognition Challenge (ILSVRC) [9],MNIST [10], and CIFAR [11], have 1.2 million, 60,000, and50,000 training patterns respectively.

Thus, in order to use thefull potential of modern machine learning methods, there is aneed for time series classification data.



ì‹¤ì œë¡œ, ë°ì´í„°ì˜ ì–‘ì„ ëŠ˜ë¦¬ë©´ ì¼ë°˜í™”ì— ë„ì›€ì´ ë˜ê³ , ê²°ê³¼ì ìœ¼ë¡œ ë§ì€ ê¸°ê³„ í•™ìŠµ ëª¨ë¸[5]â€“[7]ì˜ ì •í™•ì„±ì— ë„ì›€ì´ ëœë‹¤ëŠ” ê²ƒì€ ì˜ ì•Œë ¤ì ¸ ìˆë‹¤.ê·¸ëŸ¬ë‚˜ ì´ë¯¸ì§€ ë„ë©”ì¸ê³¼ ë‹¬ë¦¬ ì‹œê³„ì—´ ë°ì´í„° ì„¸íŠ¸ëŠ” ë¹„êµì  ì‘ì€ ê²½í–¥ì´ ìˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´, ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ì‹œê³„ì—´ ë¶„ë¥˜ ë°ì´í„° ì„¸íŠ¸ì˜ ì†ŒìŠ¤ ì¤‘ í•˜ë‚˜ì¸ ìº˜ë¦¬í¬ë‹ˆì•„ ëŒ€í•™êµ ë¦¬ë²„ì‚¬ì´ë“œ(UCR) ì‹œê³„ì—´ ì•„ì¹´ì´ë¸Œ[8]ëŠ” 85ê°œì˜ ì‹œê³„ì—´ ë°ì´í„° ì„¸íŠ¸ë¥¼ í¬í•¨í•˜ê³  ìˆì§€ë§Œ 1,000ê°œ ì´ìƒì˜ êµìœ¡ ìƒ˜í”Œì„ ë³´ìœ í•œ ê²ƒì€ 10ê°œë¿ì´ê³  ê°€ì¥ í° Electric DevicesëŠ” 8,926ê°œë§Œ ìˆë‹¤.

ì´ì— ë¹„í•´ ì¸ê¸° ìˆëŠ” ì´ë¯¸ì§€ ë°ì´í„° ì„¸íŠ¸ì¸ ImageNet Large Scale Visual Recognition Challenge(ILSVRC)[9], MNIST[10] ë° CIFAR[11]ëŠ” ê°ê° 120ë§Œ, 60,000, 50,000ê°œì˜ í›ˆë ¨ íŒ¨í„´ì„ ê°€ì§€ê³  ìˆë‹¤.

ë”°ë¼ì„œ í˜„ëŒ€ ê¸°ê³„ í•™ìŠµ ë°©ë²•ì˜ ì ì¬ë ¥ì„ ìµœëŒ€í•œ í™œìš©í•˜ê¸° ìœ„í•´ì„œëŠ” ì‹œê³„ì—´ ë¶„ë¥˜ ë°ì´í„°ê°€ í•„ìš”í•˜ë‹¤.
