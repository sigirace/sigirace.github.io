---
layout: single
title:  'ADP ì‹¤ê¸° ì—°ìŠµë¬¸ì œ (6)'
toc: true
categories: [ADP]
tags: [Missing Value, Outlier, Over Sampling, SMOTE, Sign Test, Chisquare Test, ACF]


---

ë³¸ ê²Œì‹œë¬¼ì€ ADP ì‹¤ê¸°ì˜ 23íšŒì°¨ ë¬¸ì œ í’€ì´ì— ëŒ€í•œ ê²ƒì´ë‹¤.
{: .notice}

# ë¨¸ì‹ ëŸ¬ë‹

## 1. ì˜¨, ìŠµ, ì¡°ë„, CO2 ë†ë„ì— ë”°ë¥¸ ê°ì‹¤ì˜ ì‚¬ìš© ìœ ë¬´ íŒë³„

### 1.1 ë°ì´í„° EDA ìˆ˜í–‰ í›„ ì˜ë¯¸ìˆëŠ” íƒìƒ‰

â˜€ï¸ **ë°ì´í„° ê°œìš”**

````python
import pandas as pd
import numpy as np
df =pd.read_csv('https://raw.githubusercontent.com/Datamanim/datarepo/main/adp/23/problem1.csv')
df.head()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice23/1.png?raw=true" width="900" height="150"></p>

````python
df_desc = df.describe()
df_desc
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice23/2.png?raw=true" width="900" height="230"></p>

````python
pd.DataFrame(df_desc.loc['std',:]).sort_values(by=['std'], ascending=False)
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice23/3.png?raw=true" width="300" height="200"></p>

````python
df.info()
````

````
Data columns (total 7 columns):
 #   Column         Non-Null Count  Dtype  
---  ------         --------------  -----  
 0   date           17910 non-null  object 
 1   Temperature    17910 non-null  float64
 2   Humidity       17910 non-null  float64
 3   Light          17910 non-null  float64
 4   CO2            17889 non-null  float64
 5   HumidityRatio  17910 non-null  float64
 6   Occupancy      17910 non-null  int64  
dtypes: float64(5), int64(1), object(1)
````

ğŸ“ **ë°ì´í„° íƒìƒ‰ ê²°ê³¼**

1. target: Occupancy
2. missing value: CO2
3. outlier: CO2, Light ë‘ ë³€ìˆ˜ì˜ í¸ì°¨ê°€ í° ê²ƒìœ¼ë¡œ ë³´ì•„ outlierê°€ ì¡´ì¬í•  ìˆ˜ ìˆìŒ
4. scaling: ì„œë¡œê°„ì˜ ë°ì´í„° ë²”ì£¼ê°€ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— ìŠ¤ì¼€ì¼ë§ ê³ ë ¤
5. feature type: ëª¨ë‘ float typeì´ë©° targetì¸ Occupancy categorical type
6. feature eng: date ë³€ìˆ˜ë¥¼ ìƒˆë¡œìš´ ë³€ìˆ˜ë¡œ í™œìš©í•˜ì—¬ ìš”ì¼ì„ ì¶”ê°€í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ìŒ

â˜€ï¸ **ë‚ ì§œ ìš”ì¼ ë³€í™˜**

````python
from datetime import datetime as dt

df['day'] = pd.to_datetime(df['date'], format='%Y-%m-%d')
df['weekday'] = df.apply(lambda x: dt.weekday(x['day']), axis=1)
df['is_weekend'] = df['weekday'].apply(lambda x: 1 if x >= 5 else 0)
df.drop(columns=['day', 'date'], inplace=True)
````

â˜€ï¸ **ë°ì´í„° ì‹œê°í™”**

````
categorical_columns = ['Occupancy', 'weekday', 'is_weekend']
numerical_columns = ['Temperature', 'Humidity', 'Light', 'CO2', 'HumidityRatio']
````

ğŸ‘€ **ìˆ˜ì¹˜í˜•-íˆìŠ¤í† ê·¸ë¨**

````python
import seaborn as sns
import matplotlib.pyplot as plt

fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(15, 3))

for i, column in enumerate(numerical_columns):
    ax = axes[i]

    df[column].plot(kind='hist', bins=20, ax=ax, color='skyblue', edgecolor='black')
    ax.set_title(f'Histogram of {column}')
    ax.set_xlabel(column)
    ax.set_ylabel('Frequency')

plt.tight_layout()
plt.show()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice23/4.png?raw=true" width="900" height="200"></p>

ğŸ‘€ **ìˆ˜ì¹˜í˜•-ë°•ìŠ¤í”Œë¡¯**

````python
fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(16, 2))

for i, column in enumerate(numerical_columns):

    ax = axes[i]
    sns.boxplot(x=df[column], ax=ax, color='skyblue')
    ax.set_title(f'Box plot of {column}')
    ax.set_xlabel(column)
    ax.set_ylabel('Frequency')

plt.tight_layout()
plt.show()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice23/5.png?raw=true" width="900" height="200"></p>

ğŸ‘€ **ë²”ì£¼í˜•-ë§‰ëŒ€ê·¸ë˜í”„**

````python
fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 3))

for i, column in enumerate(categorical_columns):

    df[column].value_counts().sort_index().plot(kind='bar', ax=axes[i], color='skyblue')
    axes[i].set_title(f'Bar Plot of {column}')
    axes[i].set_xlabel(column)
    axes[i].set_ylabel('Frequency')

plt.tight_layout()
plt.show()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice23/6.png?raw=true" width="500" height="200"></p>

ğŸ‘€ **ê·¸ë£¹ë³„ ë°ì´í„°**

- classification ë¬¸ì œì´ê¸° ë•Œë¬¸ì— ê·¸ë£¹ë³„ë¡œ ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ì—¬ íŒŒì•…

````python
group_class = df.groupby('Occupancy').mean()
group_class
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice23/7.png?raw=true" width="900" height="150"></p>

````python
fig, axes = plt.subplots(1, 5, figsize=(15, 3))

columns = group_class.columns.difference(['is_weekend', 'weekday']).to_list()

for i, column in enumerate(columns):
    ax = axes[i]
    sns.barplot(x=group_class.index, y=column, data=group_class, ax=ax)
    ax.set_title(f'Average {column}')
    ax.set_xlabel("Occupancy")
    ax.set_ylabel(f'Average {column}')

plt.tight_layout()
plt.show()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice23/8.png?raw=true" width="900" height="200"></p>

````python
group_counts = df.groupby(['is_weekend', 'Occupancy']).size().unstack(fill_value=0)

# íŒŒì´ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
fig, axes = plt.subplots(1, len(group_counts), figsize=(15, 4))

for i, (is_weekend, counts) in enumerate(group_counts.iterrows()):
    ax = axes[i]
    counts.plot(kind='pie', autopct='%1.1f%%', ax=ax)
    ax.set_title(f'is_weekend = {is_weekend}')
    ax.set_ylabel('')
    ax.legend(title='Occupancy', labels=counts.index)

plt.tight_layout()
plt.show()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice23/9.png?raw=true" width="900" height="250"></p>

````python
group_counts = df.groupby(['Occupancy', 'weekday']).size().unstack(fill_value=0)

# íŒŒì´ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
fig, axes = plt.subplots(1, len(group_counts), figsize=(15, 4))

for i, (occupancy, counts) in enumerate(group_counts.iterrows()):
    ax = axes[i]
    counts.plot(kind='pie', autopct='%1.1f%%', ax=ax)
    ax.set_title(f'Occupancy = {occupancy}')
    ax.set_ylabel('')
    ax.legend(title='Weekday', labels=counts.index)

plt.tight_layout()
plt.show()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice23/10.png?raw=true" width="900" height="250"></p>

ğŸ“**ì‹œê°í™” ê²°ê³¼**

- íˆìŠ¤í† ê·¸ë¨ ë° ë°•ìŠ¤í”Œë¡¯ì„ í™•ì¸í•œ ê²°ê³¼ Lightì— ì´ìƒì¹˜ê°€ ìˆì„ ìˆ˜ ìˆìŒ
- ë‚˜ë¨¸ì§€ ì´ìƒì¹˜ë“¤ì€ ì—°ì†í•´ì„œ ë¶„í¬ë˜ì–´ ìˆê¸°ì— í˜„ì—…ì˜ ì˜ê²¬ ì—†ì´ ì‰½ê²Œ ì œê±°í•  ìˆ˜ ì—†ì„ ê²ƒìœ¼ë¡œ íŒë‹¨
- ê°ì‹¤ ì‚¬ìš© ìœ ë¬´ì— ë”°ë¼ lightì™€ co2ëŠ” í™•ì‹¤í•œ í‰ê· ì˜ ì°¨ì´ê°€ ìˆìŒ
- ì£¼ë§ì— ì‚¬ìš©ì¤‘ì¸ ê²½ìš°ëŠ” ì—†ê³  í‰ì¼ì— ë¹„ìŠ·í•œ ë¹„ìœ¨ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì„


### 1.2 ê²°ì¸¡ì¹˜ë¥¼ ëŒ€ì²´í•˜ëŠ” ë°©ì‹ ì„ íƒí•˜ê³  ê·¼ê±°ì œì‹œ, ëŒ€ì²´ ìˆ˜í–‰

ğŸ‘€ **ê²°ì¸¡ì¹˜ íƒìƒ‰**

````python
df_isna = pd.DataFrame(df.isna().sum(), columns=['null_cnt'])
df_isna
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice23/11.png?raw=true" width="200" height="250"></p>

````python
for null_col in df_isna[df_isna.null_cnt > 0].index.to_list():
    print("*"*15)
    print("ê²°ì¸¡ì¹˜ ì»¬ëŸ¼ :", null_col)
    print("ê²°ì¸¡ì¹˜ ë¹„ìœ¨ : {}%".format(df_isna.loc[null_col].null_cnt *100/ len(df)))
    print("describe")
    print(df[null_col].describe())
````

````
***************
ê²°ì¸¡ì¹˜ ì»¬ëŸ¼ : CO2
ê²°ì¸¡ì¹˜ ë¹„ìœ¨ : 0.11725293132328309%
describe
count    17889.000000
mean       647.700865
std        285.997340
min        412.750000
25%        453.000000
50%        532.666667
75%        722.000000
max       2076.500000
````

ğŸ“ **ê²°ì¸¡ì¹˜ ëŒ€ì²´ ë°©ì‹ ì„ íƒ**
- CO2ì˜ ê²°ì¸¡ì¹˜ê°€ 0.11%ì´ê¸° ë•Œë¬¸ì— ì œê±°í•˜ì—¬ë„ ë¬´ë°©í•´ ë³´ì´ë‚˜ ëŒ€ì²´í•˜ê¸°ë¡œ í•¨
- ê²°ì¸¡ì¹˜ëŠ” CO2 ì—°ì†í˜• ë³€ìˆ˜
- ë”°ë¼ì„œ í‰ê·  ëŒ€ì²´, ëª¨ë¸ì„ ì‚¬ìš©í•œ ëŒ€ì²´ ë“±ì´ ê°€ëŠ¥
- ë‚˜ë¨¸ì§€ ë°ì´í„°ë“¤ì˜ ë°ì´í„°ê°€ ëª¨ë‘ ìˆê¸°ì— KNN ëª¨ë¸ì„ ì‚¬ìš©í•´ ê²°ì¸¡ì¹˜ë¥¼ ëŒ€ì²´í•˜ë„ë¡ í•¨

````python
before_fill_df = df[df.isna().any(axis=1)].copy()

from sklearn.impute import KNNImputer

KNN_data = df.copy()
imputer = KNNImputer()
df_filled = imputer.fit_transform(KNN_data)
df_filled = pd.DataFrame(df_filled, columns=KNN_data.columns)
df[KNN_data.columns] = df_filled
df.isnull().sum()
````

````
Temperature      0
Humidity         0
Light            0
CO2              0
HumidityRatio    0
Occupancy        0
weekday          0
is_weekend       0
````

````python
df.loc[before_fill_df.index]
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice23/12.png?raw=true" width="900" height="550"></p>

### 1.3 ì¶”ê°€ì ìœ¼ë¡œ ë°ì´í„°ì˜ ì§ˆ ë° í’ˆì§ˆê´€ë¦¬ë¥¼ í–¥ìƒì‹œí‚¬ë§Œí•œ ë‚´ìš© ì‘ì„±

- Lightì— ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ê²ƒìœ¼ë¡œ ë³´ì„
- ê·¹ë‹¨ì ìœ¼ë¡œ í°ê°’ê³¼ ìŒìˆ˜ê°€ ìˆìŒ
- IQR ë°©ì‹ìœ¼ë¡œ ì œê±°í•´ ì£¼ëŠ” ê²ƒì„ ìˆ˜í–‰í•˜ë©´ ë°ì´í„°ì˜ ì§ˆì´ í–¥ìƒ ë  ê²ƒ

````python
def detect_outliers(df=None, column=None, weight=1.5):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    IQR_weight = IQR*weight
    outlier_idx = df[(df[column] < Q1 - IQR_weight) | (df[column] > Q3 + IQR_weight)].index
    return outlier_idx

outlier_idx = detect_outliers(df=df, column='Light')
df.iloc[outlier_idx]
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice23/13.png?raw=true" width="900" height="350"></p>

````python
df.iloc[outlier_idx].Occupancy.value_counts()
````

````
1.0    2099
0.0    1684
````

ğŸ“ **ì´ìƒì¹˜ íŒë‹¨ ê¸°ì¤€**

- ì´ë¥¼ ëª¨ë‘ ì œê±°í•˜ë©´ Occupancyê°€ 1ì¸ ë°ì´í„°ë¥¼ ê±°ì˜ ëª¨ë‘ ì§€ìš°ê²Œ ë¨
- ìŒìˆ˜ì™€ ê°€ì¥ í° ê°’ì„ ì œê±°í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì´ìƒì¹˜ ì œê±°

````python
# ê¸°ì¤€ 0
df = df[df.Light >= 0 ].reset_index(drop=True)

# ê¸°ì¤€ 99.9%
percentile = 99.9  
threshold = np.percentile(df['Light'], percentile)
df = df[df['Light'] <= threshold]
````

## 2. ë°ì´í„° ë¶ˆê· í˜• ì²˜ë¦¬

### 2.1 ë°ì´í„°ì— ë¶ˆê· í˜•ì´ ìˆëŠ”ì§€ í™•ì¸, ë¶ˆê· í˜• íŒë‹¨ ê·¼ê±° ì‘ì„±

ğŸ‘€ **ì‹œê°í™”**

````python
sns.countplot(x='Occupancy', data =df)
plt.title('count plot of Occupancy', fontsize =14)
plt.show()
ratio0 = round(len(df[df['Occupancy']==0])/len(df)*100, 2)
ratio1 = round(len(df[df['Occupancy']==1])/len(df)*100, 2)
print('0 ë¹„ìœ¨: {}%'.format(ratio0))
print('1 ë¹„ìœ¨: {}%'.format(ratio1))
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice23/14.png?raw=true" width="550" height="350"></p>

````
0 ë¹„ìœ¨: 88.43%
1 ë¹„ìœ¨: 11.57%
````

- ë°ì´í„°ì˜ ë¹„ìœ¨ì´ ì•½ 9:1 ì´ë¯€ë¡œ ë¶ˆê· í˜•ì´ë¼ê³  íŒë‹¨

### 4.2 Oversampling

ğŸ“ **Random Oversampling**

````python
from imblearn.over_sampling import RandomOverSampler, SMOTE
import time

X = df[df.columns.difference(['Occupancy'])]
y = df['Occupancy']
start = time.time()
# Random Oversampling
ros = RandomOverSampler(random_state =42)
X_ro, y_ro = ros.fit_resample(X, y)
print("time :", time.time() - start)
````

````
time : 0.006474018096923828
````

ğŸ“ **SMOTE**

````python
start = time.time()
sm = SMOTE(random_state =42)
X_sm, y_sm = sm.fit_resample(X, y)
print("time :", time.time() - start)
````

````
time : 0.01717376708984375
````

## 5. Modeling

### 5.1 ì›ë³¸ ë° ì˜¤ë²„ìƒ˜í”Œë§ ìˆ˜í–‰ ë°ì´í„° ì…‹ìœ¼ë¡œ ëª¨ë¸ë§ ìˆ˜í–‰

ğŸ“ **Origin Dataset**

````python
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

start = time.time()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, stratify =y, random_state =100)
clf = RandomForestClassifier(n_estimators =100, min_samples_split =10)
clf.fit(X_train, y_train)
print('train ì •í™•ë„ :', clf.score(X_train, y_train), '\n')
pred=clf.predict(X_test)
print(classification_report(y_test, pred))
print('test ì •í™•ë„ :', clf.score(X_test, y_test), '\n')
print("time :", time.time() - start)
````

````
train ì •í™•ë„ : 0.997124824684432 

              precision    recall  f1-score   support

         0.0       1.00      0.99      1.00      3153
         1.0       0.94      0.99      0.97       412

    accuracy                           0.99      3565
   macro avg       0.97      0.99      0.98      3565
weighted avg       0.99      0.99      0.99      3565

test ì •í™•ë„ : 0.9918653576437587 

time : 0.6616039276123047
````

ğŸ“ **Random Oversampling Dataset**

````python
start = time.time()
X_ro_train, X_ro_test, y_ro_train, y_ro_test = train_test_split(X_ro, y_ro, test_size =0.2, stratify =y_ro, \
                                                                random_state =100)
clf_ro = RandomForestClassifier(n_estimators =100, min_samples_split=10, random_state =100)
clf_ro.fit(X_ro_train, y_ro_train)
print('train ì •í™•ë„ :', clf_ro.score(X_ro_train, y_ro_train), '\n')
pred_ro=clf_ro.predict(X_ro_test)
print(classification_report(y_ro_test, pred_ro))
print('test ì •í™•ë„ :', clf_ro.score(X_ro_test, y_ro_test), '\n')
print("time :", time.time() - start)
````

````
train ì •í™•ë„ : 0.9992466296590008 

              precision    recall  f1-score   support

         0.0       1.00      0.99      1.00      3153
         1.0       0.99      1.00      1.00      3153

    accuracy                           1.00      6306
   macro avg       1.00      1.00      1.00      6306
weighted avg       1.00      1.00      1.00      6306

test ì •í™•ë„ : 0.9955597843323819 

time : 1.362199068069458
````

ğŸ“ **SMOTE Dataset**

````python
start = time.time()
X_sm_train, X_sm_test, y_sm_train, y_sm_test = train_test_split(X_sm, y_sm, test_size =0.2, stratify =y_sm, \
                                                                random_state =100)
clf_sm = RandomForestClassifier(n_estimators =100, min_samples_split=10, random_state =234)
clf_sm.fit(X_sm_train, y_sm_train)
print('train ì •í™•ë„ :', clf_sm.score(X_sm_train, y_sm_train), '\n')
pred_sm=clf_sm.predict(X_sm_test)
print(classification_report(y_sm_test, pred_sm))
print('test ì •í™•ë„ :', clf_sm.score(X_sm_test, y_sm_test), '\n')
print("time :", time.time() - start)
````

````
train ì •í™•ë„ : 0.9984932593180016 

              precision    recall  f1-score   support

         0.0       1.00      0.99      0.99      3153
         1.0       0.99      1.00      0.99      3153

    accuracy                           0.99      6306
   macro avg       0.99      0.99      0.99      6306
weighted avg       0.99      0.99      0.99      6306

test ì •í™•ë„ : 0.9946083095464637 

time : 1.8415770530700684
````

# í†µê³„ë¶„ì„

## 1. ê°€ì„¤ê²€ì • (1)

### ê³µì¥ì—ì„œëŠ” ì§„ê³µê´€ ìˆ˜ëª…ì´ 1ë§Œ ì‹œê°„ì´ë¼ê³  ì£¼ì¥í•˜ì—¬ í’ˆì§ˆê´€ë¦¬íŒ€ì—ì„œ 12ê°œ ìƒ˜í”Œì„ ë½‘ì•˜ìŒ ìœ ì˜ìˆ˜ì¤€ 5%ì—ì„œ ë¶€í˜¸ ê²€ì •í•˜ì‹œì˜¤

````python
import pandas as pd
df =pd.read_csv('https://raw.githubusercontent.com/Datamanim/datarepo/main/adp/23/problem2.csv')
df.head()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice23/15.png?raw=true" width="200" height="150"></p>

âœï¸ **ë¬¸ì œ ì •ì˜**
- ëª¨í‰ê·  1ë§Œì‹œê°„
- ìƒ˜í”Œì‚¬ì´ì¦ˆ 12
- ìœ ì˜ìˆ˜ì¤€ 5%
- ë¶€í˜¸ ê²€ì •

### 1.1 ê°€ì„¤ìˆ˜ë¦½
- H0: ì§„ê³µê´€ ìˆ˜ëª…ì˜ ì¤‘ìœ„ìˆ˜ëŠ” 1ë§Œ ì‹œê°„
- H1: ì§„ê³µê´€ ìˆ˜ëª…ì˜ ì¤‘ìœ„ìˆ˜ëŠ” 1ë§Œ ì‹œê°„ì´ ì•„ë‹˜

### 1.2 ìœ íš¨í•œ ë°ì´í„° ê°œìˆ˜
- ë¶€í˜¸ê²€ì •ì—ì„œ ì¤‘ìœ„ìˆ˜ì™€ ë™ì¼í•œ ê°’ì€ ë¶ˆí•„ìš”í•œ ë°ì´í„°

````python
sample_data=df['life span']
df_fillter = df[df['life span'] != np.median(sample_data)]
print("ìœ íš¨ ë°ì´í„°:", sum(effective_data))
````

````
ìœ íš¨ ë°ì´í„°: 8
````

### 1.3 ê²€ì •í†µê³„ëŸ‰ ë° ì—°êµ¬ê°€ì„¤ ì±„íƒ ì—¬ë¶€ë¥¼ ì‘ì„±

````python
import numpy as np 
from scipy import stats

data = df['life span'].tolist()
# ì¤‘ì•™ê°’
median_value = np.median(data)

# ë¶€í˜¸ê²€ì •
# ì¤‘ì•™ê°’ë³´ë‹¤ í° ë°ì´í„°ì˜ ê°œìˆ˜
above = np.sum(data > median_value)
# ì¤‘ì•™ê°’ë³´ë‹¤ ì‘ì€ ë°ì´í„°ì˜ ê°œìˆ˜
below = np.sum(data < median_value)

# ì´í•­ ê²€ì •
p_value = stats.binom_test(min(above, below), n=above + below, p=0.5) 
print('p-value: ', p_value)
````

````
p-value:  0.7265625
````

í˜¹ì€

````python
import statsmodels.stats.descriptivestats as smsd

# ë‘ ì§‘ë‹¨ì˜ ë°ì´í„°
group1 = df['life span']

# ë¶€í˜¸ê²€ì • ìˆ˜í–‰
statistic, p_value = smsd.sign_test(group1 - 10000)

print("ê²€ì • í†µê³„ëŸ‰:", statistic)
print("p-value:", p_value)

alpha = 0.05  # ìœ ì˜ìˆ˜ì¤€ ì„¤ì •

if p_value < alpha:
    print("ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•©ë‹ˆë‹¤. ë‘ ì§‘ë‹¨ì˜ ì¤‘ì•™ê°’ì´ ë‹¤ë¦…ë‹ˆë‹¤.")
else:
    print("ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‘ ì§‘ë‹¨ì˜ ì¤‘ì•™ê°’ì´ ê°™ìŠµë‹ˆë‹¤.")
````

````
ê²€ì • í†µê³„ëŸ‰: -1.0
p-value: 0.7265625
ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‘ ì§‘ë‹¨ì˜ ì¤‘ì•™ê°’ì´ ê°™ìŠµë‹ˆë‹¤.
````

ğŸ“ **ê²€ì • ê²°ê³¼**
- P-valueê°€ 0.05ë³´ë‹¤ ë†’ê¸°ì— ê·€ë¬´ê°€ì„¤ ì±„íƒ
- ì¤‘ìœ„ìˆ˜ëŠ” 1ë§Œ ì‹œê°„ì´ë‹¤

## 2. ê°€ì„¤ê²€ì • (2)
### í•™ê³¼ë³„ í•™ì  ë¶„í¬ ì¸ì›ìˆ˜ í‘œê°€ ìˆë‹¤. í•™ê³¼ì™€ ì„±ì ì´ ê´€ê³„ìˆëŠ”ì§€ë¥¼ ê²€ì •í•˜ë¼

````python
df = pd.DataFrame({'ì‚¬íšŒê³¼í•™':[15,60,24], 'ìì—°ê³¼í•™':[25,69,5],'ê³µí•™':[10,77,13], 'score':['1.5-2.5','2.5-3.5','3.5-4.5']})
df = df.set_index(['score'])
df
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice23/16.png?raw=true" width="200" height="150"></p>

âœï¸ **ë¬¸ì œ ì •ì˜**
- í•™ê³¼-ë²”ì£¼í˜•, ì„±ì -ë²”ì£¼í˜•ì˜ ìƒê´€ê´€ê³„
- êµì°¨ë¶„ì„ì˜ ë…ë¦½ì„±ê²€ì • ìˆ˜í–‰

### 2.1 ê°€ì„¤ìˆ˜ë¦½
- H0: í•™ê³¼ì™€ ì„±ì ì€ ë…ë¦½
- H1: í•™ê³¼ì™€ ì„±ì ì€ ë…ë¦½ì´ ì•„ë‹˜

### 2.2 ê¸°ëŒ€ê°’ ë° ê²€ì •í†µê³„ëŸ‰, ê°€ì„¤ì„ íƒ

````python
from scipy.stats import chi2_contingency
chi, p, df, expect = chi2_contingency(df)
print('Statistic:', chi)
print('p-value:',p)
print('df:',df)
print('expect: \n', expect)
````

````
Statistic: 22.136920195949322
p-value: 0.00018822647762421383
df: 4
expect: 
 [[16.61073826 16.61073826 16.77852349]
 [68.43624161 68.43624161 69.12751678]
 [13.95302013 13.95302013 14.09395973]]
````

ğŸ“ **ê²€ì • ê²°ê³¼**

- p-value < 0.05ì´ë¯€ë¡œ ê·€ë¬´ê°€ì„¤ ê¸°ê°
-  ë…ë¦½ì´ ì•„ë‹ˆë©° ìƒê´€ê´€ê³„ê°€ ìˆìŒ

## 3. ì‹œê³„ì—´ ë¶„ì„

````python
import pandas as pd
df =pd.read_csv('https://raw.githubusercontent.com/Datamanim/datarepo/main/adp/23/problem3_covid2.csv')
df.head()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice23/17.png?raw=true" width="500" height="200"></p>

### 3.1 ë°ì´í„°ëŠ” ì¼ìë³„ ê° ë‚˜ë¼ì˜ ì¼ì¼ í™•ì§„ììˆ˜ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. ê° ë‚˜ë¼ì˜ ì¼ìë³„ ëˆ„ì í™•ì§„ì ìˆ˜ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë°ì´í„° í”„ë ˆì„ì„ ìƒì„±

````python
df_new = df.groupby(by=['location','date']).sum()
df_new
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice23/18.png?raw=true" width="500" height="400"></p>

### 3.2 1ì—ì„œ êµ¬í•œ ë°ì´í„°ë¥¼ ê° ë‚˜ë¼ë³„ë¡œ acfê°’ì„ êµ¬í•˜ê³ (lagëŠ” 50ê°œê¹Œì§€ êµ¬í•˜ê³  ì²«ë²ˆì§¸ ê°’ì„ ì œì™¸í•˜ë¼) êµ­ê°€ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìœ í´ë¦¬ë””ì•ˆ ê±°ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§ì„ ì§„í–‰ í›„ ê³„ì¸µì  êµ°ì§‘ ë¶„ì„ì„ ìœ„í•´ ë´ë“œë¡œê·¸ë¨ ì‘ì„±

````python
import statsmodels.api as sm

df_idx = df_new.reset_index()
df_acf = pd.DataFrame()

for loc in df['location'].unique():
    np.random.seed(0)

    x = df_idx[df_idx.location == loc][['date', 'new_cases']].set_index('date')

    acf_result = sm.tsa.stattools.acf(x, adjusted=False, 
                                  nlags=50, qstat=False, 
                                  fft=True, alpha=None, 
                                  bartlett_confint=True, missing='none')
    df_t = pd.DataFrame({'acf':acf_result[1:]})
    df_t = df_t.T
    df_t['location'] = loc
    df_t = df_t.set_index(['location'])
    
    df_acf = pd.concat([df_acf, df_t])
````

````python
from scipy.cluster.hierarchy import dendrogram, linkage, fcluster
single = linkage(df_acf, metric='euclidean', method='ward')

plt.figure(figsize=(10,3))
dendrogram(single, orientation='top', labels=df_acf.index.tolist(), distance_sort='descending'
          , color_threshold=4.0, show_leaf_counts=True)
plt.axhline(y=20, color='r', linewidth=1)
plt.show()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice23/19.png?raw=true" width="900" height="500"></p>









