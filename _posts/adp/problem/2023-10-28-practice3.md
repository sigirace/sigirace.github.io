---
layout: single
title:  'ADP ì‹¤ê¸° ì—°ìŠµë¬¸ì œ (3)'
toc: true
categories: [ADP]
tags: [Missing Value, Over Sampling, Time Series, ACF]


---

ë³¸ ê²Œì‹œë¬¼ì€ ADP ì‹¤ê¸°ì˜ ì—°ìŠµë¬¸ì œ í’€ì´ì— ëŒ€í•œ ê²ƒì´ë‹¤.
{: .notice}

# ë¨¸ì‹ ëŸ¬ë‹

## 1. ë°ì´í„° íƒìƒ‰ (EDA)

````python
import warnings
warnings.filterwarnings('ignore')
import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt
import seaborn as sns
hotel = pd.read_csv("https://raw.githubusercontent.com/ADPclass/ADP_book_ver01/main/data/hotel_bookings.csv")
````

### 1.1 ë°ì´í„° ê°œìš”

````
hotel
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice3/1.png?raw=true" width="900" height="350"></p>

````python
hotel_desc = hotel.describe()
hotel_desc
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice3/2.png?raw=true" width="900" height="200"></p>

````python
pd.DataFrame(hotel_desc.loc['std',:]).sort_values(by=['std'], ascending=False)
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice3/3.png?raw=true" width="400" height="350"></p>

````python
hotel.info()
````

````
 #   Column                          Non-Null Count  Dtype  
---  ------                          --------------  -----  
 0   is_canceled                     20000 non-null  int64  
 1   deposit_type                    20000 non-null  object 
 2   lead_time                       19995 non-null  float64
 3   stays_in_weekend_nights         20000 non-null  int64  
 4   stays_in_week_nights            20000 non-null  int64  
 5   is_repeated_guest               19642 non-null  float64
 6   previous_cancellations          20000 non-null  int64  
 7   previous_bookings_not_canceled  20000 non-null  int64  
 8   booking_changes                 20000 non-null  int64  
 9   days_in_waiting_list            20000 non-null  int64  
 10  adr                             18937 non-null  float64
````

ğŸ“ **ë°ì´í„° íƒìƒ‰ ê²°ê³¼**

1. target: is_cancled
2. missing value: lead_time, is_repeated_guest, adrì— ê²°ì¸¡ì¹˜ ì¡´ì¬
3. outlier: í¸ì°¨ê°€ í° lead_time, adr, days_in_waiting_listì— ëŒ€í•´ ì´ìƒì¹˜ íƒìƒ‰ í•„ìš”
4. scaling: ê° ì»¬ëŸ¼ì˜ max ê°’ì´ ìƒì´í•˜ê¸° ë•Œë¬¸ì— ì°¨ì´ê°€ í´ ê²½ìš° ìŠ¤ì¼€ì¼ë§ ê³ ë ¤
5. feature type: deposit_typeì™¸ì— is_canceled, is_repeated_guestëŠ” 0ê³¼ 1ë¡œ ì´ë£¨ì–´ì§„ categorical feature

### 1.2 ì‹œê°í™”

````python
# ìˆ˜ì¹˜í˜•
continuous_columns = ['lead_time', 'stays_in_weekend_nights',
       'stays_in_week_nights', 'previous_cancellations',
       'previous_bookings_not_canceled', 'booking_changes',
       'days_in_waiting_list', 'adr']
# ë²”ì£¼í˜•
categorical_columns = ['is_canceled', 'deposit_type', 'is_repeated_guest']
````

ğŸ‘€ **ìˆ˜ì¹˜í˜•-íˆìŠ¤í† ê·¸ë¨**

````python
fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(15, 4))

for i, column in enumerate(continuous_columns):

    row = i // 4
    col = i % 4
    hotel[column].plot(kind='hist', bins=20, ax=axes[row, col], color='skyblue', edgecolor='black')
    axes[row, col].set_title(f'Histogram of {column}')
    axes[row, col].set_xlabel(column)
    axes[row, col].set_ylabel('Frequency')

plt.tight_layout()

plt.show()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice3/4.png?raw=true" width="900" height="350"></p>

ğŸ‘€ **ìˆ˜ì¹˜í˜•-ë°•ìŠ¤í”Œë¡¯**

````python
fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(15, 4))

for i, column in enumerate(continuous_columns):

    row = i // 4
    col = i % 4
    sns.boxplot(x=hotel[column], ax=axes[row, col], color='skyblue')
    axes[row, col].set_title(f'Box plot of {column}')
    axes[row, col].set_xlabel(column)
    axes[row, col].set_ylabel('Frequency')

plt.tight_layout()
plt.show()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice3/5.png?raw=true" width="900" height="350"></p>

ğŸ‘€ **ë²”ì£¼í˜•-ë§‰ëŒ€ê·¸ë˜í”„**

````python
fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))

for i, column in enumerate(categorical_columns):

    hotel[column].value_counts().sort_index().plot(kind='bar', ax=axes[i], color='skyblue')
    axes[i].set_title(f'Bar Plot of {column}')
    axes[i].set_xlabel(column)
    axes[i].set_ylabel('Frequency')

plt.tight_layout()
plt.show()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice3/6.png?raw=true" width="900" height="350"></p>

ğŸ‘€ **ê·¸ë£¹ë³„ ë°ì´í„°**

- classification ë¬¸ì œì´ê¸° ë•Œë¬¸ì— ê·¸ë£¹ë³„ë¡œ ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ì—¬ íŒŒì•…

````python
is_canceled = hotel.groupby('is_canceled').mean()
is_canceled
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice3/7.png?raw=true" width="900" height="100"></p>

````python
fig, axes = plt.subplots(3, 3, figsize=(16, 12))

columns = is_canceled.columns.to_list()

for i, column in enumerate(columns):
    row = i // 3
    col = i % 3
    sns.barplot(x=is_canceled.index, y=column, data=is_canceled, ax=axes[row, col])
    axes[row, col].set_title(f'Average {column}')
    axes[row, col].set_xlabel("is_canceled")
    axes[row, col].set_ylabel(f'Average {column}')

plt.tight_layout()
plt.show()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice3/8.png?raw=true" width="900" height="500"></p>

ğŸ‘€ **ìƒê´€ê´€ê³„ ì‹œê°í™”**

````python
df_cor = hotel.drop(columns=["is_canceled"]).corr(method='pearson')
sns.heatmap(df_cor,
             xticklabels = df_cor.columns,
             yticklabels = df_cor.columns,
             cmap='RdBu_r',
             annot=True, 
             linewidth=3)
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice3/9.png?raw=true" width="900" height="500"></p>

ğŸ“ **ì‹œê°í™” ê²°ê³¼**
1. ìˆ˜ì¹˜í˜• ë³€ìˆ˜-íˆìŠ¤í† ê·¸ë¨: previous_cancellations, previous_bookings_not_canceld, booking_changes, days_in_waiting_listì˜ ë°ì´í„° ë¶„í¬ëŠ” í•œìª½ì— ëª°ë ¤ìˆìŒì„ í™•ì¸
2. ìˆ˜ì¹˜í˜• ë³€ìˆ˜-ë°•ìŠ¤í”Œë¡¯: ê·¸ë˜í”„ ìƒ Outlierë“¤ì´ ì¡´ì¬í•˜ë‚˜ ì—°ì†ì ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ê¸°ì— ì œê±°ë¥¼ ìœ„í•´ì„œëŠ” í˜„ì—…ì˜ ì˜ê²¬ì´ í•„ìš”, ë°ì´í„° ë¶„ì„ê°€ì˜ ì…ì¥ì—ì„œëŠ” IQRì„ í™œìš© í•  ìˆ˜ ìˆìŒ
3. ë²”ì£¼í˜• ë³€ìˆ˜-ë§‰ëŒ€ê·¸ë˜í”„: is_cancledê°€ 0ì´ ë§ì€ ë¶ˆê· í˜• ë°ì´í„°, deposit_typeê³¼ is_repeated_guest ë˜í•œ ë¶ˆê· í˜•ì„
4. ê·¸ë£¹ë³„ ë°ì´í„°: previous_cancellations, previous_bookings_not_canceledì— ë”°ë¼ ì·¨ì†Œ ë¹„ìœ¨ì´ í™•ì—°íˆ ë‹¬ë¼ì§ì„ ì•Œ ìˆ˜ ìˆìŒ
5. ìƒê´€ê´€ê³„ ë¶„ì„: ì„¤ëª…ë³€ìˆ˜ê°„ ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§€ëŠ” ê²ƒì´ ì—†ìœ¼ë¯€ë¡œ ì„ í˜• ëª¨ë¸ ì‚¬ìš©ì‹œ ëª¨ë“  ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ë„ ë¬´ë°©í•  ê²ƒìœ¼ë¡œ íŒë‹¨ë¨

## 2 ê²°ì¸¡ì¹˜ íƒìƒ‰ ë° ì²˜ë¦¬

### 2.1 ê²°ì¸¡ì¹˜ íƒìƒ‰

````python
df_isna = pd.DataFrame(hotel.isna().sum(), columns=['null_cnt'])
df_isna
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice3/10.png?raw=true" width="300" height="350"></p>

- ê²°ì¸¡ì¹˜ê°€ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ì¤‘ is_repeated_guestëŠ” categorical typeì´ë©° lead_timeê³¼ adrì€ numerical type

### 2.2 ê²°ì¸¡ì¹˜ ë¹„ìœ¨ í™•ì¸

````python
for null_col in df_isna[df_isna.null_cnt > 0].index.to_list():
    print("*"*15)
    print("ê²°ì¸¡ì¹˜ ì»¬ëŸ¼ :", null_col)
    print("ê²°ì¸¡ì¹˜ ë¹„ìœ¨ : {}%".format(df_isna.loc[null_col].null_cnt *100/ len(hotel)))
    print("describe")
    print(hotel[null_col].describe())
````

````
***************
ê²°ì¸¡ì¹˜ ì»¬ëŸ¼ : lead_time
ê²°ì¸¡ì¹˜ ë¹„ìœ¨ : 0.025%
describe
count    19995.000000
mean        85.978345
std         96.427240
min          0.000000
25%         11.000000
50%         51.000000
75%        132.000000
max        629.000000
Name: lead_time, dtype: float64
***************
ê²°ì¸¡ì¹˜ ì»¬ëŸ¼ : is_repeated_guest
ê²°ì¸¡ì¹˜ ë¹„ìœ¨ : 1.79%
describe
count    19642.000000
mean         0.038133
std          0.191521
min          0.000000
25%          0.000000
50%          0.000000
75%          0.000000
max          1.000000
Name: is_repeated_guest, dtype: float64
***************
ê²°ì¸¡ì¹˜ ì»¬ëŸ¼ : adr
ê²°ì¸¡ì¹˜ ë¹„ìœ¨ : 5.315%
describe
count    18937.000000
mean       101.410239
std         49.245097
min         -6.380000
25%         68.800000
50%         94.500000
75%        126.000000
max        451.500000
Name: adr, dtype: float64
````

### 2.3 ê²°ì¸¡ì¹˜ ì²˜ë¦¬

````python
hotel.dropna(subset=['lead_time'], axis=0, inplace=True)
hotel['is_repeated_guest'].fillna(0, inplace = True)
````

- lead_timeì€ ë§¤ìš° ì‘ì€ ë¹„ì¤‘ì„ ì°¨ì§€í•˜ê¸°ì— ê²°ì¸¡ì¹˜ ì œê±°
- is_repeated_guestì€ categorical typeì´ë©° ì•ì„œ ëŒ€ë¶€ë¶„ì˜ ë°ì´í„°ê°€ 0ì„ì„ í™•ì¸í•˜ì˜€ìœ¼ë¯€ë¡œ 0ìœ¼ë¡œ ëŒ€ì²´ (ë¹ˆë„ìˆ˜)
- adrì€ ì‹œê°í™”ë¥¼ í†µí•´ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë°©ë²• ëª¨ìƒ‰

ğŸ‘€ **adr ìƒê´€ê´€ê³„ ì‹œê°í™”-ìŠ¤ìºí„°í”Œë¡¯**

````python
columns = hotel.columns.to_list()
columns.remove('adr')
target = 'adr'

fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(16, 16))

for i, column in enumerate(columns):
    row = i // 2
    col = i % 2
    axes[row, col].scatter(hotel[column], hotel[target], alpha=0.5, color='b')
    axes[row, col].set_title('Scatter Plot of {} vs. {}'.format(column, target))
    axes[row, col].set_xlabel(column)
    axes[row, col].set_ylabel(target)

plt.tight_layout()

plt.show()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice3/11.png?raw=true" width="900" height="800"></p>

ğŸ“ **adr ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë°©ì•ˆ**

- ë‹¤ë¥¸ ì„¤ëª…ë³€ìˆ˜ë“¤ê³¼ íŠ¹ë³„í•œ ê´€ê³„ê°€ íŒŒì•…ë˜ì§€ ì•ŠìŒ 
- ê´€ê³„ê°€ ìˆë‹¤ë©´ êµ¬ê°„ë³„ í‰ê· ë“±ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ
- Tree modelì„ ì‚¬ìš©í•˜ì—¬ ê²°ì¸¡ì¹˜ ëŒ€ì²´ ë°©ë²• ìˆ˜í–‰

### 2.4 ëª¨ë¸ì„ ì‚¬ìš©í•œ ê²°ì¸¡ì¹˜ ì²˜ë¦¬

````python
df = hotel.copy()

df['deposit_type'] = df['deposit_type'].replace('No Deposit', 0)
df['deposit_type'] = df['deposit_type'].replace('Refundable', 1)
df['deposit_type'] = df['deposit_type'].replace('Non Refund', 2)
````

- categorical ë³€ìˆ˜ë¥¼ í™œìš©í•˜ê¸° ìœ„í•´ ì¸ì½”ë”© ìˆ˜í–‰

````python
from sklearn.ensemble import RandomForestRegressor

missing_col = 'adr'
features = df.columns.to_list()
features.remove('adr')

train_data = df.dropna()
test_data = df[df.isnull().any(axis=1)]

rf_model = RandomForestRegressor(n_estimators=50)
rf_model.fit(train_data[features], train_data[missing_col])

predicted_values = rf_model.predict(test_data[features])
test_data[missing_col] = predicted_values
df_fill = pd.concat([train_data, test_data])

df_fill.isna().sum()
````

````
is_canceled                       0
deposit_type                      0
lead_time                         0
stays_in_weekend_nights           0
stays_in_week_nights              0
is_repeated_guest                 0
previous_cancellations            0
previous_bookings_not_canceled    0
booking_changes                   0
days_in_waiting_list              0
adr                               0
````

## 3. ë°ì´í„° ì§ˆì„ í–¥ìƒì‹œí‚¤ëŠ” ë°©ë²• ì œì‹œ

- í˜„ì—…ì˜ ì˜ê²¬ì„ í†µí•´ ì´ìƒì¹˜ë¥¼ ì œê±°í•´ì£¼ëŠ” ë°©ë²•ì„ ì‚¬ìš©
- í˜„ì—…ì˜ ì˜ê²¬ì„ êµ¬í•  ìˆ˜ ì—†ì„ ê²½ìš° IQR ë°©ì‹ì„ ì‚¬ìš©
- ë°ì´í„° ë¶ˆê· í˜•ì„ í•´ê²°í•  ìˆ˜ ìˆë„ë¡ ë°ì´í„°ë¥¼ ìˆ˜ì§‘

## 4. ë°ì´í„° ë¶ˆê· í˜• í•´ê²°

### 4.1 ë°ì´í„° ë¶ˆê· í˜• íŒŒì•…

ğŸ‘€ **ì‹œê°í™”**

````python
sns.countplot(x='is_canceled', data =df_fill)
plt.title('count plot of is_canceled', fontsize =14)
plt.show()
ratio0 = round(len(df_fill[df_fill['is_canceled']==0])/len(df_fill)*100, 2)
ratio1 = round(len(df_fill[df_fill['is_canceled']==1])/len(df_fill)*100, 2)
print('0 ë¹„ìœ¨: {}%'.format(ratio0))
print('1 ë¹„ìœ¨: {}%'.format(ratio1))
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice3/12.png?raw=true" width="500" height="350"></p>

````
0 ë¹„ìœ¨: 88.0%
1 ë¹„ìœ¨: 12.0%
````

- ë°ì´í„°ì˜ ë¹„ìœ¨ì´ ì•½ 9:1 ì´ë¯€ë¡œ ë¶ˆê· í˜•ì´ë¼ê³  íŒë‹¨

### 4.2 Oversampling

ğŸ“ **Random Oversampling**

````python
from imblearn.over_sampling import RandomOverSampler, SMOTE
import time

X = df_fill[df_fill.columns.difference(['is_canceled'])]
y = df_fill['is_canceled']
start = time.time()
# Random Oversampling
ros = RandomOverSampler(random_state =42)
X_ro, y_ro = ros.fit_resample(X, y)
print("time :", time.time() - start)
````

````
time : 0.00850820541381836
````

ğŸ“ **SMOTE**

````python
start = time.time()
sm = SMOTE(random_state =42)
X_sm, y_sm = sm.fit_resample(X, y)
print("time :", time.time() - start)
````

````
time : 0.02542901039123535
````

ğŸ“ **Oversampling ìˆ˜í–‰ ê²°ê³¼**

- SMOTEê°€ ë” ì˜¤ëœì‹œê°„ ê±¸ë¦¼

## 5. Modeling

### 5.1 ì›ë³¸ ë° ì˜¤ë²„ìƒ˜í”Œë§ ìˆ˜í–‰ ë°ì´í„° ì…‹ìœ¼ë¡œ ëª¨ë¸ë§ ìˆ˜í–‰

ğŸ“ **Origin Dataset**

````python
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

start = time.time()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, stratify =y, random_state =100)
clf = RandomForestClassifier(n_estimators =100, min_samples_split =10)
clf.fit(X_train, y_train)
print('train ì •í™•ë„ :', clf.score(X_train, y_train), '\n')
pred=clf.predict(X_test)
print(classification_report(y_test, pred))
print('test ì •í™•ë„ :', clf.score(X_test, y_test), '\n')
print("time :", time.time() - start)
````

````
train ì •í™•ë„ : 0.934421105276319 

              precision    recall  f1-score   support

           0       0.92      1.00      0.96      3519
           1       0.96      0.40      0.56       480

    accuracy                           0.93      3999
   macro avg       0.94      0.70      0.76      3999
weighted avg       0.93      0.93      0.91      3999

test ì •í™•ë„ : 0.9259814953738434 

time : 1.3518381118774414
````

ğŸ“ **Random Oversampling Dataset**

````python
start = time.time()
X_ro_train, X_ro_test, y_ro_train, y_ro_test = train_test_split(X_ro, y_ro, test_size =0.2, stratify =y_ro, \
                                                                random_state =100)
clf_ro = RandomForestClassifier(n_estimators =100, min_samples_split=10, random_state =100)
clf_ro.fit(X_ro_train, y_ro_train)
print('train ì •í™•ë„ :', clf_ro.score(X_ro_train, y_ro_train), '\n')
pred_ro=clf_ro.predict(X_ro_test)
print(classification_report(y_ro_test, pred_ro))
print('test ì •í™•ë„ :', clf_ro.score(X_ro_test, y_ro_test), '\n')
print("time :", time.time() - start)
````

````
train ì •í™•ë„ : 0.9868925831202046 

              precision    recall  f1-score   support

           0       0.98      0.93      0.96      3519
           1       0.94      0.98      0.96      3519

    accuracy                           0.96      7038
   macro avg       0.96      0.96      0.96      7038
weighted avg       0.96      0.96      0.96      7038

test ì •í™•ë„ : 0.9568059107701051 

time : 2.283308982849121
````

ğŸ“ **SMOTE Dataset**

````python
start = time.time()
X_sm_train, X_sm_test, y_sm_train, y_sm_test = train_test_split(X_sm, y_sm, test_size =0.2, stratify =y_sm, \
                                                                random_state =100)
clf_sm = RandomForestClassifier(n_estimators =100, min_samples_split=10, random_state =234)
clf_sm.fit(X_sm_train, y_sm_train)
print('train ì •í™•ë„ :', clf_sm.score(X_sm_train, y_sm_train), '\n')
pred_sm=clf_sm.predict(X_sm_test)
print(classification_report(y_sm_test, pred_sm))
print('test ì •í™•ë„ :', clf_sm.score(X_sm_test, y_sm_test), '\n')
print("time :", time.time() - start)
````

````
train ì •í™•ë„ : 0.9648337595907929 

              precision    recall  f1-score   support

           0       0.88      0.90      0.89      3519
           1       0.90      0.88      0.89      3519

    accuracy                           0.89      7038
   macro avg       0.89      0.89      0.89      7038
weighted avg       0.89      0.89      0.89      7038

test ì •í™•ë„ : 0.8908780903665814 

time : 2.5965330600738525
````

### 5.2 ëª¨ë¸ë§ ê²°ê³¼ í•´ì„

- ì›ë³¸ ë°ì´í„°ë³´ë‹¤ oversamplingí•œ ë°ì´í„°ì—ì„œ train, test ëª¨ë‘ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì„ì„ í™•ì¸

# í†µê³„ë¶„ì„

## 1. ê°€ì„¤ê²€ì • (1)

### ê³µì¥ì—ì„œëŠ” ì‹œì œí’ˆì˜ ë†ë„(%)ê°€ 60ì´ë¼ê³  ì£¼ì¥í•˜ë©° í’ˆì§ˆê´€ë¦¬íŒ€ì—ì„œ 10ê°œì˜ ìƒ˜í”Œì„ ë½‘ì•˜ë‹¤. ìœ ì˜ìˆ˜ì¤€ 5%ì—ì„œ ë‹¤ìŒì„ ê²€ì •í•˜ì‹œì˜¤.

````python
x =[52 ,50 ,62 ,75 ,26 ,45 ,62 ,35 ,57 ,14]
````

âœï¸ **ë¬¸ì œì •ì˜**

- ëª¨í‰ê·  ì¶”ì •
- ë°ì´í„°ì˜ ìˆ˜ê°€ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì •ê·œì„± ê²€ì • ë¶ˆê°€
- ìœŒ ì½•ìŠ¨ì˜ ë¶€í˜¸ ìˆœìœ„ ê²€ì •

### 1.1 ê°€ì„¤ ìˆ˜ë¦½

- H0: ëª¨í‰ê· ì˜ ê°’ì€ 60ì„
- H1: ëª¨í‰ê· ì˜ ê°’ì€ 60ì´ ì•„ë‹˜

### 1.2 ê²€ì • í›„ ê°€ì„¤ ì±„íƒ

````python
from scipy import stats

result = stats.wilcoxon(pd.Series(x)-60)
print(result)
````

````
WilcoxonResult(statistic=9.5, pvalue=0.064453125)
````

ğŸ“ **ê²€ì •ê²°ê³¼ í•´ì„**

- p-valueê°€ ìœ ì˜ìˆ˜ì¤€ 0.05ë³´ë‹¤ í¬ë¯€ë¡œ ê·€ë¬´ê°€ì„¤ ì±„íƒ
- ëª¨í‰ê· ì˜ ê°’ì€ 60

## 2. ê°€ì„¤ê²€ì • (2)

### ì‚¬íšŒê³¼í•™, ìì—°ê³¼í•™, ê³µí•™ ì„¸ ê°œ í•™ê³¼ì˜ í‰ì ì¡°ì‚¬í‘œë¥¼ ë³´ê³  í•™ê³¼ì™€ ì„±ì ì´ ê´€ê³„ìˆëŠ”ì§€ ê²€ì •

````python
a = [16, 30, 12]
b = [12, 20, 3]
c = [18, 13, 14]

data = {
    'ì‚¬íšŒê³¼í•™': a,
    'ìì—°ê³¼í•™': b,
    'ê³µí•™': c
}

index = ['3.5~4.5', '2.5~3.5', '1.5~2.5']

table = pd.DataFrame(data, index=index)
print(table)
````

````
         ì‚¬íšŒê³¼í•™  ìì—°ê³¼í•™  ê³µí•™
3.5~4.5    16    12  18
2.5~3.5    30    20  13
1.5~2.5    12     3  14
````

âœï¸ **ë¬¸ì œì •ì˜**

- ë²”ì£¼í˜• ë³€ìˆ˜ê°€ ë‘ ê°œ ì´ìƒì¸ ê²½ìš° ìƒê´€ì´ ìˆëŠ”ì§€ ê²€ì •
- êµì°¨ë¶„ì„ ì¤‘ ë…ë¦½ì„± ê²€ì • ìˆ˜í–‰

### 2.1 ê°€ì„¤ìˆ˜ë¦½

- H0: ì„±ì ê³¼ í•™ê³¼ëŠ” ë…ë¦½ì´ë‹¤
- H1: ì„±ì ê³¼ í•™ê³¼ëŠ” ë…ë¦½ì´ ì•„ë‹ˆë‹¤

### 2.2 í•™ê³¼ì™€ ì„±ì ì´ ë…ë¦½ì¼ ë•Œ, ê¸°ëŒ€ê°’

````python
from scipy import stats
statistics, p_value, dof, expected_freq = stats.chi2_contingency(observed=table)
pd.DataFrame(expected_freq, index=index, columns=table.columns)
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice3/13.png?raw=true" width="500" height="150"></p>

### 2.3 ê²€ì •í†µê³„ëŸ‰ì„ êµ¬í•˜ê³  ê°€ì„¤ ì±„íƒ

````python
print("ê²€ì •í†µê³„ëŸ‰:",statistics)
print("p-value:", p_value)
````

````
ê²€ì •í†µê³„ëŸ‰: 10.199441509990177
p-value: 0.03719883770303157
````

- p-valueê°€ 0.05 ë³´ë‹¤ ì‘ìœ¼ë¯€ë¡œ ëŒ€ë¦½ê°€ì„¤ ì±„íƒ
- í•™ê³¼ì™€ ì„±ì ì€ ë…ë¦½ì´ ì•„ë‹˜

## 3. ì‹œê³„ì—´ ë¶„ì„

````python
import pandas as pd
covid = pd.read_csv("https://raw.githubusercontent.com/ADPclass/ADP_book_ver01/main/data/%EC%84%9C%EC%9A%B8%ED%8A%B9%EB%B3%84%EC%8B%9C%20%EC%BD%94%EB%A1%9C%EB%82%9819.csv")
covid
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice3/14.png?raw=true" width="900" height="350"></p>

### 3.1 ACF ì‚¬ìš©í•´ì„œ distanceë¥¼ ê³„ì‚°í•˜ì‹œì˜¤

````python
covid1 = covid[covid.columns.difference(['ë‚ ì§œ'])]

import statsmodels.api as sm

def acf(x, n_lags):
    return sm.tsa.stattools.acf(x, nlags =n_lags)
# Max ACF lags
n_lags = len(covid1)
lag_arr = np.repeat(n_lags, covid1.shape[1])
acf_list = list(map(acf, covid1.transpose().to_numpy(), lag_arr))
acf_df = pd.DataFrame(acf_list).transpose()
acf_df.columns = covid1.columns
acf_df
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice3/15.png?raw=true" width="900" height="350"></p>

- sm.tsa.stattools.acfë¥¼ ì‚¬ìš©í•´ ACF distanceë¥¼ ê³„ì‚°
- ì´ë•Œ lagëŠ” ë°ì´í„°ì˜ ê´€ì¸¡ ê°œìˆ˜

````python
acf_df =acf_df.T
acf_df.head()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice3/16.png?raw=true" width="900" height="200"></p>

### 3.2 ê³„ì¸µì  êµ°ì§‘ ë¶„ì„ì„ ìœ„í•´ ë´ë“œë¡œê·¸ë¨ì„ ì‘ì„±

- ACF distance ê³„ì‚°ê°’ìœ¼ë¡œ ê³„ì¸µì  êµ°ì§‘ë¶„ì„ì„ ìˆ˜í–‰
- acf_dfì˜ ì¸ë±ìŠ¤ë¥¼ labelë¡œ ì§€ì •, labelì€ ë´ë“œë¡œê·¸ë¨ì˜ ë…¸ë“œ ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©ë¨
- schì˜ linkage( )ì— acf_dfë¥¼ ì…ë ¥í•˜ì—¬ ê³„ì¸µì  êµ°ì§‘ë¶„ì„ì„ ìˆ˜í–‰
    - methodëŠ” â€˜averageâ€™ë¥¼ ì„ íƒí•˜ì—¬ í‰ê· ì—°ê²°ë²•ì„ êµ¬í˜„
    - ì„ê³—ê°’(cut-off)ëŠ” linkage matrix 3ë²ˆì§¸ ì—´ì˜ ìµœëŒ“ê°’ì˜ 30%ë¡œ ì„¤ì • 
- linkage matrixëŠ” sch.linkage( )ì˜ ê²°ê³¼ë¡œ ë°˜í™˜ë˜ëŠ” í–‰ë ¬, ê° ì—´ì€ ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì§•ì´ ìˆìŒ<br><br>
â‘  ì²« ë²ˆì§¸ ì—´ : í•œ í´ë˜ìŠ¤ì˜ ì¸ë±ìŠ¤<br>
â‘¡ ë‘ ë²ˆì§¸ ì—´ : ë‹¤ë¥¸ í´ë˜ìŠ¤ì˜ ì¸ë±ìŠ¤<br>
â‘¢ ì„¸ ë²ˆì§¸ ì—´ : í´ë˜ìŠ¤ ì‚¬ì´ì˜ ê±°ë¦¬<br>
â‘£ ë„¤ ë²ˆì§¸ ì—´ : í´ë˜ìŠ¤ë¥¼ ë§Œë“œëŠ” ë° ì‚¬ìš©ëœ ë°ì´í„° í¬ì¸íŠ¸ì˜ ê°œìˆ˜<br>

````python
import scipy.cluster.hierarchy as sch
from matplotlib import font_manager, rc
# ìœˆë„ìš° í°íŠ¸ ìœ„ì¹˜
# C:\Windows\Fonts
font_path ="/Library/Fonts/Arial Unicode.ttf"
font = font_manager.FontProperties(fname =font_path).get_name()
rc('font', family =font)

plt.figure(figsize=(15, 5))
label = acf_df.index
dend1=sch.linkage(acf_df, method ='average')
cutoff =0.5 *max(dend1[:,2])
dend_res1=sch.dendrogram(dend1, color_threshold=cutoff, labels=label)
plt.show()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice3/17.png?raw=true" width="900" height="350"></p>