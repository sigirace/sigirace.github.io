---
layout: single
title:  'ADP ì‹¤ê¸° ì—°ìŠµë¬¸ì œ (2)'
toc: true
categories: [ADP]
tags: [Outlier, Over Sampling, Under Sampling, PCA, Accosiate Analysis, Linear Programming]

---

ë³¸ ê²Œì‹œë¬¼ì€ ADP ì‹¤ê¸°ì˜ ì—°ìŠµë¬¸ì œ í’€ì´ì— ëŒ€í•œ ê²ƒì´ë‹¤.
{: .notice}

# ë¨¸ì‹ ëŸ¬ë‹

## 1. ì‹œê°í™” í¬í•¨ EDA ìˆ˜í–‰

````python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
df1 = pd.read_csv("https://raw.githubusercontent.com/ADPclass/ADP_book_ver01/main/data/diabetes_for_test.csv")
````

#### 1.1.1 ë°ì´í„° ê°œìš”

````
df1
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice2/1.png?raw=true" width="900" height="350"></p>

````python
df1.describe()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice2/2.png?raw=true" width="900" height="250"></p>

````
df1.info()
````

````
Data columns (total 9 columns):
 #   Column                    Non-Null Count  Dtype  
---  ------                    --------------  -----  
 0   Pregnancies               768 non-null    int64  
 1   Glucose                   768 non-null    int64  
 2   BloodPressure             768 non-null    int64  
 3   SkinThickness             768 non-null    int64  
 4   Insulin                   768 non-null    int64  
 5   BMI                       768 non-null    float64
 6   DiabetesPedigreeFunction  768 non-null    float64
 7   Age                       768 non-null    int64  
 8   Outcome                   768 non-null    int64  
dtypes: float64(2), int64(7)
````

ğŸ“ **ë°ì´í„° ê°œìš” í•´ì„**
- null ê°’ì´ ì—†ëŠ” ë°ì´í„° ì…‹
- ìˆ˜ì¹˜í˜• ë°ì´í„°ëŠ” ì´ìƒì¹˜ê°€ ìˆëŠ”ì§€ ìœ ì˜í•´ì„œ ë´ì•¼ í•¨
- outcomeì€ Intí˜•ì´ì§€ë§Œ categorical ë³€ìˆ˜ì„
- ê° ì»¬ëŸ¼ë³„ ë²”ìœ„ì˜ ì°¨ì´ê°€ ìˆê¸° ë•Œë¬¸ì— ìŠ¤ì¼€ì¼ë§ ê³ ë ¤í•´ì•¼ í•¨

#### 1.1.2 ì‹œê°í™”

````python
fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(16, 16))

columns = df1.columns.to_list()

for i, column in enumerate(columns):
    row = i // 3
    col = i % 3
    axes[row, col].hist(df1[column], bins=20, color='skyblue', alpha=0.7)
    axes[row, col].set_title(f'Histogram of {column}')
    axes[row, col].set_xlabel(column)
    axes[row, col].set_ylabel('Frequency')

plt.tight_layout()
plt.show()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice2/3.png?raw=true" width="900" height="800"></p>

````python
# ì—°ì†í˜•
continuous_columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']

# ë²”ì£¼í˜•
categorical_columns = ['Outcome']
````

ğŸ‘€ **ì—°ì†í˜•-íˆìŠ¤í† ê·¸ë¨**

````python
fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(15, 4))

for i, column in enumerate(continuous_columns):

    row = i // 4
    col = i % 4
    df1[column].plot(kind='hist', bins=20, ax=axes[row, col], color='skyblue', edgecolor='black')
    axes[row, col].set_title(f'Histogram of {column}')
    axes[row, col].set_xlabel(column)
    axes[row, col].set_ylabel('Frequency')

plt.tight_layout()

plt.show()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice2/4.png?raw=true" width="900" height="350"></p>

ğŸ‘€ **ì—°ì†í˜•-ë°•ìŠ¤í”Œë¡¯**

````python
fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(15, 4))

for i, column in enumerate(continuous_columns):

    row = i // 4
    col = i % 4
    sns.boxplot(x=df1[column], ax=axes[row, col], color='skyblue')
    axes[row, col].set_title(f'Box plot of {column}')
    axes[row, col].set_xlabel(column)
    axes[row, col].set_ylabel('Frequency')

plt.tight_layout()
plt.show()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice2/5.png?raw=true" width="900" height="350"></p>

ğŸ‘€ **ë²”ì£¼í˜•-ë§‰ëŒ€ ê·¸ë˜í”„**

````python
fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(3, 3))

for i, column in enumerate(categorical_columns):

    df1[column].value_counts().sort_index().plot(kind='bar', ax=axes, color='skyblue')
    axes.set_title(f'Bar Plot of {column}')
    axes.set_xlabel(column)
    axes.set_ylabel('Frequency')    

plt.tight_layout()
plt.show()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice2/6.png?raw=true" width="300" height="350"></p>

ğŸ‘€ **ê·¸ë£¹ë³„ ë°ì´í„°**

- classification ë¬¸ì œì´ê¸° ë•Œë¬¸ì— ê·¸ë£¹ë³„ë¡œ ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ì—¬ íŒŒì•…

````python
diabetes = df1.groupby('Outcome').mean()
diabetes
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice2/7.png?raw=true" width="900" height="100"></p>

- Outcomeì— ë”°ë¥¸ ê·¸ë£¹ë³„ í‰ê·  ë°ì´í„°

````python
fig, axes = plt.subplots(2, 4, figsize=(16, 12))

columns = diabetes.columns.to_list()

for i, column in enumerate(columns):
    row = i // 4
    col = i % 4
    sns.barplot(x=diabetes.index, y=column, data=diabetes, ax=axes[row, col])
    axes[row, col].set_title(f'Average {column}')
    axes[row, col].set_xlabel("Outcome")
    axes[row, col].set_ylabel(f'Average {column}')

plt.tight_layout()
plt.show()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice2/8.png?raw=true" width="900" height="500"></p>

ğŸ‘€ **ìƒê´€ê´€ê³„ ì‹œê°í™”**

````python
df_cor = df1.drop(columns=["Outcome"]).corr(method='pearson')
sns.heatmap(df_cor,
             xticklabels = df_cor.columns,
             yticklabels = df_cor.columns,
             cmap='RdBu_r',
             annot=True, 
             linewidth=3)
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice2/9.png?raw=true" width="900" height="500"></p>

ğŸ“ **ì‹œê°í™” ê²°ê³¼ í•´ì„**
- ì—°ì†í˜• ë³€ìˆ˜ì˜ íˆìŠ¤í† ê·¸ë¨ì„ í†µí•´ Insulinê³¼ Ageì˜ ë¶„í¬ê°€ í•œìª½ì— ë§ì´ ëª°ë ¤ìˆìŒì„ ì•Œ ìˆ˜ ìˆìŒ
- ì—°ì†í˜• ë³€ìˆ˜ì˜ ë°•ìŠ¤í”Œë¡¯ì„ í†µí•´ Outlierë“¤ì´ ì¡´ì¬í•¨ì„ í™•ì¸
- ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ë§‰ëŒ€ê·¸ë˜í”„ë¥¼ í†µí•´ í´ë˜ìŠ¤ê°€ ë¶ˆê· í˜•í•¨ì„ í™•ì¸
- Outcomeì´ 1ì¼ë•Œ ëŒ€ë¶€ë¶„ì˜ ë°ì´í„°ê°€ ë†’ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ê²½í–¥ì´ ìˆìŒ
- ìƒê´€ê´€ê³„ ë¶„ì„ì„ í†µí•´ 0.9 ì´ìƒì˜ ë†’ì€ ê°’ì„ ê°€ì§€ëŠ” ë³€ìˆ˜ê°€ ì—†ìŒì„ í™•ì¸í•˜ì˜€ê¸°ì— ì„ í˜• ëª¨ë¸ ì‚¬ìš©ì‹œ ëª¨ë“  ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ë„ ë¬´ë°©í•  ê²ƒìœ¼ë¡œ íŒë‹¨

### 1.2 ì´ìƒì¹˜ë¥¼ ì‹ë³„í•˜ê³  ì²˜ë¦¬

#### 1.2.1 ì´ìƒì¹˜ ì‹ë³„

ğŸ‘€ **ì´ìƒì¹˜ ì‹œê°í™”-ë°•ìŠ¤í”Œë¡¯**

````python
X = df1.drop(columns=['Outcome'])
df_v1 = pd.melt(X ,var_name='col', value_name='value')
df_v1
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice2/10.png?raw=true" width="300" height="350"></p>

````python
plt.figure(figsize = (15, 7))
sns.boxplot(x ='col', y ='value', data = df_v1)
plt.xticks(range(8), X.columns)
plt.show()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice2/11.png?raw=true" width="900" height="350"></p>

ğŸ‘€ **ì´ìƒì¹˜ ë¹„ìœ¨ í™•ì¸**

````python
out_Glucose = df1[df1.Glucose == 0]
out_Blood = df1[df1.BloodPressure == 0]
out_Age = df1[df1.Age > 100]

sorted_df = df1.sort_values(by='Insulin', ascending=False)
total_rows = len(sorted_df)
top_percent = int(total_rows * 0.005)
out_Insulin = sorted_df.head(top_percent)

df_out = pd.DataFrame({"num": [len(out_Glucose), len(out_Blood), len(out_Age), len(out_Insulin)], "index":["Glucose", "BloodPressure", "Age", "Insulin"]})
df_out['percent'] = df_out.apply(lambda x: round(x.num/len(df1), 3)*100, axis=1)
df_out.set_index("index")
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice2/12.png?raw=true" width="300" height="150"></p>

ğŸ“ **ì´ìƒì¹˜ ì‹ë³„ ê²°ê³¼ í•´ì„**
- AGEë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ë°ì´í„°ë“¤ì€ ì—°ì†ì ì¸ ê°’ì„ ê°€ì§€ê¸°ì— ì •í™•í•œ ì´ìƒì¹˜ë¥¼ íŒŒì•…í•˜ê¸° ìœ„í•´ì„œëŠ” í˜„ì—…ì˜ ì˜ê²¬ì´ í•„ìš”í•˜ë‚˜ ê°œì¸ì ì¸ íŒë‹¨ìœ¼ë¡œ ì´ìƒì¹˜ ì •ì˜
   - Glucose, BloodPressure, BMI ë“± 0ì´ ë  ìˆ˜ ì—†ëŠ” ê°’ì€ ì´ìƒì¹˜ë¡œ íŒë‹¨
   - Insulineì€ ìƒìœ„ 0.5%ì¸ ê²½ìš° ì´ìƒì¹˜ë¡œ íŒë‹¨
   - AGEëŠ” 100ì´ ì´ìƒì¸ ê²½ìš° ì´ìƒì¹˜ë¡œ íŒë‹¨
- ì´ìƒì¹˜ ì‹ë³„ ê²°ê³¼ BloodPressureë¥¼ ì œì™¸í•œ ê°’ë“¤ì€ ë§¤ìš° ì‘ì€ ë¹„ìœ¨ì´ê¸°ì— ì œê±°
- BloodPressureëŠ” Nullë¡œ ëŒ€ì²´ í›„ KNNì„ ì‚¬ìš©í•˜ì—¬ ì´ìƒì¹˜ ì²˜ë¦¬

#### 1.2.2 ì´ìƒì¹˜ ì²˜ë¦¬

ğŸ‘€ **ì¸ë±ìŠ¤ë¥¼ í†µí•œ ì´ìƒì¹˜ ì œê±° ë° ëŒ€ì²´**

````python
out_index = set(out_Glucose.index.tolist()).union(set(out_Age.index.tolist()))
out_index = list(out_index.union(set(out_Insulin.index.tolist())))
df1 = df1.drop(out_index)
````

- ì´ìƒì¹˜ ì œê±°

````python
out_blood_index = list(set(out_Blood.index.tolist()).difference(set(out_index)))
df1.loc[out_blood_index, 'BloodPressure'] = None
df1.reset_index(drop=True, inplace=True)
````

- ì´ìƒì¹˜ ëŒ€ì²´(=ê²°ì¸¡ì¹˜ ìƒì„±)

ğŸ‘€ **KNNì„ ì´ìš©í•œ ê²°ì¸¡ì¹˜ ëŒ€ì²´**

````python
from sklearn.impute import KNNImputer

imputer = KNNImputer()
df_filled = imputer.fit_transform(df1)
df_filled = pd.DataFrame(df_filled, columns=df1.columns)
df1[df1.columns] = df_filled
df1.isna().sum()
````

````
Pregnancies                 0
Glucose                     0
BloodPressure               0
SkinThickness               0
Insulin                     0
BMI                         0
DiabetesPedigreeFunction    0
Age                         0
Outcome                     0
````

ğŸ‘€ **ì´ìƒì¹˜ ì²˜ë¦¬ ì‹œê°í™”-ë°•ìŠ¤í”Œë¡¯**

````python
X = df1.drop(columns=['Outcome'])
df_v1 = pd.melt(X ,var_name='col', value_name='value')
df_v1

plt.figure(figsize = (15, 7))
sns.boxplot(x ='col', y ='value', data = df_v1)
plt.xticks(range(8), X.columns)
plt.show()
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice2/13.png?raw=true" width="900" height="350"></p>

## 2. í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬

ğŸ‘€ **í´ë˜ìŠ¤ ë¶ˆê· í˜• ì‹ë³„**

````python
df1['Outcome'].value_counts()
````

````
0.0    492
1.0    265
Name: Outcome, dtype: int64
````

â˜€ï¸ **OverSampling**

````python
from imblearn.over_sampling import RandomOverSampler 

X = df1.drop(['Outcome'],axis=1)
y = df1[['Outcome']]
ros = RandomOverSampler()
X_upsampling,y_upsampling = ros.fit_resample(X,y)
print('ê¸°ì¡´ì˜ íƒ€ê¹ƒ ë¶„í¬')
print(df1['Outcome'].value_counts()/len(df1))
print('-'*10)
print('upsamplingì˜ íƒ€ê¹ƒ ë¶„í¬')
print(y_upsampling['Outcome'].value_counts()/len(y_upsampling))
````

````
ê¸°ì¡´ì˜ íƒ€ê¹ƒ ë¶„í¬
0.0    0.649934
1.0    0.350066
Name: Outcome, dtype: float64
----------
upsamplingì˜ íƒ€ê¹ƒ ë¶„í¬
1.0    0.5
0.0    0.5
Name: Outcome, dtype: float64
````

â˜€ï¸ **UnderSampling**

````python
from imblearn.under_sampling import RandomUnderSampler
rus = RandomOverSampler()
X_undersampling,y_undersampling = rus.fit_resample(X,y)
print('ê¸°ì¡´ì˜ íƒ€ê¹ƒ ë¶„í¬')
print(df1['Outcome'].value_counts()/len(df1))
print('-'*10)
print('undersamplingì˜ íƒ€ê¹ƒ ë¶„í¬')
print(y_undersampling['Outcome'].value_counts()/len(y_undersampling))
````

````
ê¸°ì¡´ì˜ íƒ€ê¹ƒ ë¶„í¬
0.0    0.649934
1.0    0.350066
Name: Outcome, dtype: float64
----------
undersamplingì˜ íƒ€ê¹ƒ ë¶„í¬
1.0    0.5
0.0    0.5
Name: Outcome, dtype: float64
````

## 3. ëª¨ë¸ë§

#### 3.1 ë‹¤ì–‘í•œ ëª¨ë¸ë§ ê²°ê³¼ ë„ì¶œ

````python
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
import sklearn.svm as svm

log = LogisticRegression()
xgb = XGBClassifier(random_state=0)
svm_clf =svm.SVC(kernel ='linear')

from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score
import time
from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=0)
## 5ê°œì˜ ê²½ìš°ì˜ ìˆ˜ë¡œ ë¶„í• í•˜ì—¬ ê²€ì¦ 
kfold = KFold()

def model_result(model):
    pred_li =[]
    
    for train_index,test_index in kfold.split(X):
        X_train,X_test = X.iloc[train_index,:],X.iloc[test_index,:]
        y_train,y_test = y.iloc[train_index,:],y.iloc[test_index,:]

        X_train_resample,y_train_resample = smote.fit_resample(X_train,y_train)

        start = time.time()
        model.fit(X_train_resample,y_train_resample)
        end = time.time()

        pred = model.predict(X_test)
        pred_li.append(accuracy_score(pred,y_test['Outcome']))

    ## ë§ˆì§€ë§‰ ë°ì´í„° í•™ìŠµ ì†ë„ 
    print(f"{end - start:.5f} sec")
    ## 5ê°œì˜ trainë°ì´í„°ì— ëŒ€í•œ ì •í™•ë„ì˜ í‰ê·  ê°’ 
    print(np.mean(pred_li))
````

````python
model_result(log)
````

````
0.01135 sec
0.7306117113976995
````

````
model_result(xgb)
````

````
0.18677 sec
0.7450766817706518
````

````
model_result(svm_clf)
````

````
1.37559 sec
0.7557162774485884
````

### 3.2 ì°¨ì›ì¶•ì†Œë¥¼ ì‚¬ìš©í•œ ëª¨ë¸ë§

â˜€ï¸ **PCAë¥¼ í†µí•œ ì°¨ì› ì¶•ì†Œ**

````python
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_train = train_test_split(X,y, stratify=y, test_size=0.3, random_state=2022)

scaler = StandardScaler()
X_train_s = scaler.fit_transform(X_train)
pca = PCA(n_components=8)
X_train_pca = pca.fit(X_train_s)
print(pca.explained_variance_ratio_)

for i in range(len(pca.explained_variance_ratio_)):
    print(i, pca.explained_variance_ratio_[:i].sum())
````

````
[0.25906554 0.22771341 0.12534153 0.11213758 0.10048032 0.07434416
 0.05278052 0.04813696]
0 0.0
1 0.2590655358872176
2 0.4867789432683496
3 0.6121204775600299
4 0.7242580556898799
5 0.824738371243592
6 0.8990825273257718
7 0.9518630446620266
````

- ì£¼ì„±ë¶„ ë¶„ì„ì„ í†µí•´ 5ê°œì˜ ì£¼ì„±ë¶„ ì‚¬ìš©ì‹œ ì´ ë°ì´í„°ì˜ 82%ë¥¼ í‘œí˜„í•  ìˆ˜ ìˆìŒì„ í™•ì¸

````python
def pca_model_result(model):
    pred_li =[]
    smote = SMOTE(random_state=0)
    
    for train_index,test_index in kfold.split(X):
        X_train,X_test = X.iloc[train_index,:],X.iloc[test_index,:]
        y_train,y_test = y.iloc[train_index,:],y.iloc[test_index,:]

        X_train_resample,y_train_resample = smote.fit_resample(X_train,y_train)

        scaler = StandardScaler()
        X_train_res_s = scaler.fit_transform(X_train_resample)
        X_test_s = scaler.transform(X_test)

        pca = PCA(n_components=5)
        X_train_pca = pca.fit_transform(X_train_res_s)
        X_test_pca = pca.transform(X_test_s)

        start = time.time()
        model.fit(X_train_pca,y_train_resample)
        end = time.time()

        pred = model.predict(X_test_pca)
        pred_li.append(accuracy_score(pred,y_test['Outcome']))


    print(f"{end - start:.5f} sec")
    print(np.mean(pred_li))
````

````
pca_model_result(log)
````

````
0.00185 sec
0.7319100731962357
````

````
pca_model_result(xgb)
````

````
0.20892 sec
0.7107877309166957
````

````
pca_model_result(svm_clf)
````

````
0.01554 sec
0.7279365632624608
````

- ì˜ˆì¸¡ ì„±ëŠ¥ì€ ë–¨ì–´ì¡Œì§€ë§Œ ìˆ˜í–‰ ì†ë„ê°€ ë¹¨ë¼ì§ì„ í™•ì¸

# í†µê³„ë¶„ì„

## 1. ì—°ê´€ì„± ë¶„ì„

### ìƒí’ˆ aì™€ bê°€ ìˆì„ ë•Œ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ë§¤ íŒ¨í„´ì´ ìˆë‹¤ê³  í•œë‹¤. 
> [â€˜aâ€™,â€˜aâ€™,â€˜bâ€™,â€˜bâ€™,â€˜aâ€™,â€˜aâ€™,â€˜aâ€™,â€˜aâ€™,â€˜bâ€™,â€˜bâ€™,â€˜bâ€™,â€˜bâ€™,â€˜bâ€™,â€˜aâ€™,â€˜aâ€™,â€˜bâ€™,â€˜bâ€™,â€˜aâ€™,â€˜bâ€™,â€˜bâ€™]

### 1.1 êµ¬ë§¤ íŒ¨í„´ìœ¼ë¡œ ë³¼ ë•Œ ë‘ ìƒí’ˆì´ ì—°ê´€ì´ ìˆëŠ”ì§€ ê°€ì„¤ì„ ì„¸ìš°ê³  ê²€ì •í•˜ì‹œì˜¤.

âœï¸ **ë¬¸ì œ ì •ë¦¬**
- ì´ì§„í•­ëª©ì— ëŒ€í•œ ì—°ê´€ì„±ì„ ê²€ì •í•˜ëŠ” ê²ƒìœ¼ë¡œ one sample run testë¥¼ ìˆ˜í–‰í•¨

ğŸ“ **ê°€ì„¤ ìˆ˜ë¦½**
- H0: ì—°ì†ì ì¸ ê´€ì¸¡ì´ ì—°ê´€ì„±ì´ ì—†ë‹¤.
- H1: ì—°ì†ì ì¸ ê´€ì¸¡ì´ ì—°ê´€ì„±ì´ ìˆë‹¤.

````python
import pandas as pd 
data = ['a','a','b','b','a','a','a','a','b','b','b','b','b','a','a','b','b','a','b','b']
test_df = pd.DataFrame(data,columns=['product'])
test_df.loc[test_df['product']=='a','product'] =1
test_df.loc[test_df['product']=='b','product'] =0
test_df['product']
````

````
0     1
1     1
2     0
3     0
4     1
5     1
6     1
7     1
8     0
9     0
10    0
11    0
12    0
13    1
14    1
15    0
16    0
17    1
18    0
19    0
````

````python
from statsmodels.sandbox.stats.runs import runstest_1samp
runstest_1samp(test_df['product'])
````

````
(-1.1144881152070183, 0.26506984027306035)
````

ğŸ“ **one sample run test í•´ì„**
- í†µê³„ëŸ‰: -1.1144881152070183
- p-value: 0.26506984027306035
- p-valueê°€ 0.05ë³´ë‹¤ í¬ë¯€ë¡œ ê·€ë¬´ê°€ì„¤ ì±„íƒ
- êµ¬ë§¤ ì´ë ¥ì— ì—°ê´€ì„±ì´ ì—†ìŒ

## 2. ì½”ë”© í…ŒìŠ¤íŠ¸

### ì œí’ˆ 1, 2ë¥¼ ë§Œë“œëŠ” ë° ì¬ë£Œ a, b, cê°€ ì¼ë¶€ ì‚¬ìš©ë˜ë©°, ì œí’ˆ 1ê³¼ 2ë¥¼ ë§Œë“¤ ë•Œ 12ë§Œì›ê³¼ 18ë§Œì›ì„ ë²Œ ìˆ˜ ìˆë‹¤. ì¬ë£ŒëŠ” í•œì •ì ìœ¼ë¡œ ì£¼ì–´ì§€ëŠ”ë°, ì´ë•Œ ìµœëŒ€ ìˆ˜ìµì„ ë‚¼ ìˆ˜ ìˆì„ ë•Œì˜ ì œí’ˆ 1ê³¼ ì œí’ˆ 2ì˜ ê°œìˆ˜ë¥¼ êµ¬í•˜ë¼.

> ì¬ë£Œ ê³µê¸‰ëŸ‰ â˜ {a:1300, b:1000, c:1200}

````python
data = pd.DataFrame({"a": [20, 40], "b":[20, 30], "c":[20,30]}, index=[1,2])
data
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/adp/problem/practice2/14.png?raw=true" width="200" height="150"></p>

âœï¸ **ë¬¸ì œ ì •ì˜**

- ì„ í˜• ê³„íšë²•ìœ¼ë¡œ í’€ì´
- ì œí’ˆ 1: 12ë§Œì› / ì œí’ˆ 2: 18ë§Œì›

````python
from pulp import LpProblem, LpVariable, LpMaximize

# ë¬¸ì œ ì •ì˜ (ìµœëŒ€í™” ë¬¸ì œ)
prob = LpProblem("MaximizeProfit", LpMaximize)

# ë³€ìˆ˜ ì •ì˜ (ì œí’ˆ 1ê³¼ ì œí’ˆ 2ì˜ ê°œìˆ˜, 0 ì´ìƒì˜ ì •ìˆ˜)
x1 = LpVariable("Product1", 0, None, 'Integer')
x2 = LpVariable("Product2", 0, None, 'Integer')

# ëª©ì í•¨ìˆ˜ ì¶”ê°€ (ì œí’ˆ 1ê³¼ ì œí’ˆ 2ë¡œë¶€í„°ì˜ ìˆ˜ìµ ìµœëŒ€í™”)
prob += 120000 * x1 + 180000 * x2

# ì œì•½ì¡°ê±´ ì¶”ê°€ (ì¬ë£Œ a, b, cì˜ ê³µê¸‰ëŸ‰ í•œì •)
prob += 20 * x1 + 40 * x2 <= 1300, "Material A Constraint"
prob += 20 * x1 + 30 * x2 <= 1000, "Material B Constraint"
prob += 20 * x1 + 30 * x2 <= 1200, "Material C Constraint"

# ë¬¸ì œ í’€ì´
prob.solve()

# ê²°ê³¼ ì¶œë ¥
print("Product1: ", int(x1.varValue))
print("Product2: ", int(x2.varValue))
print("Max Profit: ", int(prob.objective.value()))
````

````
Product1:  5
Product2:  30
Max Profit:  6000000
````

