---
layout: single
title:  'MLOps Model Development (2) Build End to end prototype'
toc: true
categories: [MLOps]
tags: [Model Development]

---

ë³¸ ê²Œì‹œë¬¼ì€ W&Bê°€ ì œê³µí•œ [MLOpsì˜ Model Development](chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://import.cdn.thinkific.com/705742/courses/2069435/MLOpsAHolisticApproach1121-221121-125813.pdf)ì— ëŒ€í•œ ë‚´ìš©ì„ ê¸°ìˆ í•œë‹¤.
{: .notice}

## 1. Introduce

> Model developmentë¥¼ ìœ„í•´ W&Bì˜ ì—¬ëŸ¬ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ End to End Prototypeì„ ìƒì„±í•´ ë´„

### 1.1 Agenda

ğŸ“ **Build to End to End Prototype**

Prototypeì„ ì„¤ê³„í•˜ê¸° ìœ„í•œ ë‹¨ê³„ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.

1. Understand the Business Context
2. Frame the Data Science Problem
3. Explore & Understand Your Data
4. Establish Baseline Metrics & Models
5. Communicate Your Result

### 1.2 Case Study

ğŸ“ **Autonomous Vehicles Perception**

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/mlops/ete/1.png?raw=true" width="900" height="350"></p>

- ììœ¨ì£¼í–‰ì„ ìœ„í•œ ì¸ì‹, ì˜ˆì¸¡, ë™ì‘ ì¤‘ ì¸ì‹ì— ì´ˆì ì„ ë§ì¶¤
- BDD100Kë¼ëŠ” ê¸°ì¡´ ë°ì´í„°ì„¸íŠ¸ì˜ ì„œë¸Œì„¸íŠ¸ë¡œ í•™ìŠµ
- Semantic Segmentationì„ ì‚¬ìš©

ğŸ‘€ **Object Detection Vs Semantic Segmentation**

1. **Object Detection (ê°ì²´ ê²€ì¶œ)**:
   - Object detectionì€ ì´ë¯¸ì§€ ë‚´ì—ì„œ ë¬¼ì²´ë¥¼ ê°ì§€í•˜ê³  í•´ë‹¹ ë¬¼ì²´ê°€ ì–´ë””ì— ìˆëŠ”ì§€ë¥¼ ë°”ìš´ë”© ë°•ìŠ¤(bounding box)ë¡œ í‘œì‹œí•œë‹¤.
   - ì´ë¯¸ì§€ì—ì„œ ì—¬ëŸ¬ ë¬¼ì²´ë¥¼ ë™ì‹œì— ê°ì§€í•˜ê³ , ê° ë¬¼ì²´ì˜ ìœ„ì¹˜ì™€ í´ë˜ìŠ¤ë¥¼ ì‹ë³„í•œë‹¤.
2. **Semantic Segmentation (ì˜ë¯¸ì  ë¶„í• )**:
   - Semantic segmentationì€ ì´ë¯¸ì§€ë¥¼ í”½ì…€ ìˆ˜ì¤€ì—ì„œ ë¶„í• í•˜ì—¬ ê° í”½ì…€ì„ íŠ¹ì • í´ë˜ìŠ¤(ë¬¼ì²´ ë˜ëŠ” ë°°ê²½)ë¡œ í• ë‹¹í•œë‹¤.
   - ê° í”½ì…€ì— ëŒ€í•´ í•´ë‹¹ í”½ì…€ì´ ì–´ë–¤ ë¬¼ì²´ì— ì†í•˜ëŠ”ì§€ ë˜ëŠ” ë°°ê²½ì— ì†í•˜ëŠ”ì§€ë¥¼ ì‹ë³„í•œë‹¤.

## 2. EDA

### 2.1 ì˜ì¡´ì„± ì„¤ì¹˜ ë° ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ

````python
# Install dependencies (run once)
!wget https://raw.githubusercontent.com/wandb/edu/main/mlops-001/lesson1/requirements.txt
!wget https://raw.githubusercontent.com/wandb/edu/main/mlops-001/lesson1/params.py
!wget https://raw.githubusercontent.com/wandb/edu/main/mlops-001/lesson1/utils.py
!pip install -r requirements.txt

DEBUG = False # set this flag to True to use a small subset of data for testing

from fastai.vision.all import *
import params

import wandb

URL = 'https://storage.googleapis.com/wandb_course/bdd_simple_1k.zip'
path = Path(untar_data(URL, force_download=True))
path.ls()
````

````
(#3) [Path('/root/.fastai/data/bdd_simple_1k/labels'),Path('/root/.fastai/data/bdd_simple_1k/LICENSE.txt'),Path('/root/.fastai/data/bdd_simple_1k/images')]
````

- ì´ë¯¸ì§€ íŒŒì¼ê³¼ ë¼ë²¨ë§ ê·¸ë¦¬ê³  ë¼ì´ì„ ìŠ¤ íŒŒì¼ì´ ìˆìŒì„ í™•ì¸

### 2.2 W&B Table

````python
run = wandb.init(project=params.WANDB_PROJECT, entity=params.ENTITY, job_type="upload")
raw_data_at = wandb.Artifact(params.RAW_DATA_AT, type="raw_data")
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/mlops/ete/2.png?raw=true" width="900" height="450"></p>

- W&B initialize ë° ìˆ˜í–‰ í™”ë©´

````python
def label_func(fname):
    return (fname.parent.parent/"labels")/f"{fname.stem}_mask.png"

def get_classes_per_image(mask_data, class_labels):
    unique = list(np.unique(mask_data))
    result_dict = {}
    for _class in class_labels.keys():
        result_dict[class_labels[_class]] = int(_class in unique)
    return result_dict

def _create_table(image_files, class_labels):
    "Create a table with the dataset"
    # W&B Table ìƒì„± ì½”ë“œ
    labels = [str(class_labels[_lab]) for _lab in list(class_labels)]
    table = wandb.Table(columns=["File_Name", "Images", "Split"] + labels)
    
    for i, image_file in progress_bar(enumerate(image_files), total=len(image_files)):
        image = Image.open(image_file)
        mask_data = np.array(Image.open(label_func(image_file)))
        class_in_image = get_classes_per_image(mask_data, class_labels)
        table.add_data(
            str(image_file.name),
            wandb.Image(
                    image,
                    masks={
                        "predictions": {
                            "mask_data": mask_data,
                            "class_labels": class_labels,
                        }
                    }
            ),
            "None", # we don't have a dataset split yet
            *[class_in_image[_lab] for _lab in labels]
        )
    
    return table
````

- Interactiveí•˜ê²Œ EDAë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ W&Bì˜ Table ìƒì„±
- [W&B table ê°€ì´ë“œ](https://docs.wandb.ai/ref/weave/table#docusaurus_skipToContent_fallback)
- [W&B artifacts ê°€ì´ë“œ](https://docs.wandb.ai/guides/artifacts#docusaurus_skipToContent_fallback)

````python
raw_data_at.add_file(path/'LICENSE.txt', name='LICENSE.txt')
raw_data_at.add_dir(path/'images', name='images')
raw_data_at.add_dir(path/'labels', name='labels')
image_files = get_image_files(path/"images", recurse=False)
````

- raw_data_atì— íŒŒì¼ ë° í´ë” ì¶”ê°€
- fastaiì˜ get_image_filesì„ ì‚¬ìš©í•´ ì´ë¯¸ì§€ ê°€ì ¸ì˜´

````python
# sample a subset if DEBUG
if DEBUG: image_files = image_files[:10]

table = _create_table(image_files, params.BDD_CLASSES)
raw_data_at.add(table, "eda_table")
run.log_artifact(raw_data_at)
run.finish()
````

- ìƒì„±ëœ í…Œì´ë¸”(eda_table)ì— ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì„í¬íŠ¸

ğŸ“ **Artifacts import ìˆ˜í–‰í™”ë©´**

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/mlops/ete/3.png?raw=true" width="900" height="300"></p>

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/mlops/ete/4.png?raw=true" width="900" height="300"></p>

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/mlops/ete/5.png?raw=true" width="900" height="300"></p>

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/mlops/ete/6.png?raw=true" width="900" height="300"></p>

- W&B Tableì„ í†µí•´ ë°ì´í„°ë¥¼ ì‰½ê²Œ EDA í•  ìˆ˜ ìˆê²Œ ë¨

## 3. Split Dataset

````python
import os, warnings
import pandas as pd
from sklearn.model_selection import StratifiedGroupKFold
warnings.filterwarnings('ignore')

run = wandb.init(project=params.WANDB_PROJECT, entity=params.ENTITY, job_type="data_split")
raw_data_at = run.use_artifact(f'{params.RAW_DATA_AT}:latest')

fnames = os.listdir(path/'images')
groups = [s.split('-')[0] for s in fnames]
orig_eda_table = raw_data_at.get("eda_table")
y = orig_eda_table.get_column('bicycle')
````

- ì´ì „ ì €ì¥í•œ Tableê³¼ ë°ì´í„°ë“¤ì„ ë¶ˆëŸ¬ì˜´

````python
df = pd.DataFrame()
df['File_Name'] = fnames
df['fold'] = -1

cv = StratifiedGroupKFold(n_splits=10)
for i, (train_idxs, test_idxs) in enumerate(cv.split(fnames, y, groups)):
    df.loc[test_idxs, ['fold']] = i
    
df['Stage'] = 'train'
df.loc[df.fold == 0, ['Stage']] = 'test'
df.loc[df.fold == 1, ['Stage']] = 'valid'
del df['fold']
df.Stage.value_counts()
````

````
train    800
valid    100
test     100
Name: Stage, dtype: int64
````

````python
df.to_csv('data_split.csv', index=False)
processed_data_at = wandb.Artifact(params.PROCESSED_DATA_AT, type="split_data")
processed_data_at.add_file('data_split.csv')
processed_data_at.add_dir(path)
data_split_table = wandb.Table(dataframe=df[['File_Name', 'Stage']])
join_table = wandb.JoinedTable(orig_eda_table, data_split_table, "File_Name")
processed_data_at.add(join_table, "eda_table_data_split")

run.log_artifact(processed_data_at)
run.finish()
````

- Train, Validation, Testë¡œ ë¶„ë¦¬ëœ ë°ì´í„°ë¥¼ ë‹¤ì‹œ Artifacts ë° Tableì— ì €ì¥

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/mlops/ete/7.png?raw=true" width="900" height="300"></p>

## 4. Baseline Model

````python
from fastai.callback.wandb import WandbCallback
from utils import get_predictions, create_iou_table, MIOU, BackgroundIOU, \
                  RoadIOU, TrafficLightIOU, TrafficSignIOU, PersonIOU, VehicleIOU, BicycleIOU

train_config = SimpleNamespace(
    framework="fastai",
    img_size=(180, 320),
    batch_size=8,
    augment=True, # use data augmentation
    epochs=10, 
    lr=2e-3,
    pretrained=True,  # whether to use pretrained encoder
    seed=42,
)

set_seed(train_config.seed, reproducible=True)
run = wandb.init(project=params.WANDB_PROJECT, entity=params.ENTITY, job_type="training", config=train_config)
````

- configë¥¼ í†µí•´ ì‹¤í—˜ì˜ ì¡°ê±´ì„ ì„¤ì •

````python
processed_data_at = run.use_artifact(f'{params.PROCESSED_DATA_AT}:latest')
processed_dataset_dir = Path(processed_data_at.download())
df = pd.read_csv(processed_dataset_dir / 'data_split.csv')
````

- ì•ì„œ ì €ì¥ëœ artifactsë¥¼ ì‚¬ìš©í•´ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜´

````python
df = df[df.Stage != 'test'].reset_index(drop=True)
df['is_valid'] = df.Stage == 'valid'

# assign paths
df["image_fname"] = [processed_dataset_dir/f'images/{f}' for f in df.File_Name.values]
df["label_fname"] = [label_func(f) for f in df.image_fname.values]
````

- validì™€ testë¥¼ êµ¬ë¶„

````python
def get_data(df, bs=4, img_size=(180, 320), augment=True):
    block = DataBlock(blocks=(ImageBlock, MaskBlock(codes=params.BDD_CLASSES)),
                  get_x=ColReader("image_fname"),
                  get_y=ColReader("label_fname"),
                  splitter=ColSplitter(),
                  item_tfms=Resize(img_size),
                  batch_tfms=aug_transforms() if augment else None,
                 )
    return block.dataloaders(df, bs=bs)
````

- fastaiì˜ datablockì„ ì‚¬ìš©í•´ dataloaders ìƒì„±

````python
config = wandb.config

dls = get_data(df, bs=config.batch_size, img_size=config.img_size, augment=config.augment)

metrics = [MIOU(), BackgroundIOU(), RoadIOU(), TrafficLightIOU(), \
           TrafficSignIOU(), PersonIOU(), VehicleIOU(), BicycleIOU()]

learn = unet_learner(dls, arch=resnet18, pretrained=config.pretrained, metrics=metrics)

callbacks = [
    SaveModelCallback(monitor='miou'),
    WandbCallback(log_preds=False, log_model=True)
]
````

- fastaiì˜ unet_learnerë¥¼ í†µí•´ í•™ìŠµ
- Metric ì¤‘ miouë¥¼ í†µí•´ ëª¨ë¸ í•™ìŠµì„ ëª¨ë‹ˆí„°ë§í•˜ë„ë¡ ì„¤ì •

````python
learn.fit_one_cycle(config.epochs, config.lr, cbs=callbacks)

samples, outputs, predictions = get_predictions(learn)
table = create_iou_table(samples, outputs, predictions, params.BDD_CLASSES)
wandb.log({"pred_table":table})

scores = learn.validate()
metric_names = ['final_loss'] + [f'final_{x.name}' for x in metrics]
final_results = {metric_names[i] : scores[i] for i in range(len(scores))}
for k,v in final_results.items(): 
    wandb.summary[k] = v

wandb.finish()
````

- í•™ìŠµ ë° ê²°ê³¼ ë¡œê¹…

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/mlops/ete/8.png?raw=true" width="900" height="400"></p>

## 5. Future Plan

- ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„  case studyë¥¼ í†µí•´ W&Bì˜ artifactsì™€ tableì„ ì‚¬ìš©í•˜ì—¬ íš¨ê³¼ì ì¸ EDAë¥¼ ìˆ˜í–‰í•˜ì˜€ê³ , baseline ëª¨ë¸ì˜ í•™ìŠµ ê²°ê³¼ë¥¼ ê¸°ë¡í•˜ì˜€ë‹¤.
- ë‹¤ìŒ í¬ìŠ¤íŒ…ì—ì„œëŠ” í˜„ì¬ ë§Œë“¤ì–´ì§„ baseline ëª¨ë¸ì„ developement ì‹œí‚¤ë„ë¡ í•˜ëŠ” ê³¼ì •ì„ ì‚´í´ë³¼ ê²ƒì´ë‹¤.
