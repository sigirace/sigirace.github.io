---
layout: single
title:  'LSTMì˜ ëª¨ë“ ê²ƒ (2) PyTorch ê³µì‹ ë¬¸ì„œë¡œ ë³´ëŠ” êµ¬ì„±ìš”ì†Œ'
toc: true
categories: [Deep Learning]
tags: [lstm, pytorch]
---

ë³¸ ê²Œì‹œë¬¼ì€ [Pytorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)ë¥¼ ì°¸ê³ í•˜ì—¬ LSTMì˜ êµ¬ì„±ìš”ì†Œì— ëŒ€í•´ ì •ë¦¬í•˜ëŠ” ê¸€ì´ë‹¤.
{: .notice}

## 1. Parameters

```python
torch.nn.LSTM(input_size, hidden_size, num_layers, bias, batch_first, dropout, bidirectional, proj_size)
```

### 1.1 input_size / hidden_size

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/pytorch/lstm/lstm_c_4.png?raw=true" width="600" height="300"></p>

- input_sizeëŠ” ì…ë ¥ë˜ëŠ” ë°ì´í„°ì˜ ì°¨ì›ì´ë‹¤. ì…ë ¥ë˜ëŠ” ë°ì´í„°ëŠ” ë³´í†µ (batch_size, sequence_length, input_size)ë¡œ êµ¬ì„±ë˜ë©°, sequence_lengthëŠ” ì‹œê³„ì—´ í˜¹ì€ ë¬¸ì¥ì˜ ê¸¸ì´, input_sizeëŠ” ì‹œê³„ì—´ì— í¬í•¨ëœ feature ìˆ˜ í˜¹ì€ ë‹¨ì–´ì˜ ì„ë² ë”©ì˜ ì°¨ì›ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆë‹¤.

- hidden_sizeëŠ” hidden stateì˜ ì°¨ì›ì´ë‹¤. ì…ë ¥ëœ ë°ì´í„°ê°€ ì—°ì‚°ì„ í†µí•´ ê°€ì§€ê²Œ ë  ì°¨ì›ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆë‹¤.

### 1.2 num_layers

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/pytorch/lstm/lstm_c_5.png?raw=true" width="350" height="350"></p>

- num_layersëŠ” LSTM cellì„ stackí•˜ëŠ” ìˆ˜ì´ë‹¤. ìœ ì˜í•  ì ì€ ì²«ë²ˆì§¸ layerì—ì„œëŠ” inputìœ¼ë¡œ ì…ë ¥ ë°ì´í„°ê°€ ë“¤ì–´ê°€ë‚˜ ë‘ë²ˆì§¸ layerëŠ” inputìœ¼ë¡œ ì²«ë²ˆì§¸ layerì˜ hidden stateê°€ ë“¤ì–´ê°„ë‹¤ëŠ” ê²ƒì´ë‹¤. ë”°ë¼ì„œ ë‘ë²ˆì§¸ lstmì˜ inputê³¼ ì—°ì‚°ë˜ëŠ” weightì˜ ì°¨ì›ì´ ë°”ë€Œê²Œ ëœë‹¤.

### 1.3 bias

- biasëŠ” hidden stateì™€ inputì´ ê° gateì—ì„œ ì„ í˜•ê²°í•©ì‹œ ë”°ë¼ì˜¤ëŠ” ê²ƒìœ¼ë¡œ hidden sateì˜ ì°¨ì›ê³¼ ë™ì¼í•˜ë‹¤.

### 1.4 batch_first

### 1.5 dropout

### 1.6 bidirectional

### 1.7 proj_size

## 2. CLASS

### 2.1 Componenets

- $i_t, f_t, o_t$ : input / forget/ output gateì˜ ì¶œë ¥
- $c_t, g_t$ : cell stateì™€ ì´ë¥¼ êµ¬í•˜ê¸° ìœ„í•œ ì¤‘ê°„ ì—°ì‚°(i_tì™€ element-wise ê³±ì„ ìˆ˜í–‰í•¨)
- $W_i, W_h$ : inputê³¼ hiddenì˜ ì„ í˜•ê²°í•©ì‹œì— ì‚¬ìš©ë˜ëŠ” ê°€ì¤‘ì¹˜
- $b_i, h_i$ : bias

### 2.2 Calculate

ğŸ“ **ì˜ˆì‹œ**

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/pytorch/lstm/lstm_c_6.png?raw=true" width="900" height="500"></p>

> Hidden size: 2, Input size 3, Num layers 1ì¼ë•Œ ê° cellì—ì„œ componentë“¤ì´ ì—°ì‚°ë˜ëŠ” ê³¼ì •

### 1.3 Component Shape

- $x_t$ : [input_size, 1]
- $h_t$ : [hidden_size, 1]
- $W_{i}$
  - at first layer : [hidden_size, input_size]  
  - otherwise : [hidden_size, num_directions * hidden_size] 
  - proj_size > 0 : [hidden_size, proj_size] not at first layer
- $W_{h}$
  - at first layer : [hidden_size, hidden_size]
  - proj_size > 0 : [hidden_size, proj_size]
- $b_i$ : [hidden_size]
- $b_h$ : [hidden_size]

## 3. Inputs

## 4. Outputs

## 5. Variables



