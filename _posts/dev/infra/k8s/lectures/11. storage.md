## Storage

### 👀 볼륨

- 컨테이너가 외부 스토리지에 액세스하고 공유하는 방법
- 포드의 각 컨테이너는 고유의 분리된 파일 시스템 존재
- 볼륨은 포드의 컴포넌트이며 포드의 스펙에 의해 정의
- 독립적인 쿠버네티스 오브젝트가 아니며 스스로 생성, 삭제 불가



### 📍 `emptyDir`

> 파드 안의 컨테이너간 데이터 공유



📒 **gasbugs/count**

```dockerfile
FROM busybox:latest

ADD count.sh /bin/count.sh

ENTRYPOINT /bin/count.sh
```



📒 **count.sh**

```sh
trap "exit" SIGINT
mkdir /var/htdocs

SET=$(seq 0 99999)

for i in $SET

do
	echo "Running loop seq "$i > /var/htdos/index.html
	sleep 10
done
```



📒 **count-httpd.yaml**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: count
spec:
  containers:
  - image: gasbugs/count
    name: html-generator
    volumeMounts:
    - mountPath: /var/htdocs
      name: html
  - image: httpd
    name: web-server
    ports:
    - containerPort: 80
    volumeMounts:
    - name: html
      mountPath: /usr/local/apache2/htdocs
      readOnly: true
  volumes:
  - name: html
    emptyDir: {}
```

- `volume`간의 `name`이 동일해야함
- `readOnly`: 해당 옵션이 붙은 이미지는 쓰기 옵션이 불가능



🪄 **생성 및 확인**

```
kubectl create -f count-httpd.yaml
kubectl get pod -o wide
```

```
NAME                       READY   STATUS    RESTARTS   AGE   IP           NODE                                       NOMINATED NODE   READINESS GATES
count                      2/2     Running   0          11m   10.20.2.21   gke-cluster-1-default-pool-d71ec015-8z29   <none>           <none>
http-go-58576dbbc4-xwbrz   1/1     Running   0          7s    10.20.2.22   gke-cluster-1-default-pool-d71ec015-8z29   <none>           <none>
```



🪄 **http-go**

```
kubectl create deploy http-go --image=gasbugs/http-go
```



🪄 **curl 명령 확인**

```
kubectl exec -it http-go-58576dbbc4-xwbrz -- curl 10.20.2.21
```

```
Running loop seq 74
```

- pod 내부에 html이라는 volume이 생성되어 데이터를 공유하고 있음



### 📍 `hostPath`

> 컨테이너와 노드간의 데이터 공유

- 서로 다른 노드의 포드끼리 데이터 공유는 안됨
- 노드를 모니터링 하는 용도로 사용
- gcp에서는 `fluentdbit`으로 생성되어있음



🪄 **kube-system 확인**

```
kubectl get pod --namespace kube-system
```

```
NAME                                                  READY   STATUS    RESTARTS   AGE
event-exporter-gke-79cd469d79-qj6mb                   2/2     Running   0          2d
fluentbit-gke-cngsv                                   3/3     Running   0          2d
fluentbit-gke-czjm7                                   3/3     Running   0          2d
fluentbit-gke-ttl2z                                   3/3     Running   0          2d
```



🪄 **fluentbit 확인**

```
kubectl get pod fluentbit-gke-ttl2z -n kube-system -o yaml
```

```yaml
...
  volumes:
  - hostPath:
      path: /var/run/google-fluentbit
      type: DirectoryOrCreate
    name: varrungooglefluentbit
  - hostPath:
      path: /var/log
      type: Directory
    name: varlog
  - hostPath:
      path: /var/lib/docker/containers
      type: Directory
    name: varlibdockercontainers
  - hostPath:
      path: /var/lib/google-fluentbit
      type: DirectoryOrCreate
    name: varlibgooglefluentbit
  - hostPath:
      path: /var/lib/google-fluentbit/pos-files
      type: DirectoryOrCreate
    name: varlibgooglefluentbitpos
...
```

- `volumes` 아래에 `hostPath`가 존재함



### 📍 GCE 영구 스토리지

```
gcloud compute disks create --size=[size]GiB --zone=[k8s zone] [storage-name]
```

- GCP의 `compute engine-disk`로 들어가면 볼 수 있음



📒 **mongo-pod-gce.yaml**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: [pod-name]
spec:
  volumes:
  - name: [volume-name]
    gcePersistentDisk:
      pdName: [storage-name]
      fsType: ext4 # linux filesystem 거의 고정
  containers:
  - image: [image-name]
    name: [container-name]
    volumeMounts:
    - name: [volume-name]
      mountPath: [path in container]
    ports:
    - containerPort: [port in container]
      protocol: TCP
```



### 📍 PV & PVC

- 개발자가 인프라의 영역을 몰라도 되게끔함
- `PV(persistentVolume)`: 유지 가능한 디스크, 관리자 영역
- `PVC(PersistentVolumeClaim)`: 사용자가 생성하는 요청
  - 볼륨을 생성할때 상세 내용 대신 `PVC`를 참조함을 명시



📌 **스토리지 추상화**

- **PV(PersistentVolume)**: 클러스터 관리자가 사전에 프로비저닝한 실제 스토리지 (예: NFS, GCP Persistent Disk, AWS EBS 등)를 Kubernetes에 등록합니다. PV는 스토리지 제공자의 세부 정보를 포함합니다.
- **PVC(PersistentVolumeClaim)**: 개발자가 필요로 하는 스토리지 요구 사항(크기, 접근 모드 등)을 정의하여 클레임합니다. PVC는 사용자가 PV의 내부 세부 사항을 알 필요 없이 필요한 스토리지를 요청할 수 있도록 합니다.



📌 **장점**

- 사용자(PVC 요청자)는 스토리지의 물리적인 세부 사항(GCP, AWS, NFS 등)을 몰라도 됩니다.
- 관리자는 다양한 스토리지를 PV로 등록하고 Kubernetes가 PVC 요청에 따라 자동으로 PV를 매칭하도록 할 수 있습니다.



📒 **mongo-pvc.yaml**

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: [pvc-name] # storage와 연결될 pod에 등록될 이름
spec:
  resources:
    requests:
      storage: [capacity] # 요청하는 스토리지 양
  accessModes:
  - ReadWriteOnce
  storageClassName: "" # 동적 프로비저닝에서 사용
```



📒 **mongo-pv.yaml**

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: [pv-name]
spec:
  capacity:
    storage: [capacity]
  accessModes:
    - ReadWriteOnce
    - ReadOnlyMany
  persistentVolumereclaimPolicy: Retain # disk 정책
  gcePersistentDisk: # 물리적인 db 내용
    pdName: [db]
    fsType: ext4
```

- `pvc`와 spec이 동일해야함, pv가 더 많이 가질 수 있지만 적게는 안됨



📒 **mongo-pv-pvc-pod.yaml**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: mongodb-pod
spec:
  containers:
  - image: mongo
    name: mongodb-container
    volumeMounts:
    - mountPath: /data/db
      name: mongodb-volume
  volumes:
  - name: mongodb-volume
    persistentVolumeClaim:
      claimName: mongo-pvc
        
---

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mongo-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: ""
    
--- 

apiVersion: v1
kind: PersistentVolume
metadata:
  name: mongo-pv
spec:
  capacity:
    storage: 10Gi
  volumeMode: Filesystem
  accessModes:
  - ReadWriteOnce
  - ReadOnlyMany
  persistentVolumeReclaimPolicy: Retain
  gcePersistentDisk:
    pdName: mongodb
    fsType: ext4
```

- `pdName: mongodb`는 GCP가 미리 정의해놓은 네트워크 스토리지 명칭



### 📍 PV 동적 프로비저닝

> PV를 직접 만드는 대신 사용자가 원하는 PV 유형을 선택하도록 오브젝트 정의

[img/k8s.network.storage]

- `PVC`가 바운딩이 되려면 적합한 `PV`가 있어야 함
- `PV`가 없다면 pending이 발생함
- `StorageClass`: 동적으로 PV를 만듦

📒 **storageclass.yaml**

```yaml
apiVersion: storage.k8s.io/v1
kind: Storageclass
metadata:
  name: storage-class # PVC에 쓰일 storageClassName
provisioner: kubernetes.io/gce-pd # 프로비저닝에 사용할 플로그인 선택
parameters:
  type: pd-ssd # 사용자에게 전달될 매개변수
```

📒 **pvc.yaml**

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mongo-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: storage-class
```



📌 **PV 설정 변경**

- `RECLAIM POLICY`의 기본값은 `Delete`

```
kubectl edit pv [pv_name]
```

```yaml
persistentVolumeReclaimPolicy: Retain
```

- Delete: 파괴



### 📍 스테이트 풀셋

> 애플리케이션의 상태를 저장하고 관리하는데 사용되는 쿠버네티스 객체

- 기존의 파드는 상태 유지를 하지 않음

📌 **스테이트풀셋 사용 case**

- 안정적이고 고유한 네트워크 식별자가 필요
- 지속적인 스토리지를 사용해야 하는 경우
- 질서 정연한 파드의 배치와 확장을 원함
  - 기존 파드는 랜덤하게 이름이 생김
- 파드의 자동 롤링업데이트를 사용하기 원하는 경우

📌 **스테이트풀셋 단점**

- 볼륨이 삭제되지 않음
- 파드의 스토리지는 PV나 스토리지클래스로 프로비저닝 수행해야 함
- 롤링업데이트를 수행하는 경우 수동으로 복구해야 할 수 있음
- 파드 네트워크 ID를 유지하기 위해 헤더레스 서비스 필요
  - 로드밸런싱을 위한 목적이 아님
  - 고정된 도메인 주소를 제공하기 위함



✏️ **헤드리스 서비스**

**1. 헤드리스 서비스의 기본 개념**

- **IP 없음:** 헤드리스 서비스는 ClusterIP 서비스를 만들 때와 달리, 서비스 자체에 IP 주소가 할당되지 않습니다. 이를 설정하려면 spec.clusterIP를 None으로 설정합니다.
- **DNS 이름으로 접근:** 헤드리스 서비스는 포드 각각의 IP 주소를 클라이언트에게 직접 제공하며, DNS 이름을 통해 각 포드에 접근할 수 있습니다.

**2. 기존 서비스와 헤드리스 서비스의 차이**

**기존 서비스 (ClusterIP, NodePort, LoadBalancer)**

- **kube-proxy 사용:** 기존 서비스는 kube-proxy를 통해 로드 밸런싱이 이루어집니다. 클라이언트가 서비스에 요청을 보내면, kube-proxy가 이를 적절한 포드로 전달합니다.
- **IP 기반 접근:** 클라이언트는 서비스의 고정된 ClusterIP 또는 외부 IP(NodePort/LoadBalancer)를 사용해 요청합니다.
- **동작:** 서비스는 여러 포드로 트래픽을 분산합니다.

**헤드리스 서비스 (ClusterIP: None)**

- **kube-proxy 미사용:** 헤드리스 서비스는 kube-proxy를 사용하지 않습니다. 즉, 로드 밸런싱이나 프록시 역할이 없고 클라이언트가 직접 포드와 통신합니다.
- **DNS 기반 접근:** DNS를 조회하면, 각 포드의 IP 주소가 반환됩니다. 클라이언트는 반환된 IP 목록에서 적절한 포드로 직접 연결을 설정합니다.
- **동작:** 클라이언트가 자체적으로 로드 밸런싱을 수행하거나 특정 포드와 통신하도록 설계되어 있습니다.

**3. 헤드리스 서비스의 활용 사례**

> 헤드리스 서비스는 **포드 하나하나에 직접 연결이 필요**한 경우에 유용

- **StatefulSet:** 각 포드가 고유한 ID를 가지며, 클라이언트가 특정 포드에 접근해야 하는 경우.
  - 데이터베이스 클러스터(예: Kafka, Cassandra, MongoDB 등)에서 각 포드가 고유한 데이터 셰어를 담당할 때.
- **직접 로드 밸런싱:** 애플리케이션에서 DNS 정보를 활용하여 자체적으로 로드 밸런싱을 구현하는 경우.

**4. DNS 이름을 사용한 접근 방식**

- 헤드리스 서비스는 다음과 같은 방식으로 DNS 이름을 통해 포드에 접근
  - **서비스 DNS 이름:** <포드이름>.<서비스이름>.<네임스페이스>.svc.cluster.local
  - DNS를 조회하면, 해당 서비스 아래의 모든 포드 IP 목록이 반환됩니다.

🌈 **예시**

```
서비스 이름: my-service
네임스페이스: default
포드 이름: pod-1
```

- DNS로 pod-1.my-service.default.svc.cluster.local를 조회하면 해당 포드의 IP가 반환됩니다.



📌 **스테이트풀셋 다수 파드 식별 요령**

- 스테이트풀셋은 replicas를 사용해 다수의 파드를 생성할 수 있음
- 상태를 저장해야 하는 파드가 스케일링 기능을 제공하려면 레플리카셋처럼 랜덤한 문자열로 만들어져서는 안됨
- 스테이트풀셋은 순차적으로 파드를 하나씩 배포하면서 상태를 유지할 수 있도록 0번부터 번호를 부여함
- 이러한 형태로 스테이트풀셋은 안정적인 네트워크 ID와 스토리지를 식별할 수 있음
- 스테이트풀셋은 앞의 포드가 준비 상태가 되어야 다음 포드를 생성함
- 종료 순서와 업데이트 순서는 배포 순서의 역순으로 진행 됨

