아이스브레이킹



**1. 머신러닝에 대한 이해**

**1.1 머신러닝이란 무엇인가**

- 이번에는 **머신러닝이란 무엇인지,** 그리고 어떤 절차로 이루어지는지에 대해 자세히 알아보겠습니다.
- 어제 1강의 웜업 단계에서 머신러닝은 사람이 데이터를 분석하여 규칙을 수작업으로 만들지 않아도, **컴퓨터가 데이터 안에 숨어있는 규칙과 패턴을 스스로 학습하여 결과를 예측하는 기술**이라고 말씀드렸습니다.
- 이는 우리가 스팸메일 분류 예시를 통해 확인해 보았죠.
- 전통적인 프로그래밍에서는, 입력 데이터를 주고 사람이 명확하게 정의한 규칙을 통해 출력을 얻는 방식이었다면,
- 머신러닝은 **입력과 출력 데이터를 주면, 컴퓨터가 스스로 그 사이의 규칙을 학습해냅니다**.
- 이처럼 머신러닝은 명시적인 프로그래밍 없이도 복잡한 문제 해결이 가능하다는 점에서 **현대 데이터 분석의 핵심 도구**로 자리잡고 있습니다.
- 최근에는 이미지 인식, 자연어 처리, 의료 진단, 금융 사기 탐지, 추천 시스템 등 다양한 분야에서 머신러닝이 활발히 사용되고 있으며,
- 특히 파이썬 언어의 발전과 함께 scikit-learn, XGBoost, LightGBM, TensorFlow, PyTorch 등 **고성능 라이브러리를 통해 누구나 쉽게 모델을 개발하고 학습시킬 수 있는 환경**이 조성되었습니다.
- 특히 GPT의 발전이 가장 크게 기여했을 것 같은데요.
- 오늘 마지막시간에는 이제 GPT를 활용해서 데이터 분석을 하는 과정도 함께 경험해보실 것입니다.
- 이때, 이번시간에 배울 분석 프로세스가 이후 모든 실습과정에서 적용될 뿐만 아니라 GPT를 활용한 데이터 분석에서도 활용될 것이기 때문에 전체 흐름을 잘 이해하는 것이 중요 포인트가 될 것 같습니다.

**1.2 머신러닝 분석 프로세스**

- 다음으로는 머신러닝 분석이 **어떤 순서로 진행되는지**, 그 전체 흐름을 단계별로 살펴보겠습니다.
- 머신러닝 프로젝트는 단순히 알고리즘만을 적용하는 것이 아니라, **데이터 수집에서부터 모델 평가에 이르기까지 여러 복합적인 과정을 포함**합니다.
- 이 과정을 이해하고 체계적으로 접근해야만 **안정적이고 정확한 결과를 얻을 수 있습니다**.

[읽기]

[5:30]

---

- 요렇게 개요를 살표보았는데요, 약간 재방송 같겠지만 상세 과정을통해 좀더 명확하게 살펴보도록 하겠습니다.

**Step 1. 데이터 확인 (Data Understanding)**

- 가장 먼저 해야 할 일은 **데이터의 속성과 구조를 파악하는 작업**입니다.
- 분석 대상이 되는 데이터셋을 불러온 뒤, **변수들의 타입, 분포, 누락값 여부, 데이터의 양과 품질**을 확인합니다.
- 특히 머신러닝에서는 **독립변수(X)와 종속변수(y)**를 명확히 구분하는 것이 중요합니다.

- 종속변수가 있는 경우, 그 특성에 따라 분석 접근법이 달라집니다:
  - **연속형** 종속변수이면 → 회귀분석
  - **범주형** 종속변수이면 → 분류분석
  - **종속변수가 없다면** → 비지도 학습(군집, 차원 축소 등)

- 이때 변수의 유형을 잘못 파악하게 되면, 적절하지 않은 분석 방법을 적용하게 되어 모델 성능에 심각한 영향을 줄 수 있으므로,
- **변수별로 데이터 타입, 수치 분포, 중복 여부 등을 꼼꼼히 확인하는 습관**이 필요합니다.

- 또한, 독립변수 중에 **범주형 변수(categorical)**가 있는 경우에는 이후 인코딩 처리가 필요하기 때문에 미리 구분해두는 것이 좋습니다.

[1:30 / 7:00]

---

**Step 2. EDA (Exploratory Data Analysis)**

- 두 번째 단계는 **탐색적 데이터 분석, 즉 EDA**입니다.
- 이 단계는 **데이터의 본질을 직관적으로 파악**하는 과정으로, 본격적인 분석에 앞서 **데이터에 대한 감각을 익히는 매우 중요한 절차**입니다.

- EDA의 목적은 다음과 같습니다:
  - 데이터의 분포 파악 (히스토그램, 커널 밀도 추정 등)
  - 변수 간 관계 확인 (산점도, 상관계수, 쌍변량 시각화)
  - 이상치(outlier), 결측치(missing value)의 유무 및 위치 확인
  - 잠재적인 패턴 혹은 문제점 발견

- 특히 변수의 특성에 따라 **적절한 시각화 기법을 선택하는 것이 중요**합니다.
  - 수치형 변수는 히스토그램, 박스플롯 등을 사용하고,
  - 범주형 변수는 막대그래프나 파이차트를 활용합니다.

- 분석 방향이나 가설 수립에도 EDA가 핵심 역할을 합니다.
- 예를 들어, 특정 변수 간의 상관성이 높게 나타난다면 그 변수들을 함께 고려해 예측 모델을 설계할 수 있고,
- 데이터가 특정 군집으로 나뉘어 있다면 비지도 학습으로 접근하는 방향도 고려해볼 수 있습니다.

[1:00 / 8:00]

---

**Step 3. 데이터 전처리 (Data Preprocessing)**

- 세 번째는 **전처리 단계**입니다. 이 단계는 말 그대로 **데이터를 분석과 모델 학습에 적합한 상태로 정제하는 과정**입니다.
- 전처리를 제대로 수행하지 않으면, 아무리 좋은 알고리즘을 써도 **성능이 낮게 나올 수 있습니다**.

- 주요 작업 항목은 다음과 같습니다:

1. **결측치 처리**:
   - 평균, 중앙값 대체 또는 제거
   - 모델 기반 예측, KNN 대체 등 고급 기법
2. **이상치 처리**:
   - 시각화를 통한 탐지 (박스플롯, IQR 등)
   - 제거하거나, 극단값 처리 혹은 로그 변환 등
3. **범주형 변수 인코딩**:
   - 원핫인코딩(One-Hot Encoding): 순서가 없는 범주형 변수
   - 라벨 인코딩(Label Encoding): 순서가 있는 변수
4. **스케일링(정규화, 표준화)**:
   - MinMaxScaler: 0~1 범위로 변환
   - StandardScaler: 평균 0, 표준편차 1로 정규화
   - 모델에 따라 스케일링의 중요성이 크기 때문에 반드시 확인
5. **샘플링**:
   - 클래스 불균형 문제를 해결하기 위해 언더샘플링 또는 오버샘플링을 고려

[4:00/ 12:00]

---

**Step 4. 모델 학습 (Model Training)**

- 네 번째는 **모델을 학습시키는 단계**입니다.
- 전처리된 데이터를 바탕으로, 분석 목적에 부합하는 머신러닝 알고리즘을 적용합니다.

- 대표적인 알고리즘은 다음과 같습니다:

1. **회귀 분석 (Regression)**:
   - 선형회귀, 릿지, 라쏘, 결정트리 회귀, XGBoost 회귀 등

2. **분류 분석 (Classification)**:
   - 로지스틱 회귀, 의사결정나무, 랜덤포레스트, SVM, KNN, XGBoost 등

3. **비지도 학습 (Unsupervised)**:
   - K-평균, DBSCAN, PCA, t-SNE 등

- 또한, 모델의 성능을 향상시키기 위해 **하이퍼파라미터 튜닝**을 수행합니다.
  - GridSearchCV, RandomizedSearchCV, Bayesian Optimization 등 다양한 방식이 있습니다.

- 이 과정에서 중요한 것은 **단일 모델 성능에만 의존하지 않고 여러 모델을 비교하고 교차 검증하는 습관**입니다.

[3:30 / 15:30]

---

**Step 5. 성능 평가 (Evaluation)**

- 마지막 단계는 **학습된 모델이 얼마나 잘 작동하는지를 평가하는 단계**입니다.
- 이때 사용하는 데이터는 반드시 **훈련에 사용되지 않은 평가용 데이터셋(test set)**이어야 하며,
- 평가 지표는 문제 유형에 따라 달라집니다.

[1:00 / 16:30]

---



## 1.3 성능평가 기법

- 그래서 이번에는 **머신러닝 모델의 성능을 평가하는 방법**들에 대해 알아보도록 하겠습니다.
- 머신러닝은 우리가 데이터를 학습시켜, 그로부터 패턴을 찾아내고 미래의 값을 예측하도록 만드는 기술입니다. 그런데 여기서 중요한 질문 하나가 생깁니다.

​	**“이 모델, 과연 잘 작동하고 있을까?”**

- 단순히 예측을 한다고 해서 좋은 모델이 되는 건 아닙니다.
- **얼마나 정확하게 예측했는지, 얼마나 실제값과 가까운지를 수치적으로 평가해야만**,
- 모델의 성능을 객관적으로 판단하고, 더 나은 모델로 개선할 수 있는 방향을 잡을 수 있습니다.
- 이때 사용하는 도구가 바로 **성능 평가 지표**, 즉 **Evaluation Metric**입니다.
- 현업에서는 흔히 “**메트릭(metric)**”이라는 용어로 많이 표현되죠.
- 이 메트릭은 단지 모델 학습 후 결과를 평가하는 데만 쓰이는 게 아닙니다.
- 실제로 머신러닝 모델이 학습되는 과정에서도 내부에서 더 나은 방향으로 모델을 개선하기 위한 판단기준으로 삼게 됩니다.
- 예를 들어, 회귀 문제에서는 **오차를 줄이는 방향**으로 분류 문제에서는 **정확도나 재현율 등을 높이는 방향**으로 모델이 개선되죠.
- 그리고 이러한 평가를 위해 필요한 것은 **테스트셋이 아니라**, 모델 학습 중간에 성능을 측정하기 위한 **검증용 데이터(Validation Set)**입니다.
- 즉, 학습 데이터만으로 모델을 판단하지 않고,
- **모델이 새로운 데이터에서도 잘 작동하는지를 검증하는 용도**로 별도 데이터를 활용하는 것이죠.
- 이제 본격적으로, **회귀 문제에서는 어떤 평가 지표가 쓰이고**, **분류 문제에서는 어떤 방식으로 모델을 평가하는지**, 예제를 통해 하나씩 살펴보도록 하겠습니다.

[1:30 / 18:00]

---

**1.3.1 회귀분석의 기본 개념**

- 회귀 분석에서 모델의 성능은, **예측값과 실제값이 얼마나 차이가 나는지**에 따라 결정되며 차이가 없을수록 즉, 오차가 0에 가까울수록 좋은 모델로 평가 됩니다.
- 그런데 이 차이를 단순히 모두 더하게 되면, 양의 오차와 음의 오차가 상쇄되어 총합이 0이 되어버릴 수도 있습니다.
- 예를 들어, 하나는 +2, 하나는 -2의 오차라면 평균은 0이 되겠지만, 실제로는 두 번의 오류가 있었던 셈입니다.
- 따라서 이를 해결하기 위해 우리는 **절댓값 또는 제곱**을 사용하여 오차를 모두 양수로 만든 뒤 평균을 구하는 방식을 사용합니다.
- 이때 사용되는 대표적인 지표가 **MAE(Mean Absolute Error)**와 **MSE(Mean Squared Error)**입니다.
- 두 지표 모두 예측값과 실제값의 차이를 기반으로 성능을 수치화하지만, 오차를 처리하는 방식에서 중요한 차이를 갖습니다.

---

**1.3.2 MAE (Mean Absolute Error)**

- 먼저, **MAE**에 대해 알아보겠습니다.
- MAE는 **실제값과 예측값 사이의 차이의 절댓값**을 모두 구한 다음, 그 평균을 내는 방식입니다.
- 다시 말해, 각 예측이 실제값에서 평균적으로 **얼마만큼 벗어나 있는지를 직관적으로 나타내는 지표**라고 할 수 있습니다.
- 예를 들어, MAE가 3이라는 것은, 예측값이 평균적으로 실제값과 3만큼의 차이를 가진다는 뜻입니다.

- MAE는 오차의 크기를 **직관적으로 해석할 수 있다는 장점**이 있습니다.
- 특히, 큰 오차던 작은 오차던 **동등한 가중치**를 부여하기 때문에, 이상치에 덜 민감하다는 특징을 가지고 있습니다.

- 예제 그림을 보면, 각 파란 점은 실제값이고, 녹색 선은 회귀 모델의 예측 직선입니다.
- 빨간 수직선은 각 점에서 예측값까지의 거리, 즉 **절댓값 오차**를 의미합니다.
- 이 모든 오차의 평균이 바로 MAE가 됩니다.

- 따라서 MAE는 실제적인 오차의 크기를 명확하게 전달하고자 할 때 주로 사용하게 됩니다.:

---

**1.3.3 MSE (Mean Squared Error)**

- 다음으로는 **MSE**입니다.
- MSE는 MAE와 비슷하게 오차를 측정하지만, 차이점은 **오차를 제곱한 뒤 평균을 낸다는 점**입니다.
- 이렇게 하면, **오차가 클수록 그에 대한 패널티가 훨씬 더 커지게 됩니다.**
- 앞서서 성능평가 지표는 단순히 모델의 성능을 판단하는 것 외에 모델 내부에서 더 나은 모델로 개선하는 방향점이라고 설명드렸습니다.
- 즉, 모델은 자체적으로 연산을통해 이 성능지표가 낮아지는 방향으로 개선을 해나가는 것인데요.
- 이때 오차가 클수록 모델은 그 오차를 줄위기 위한 방향으로 더 큰 보정을 하게 됩니다.
- 즉, MSE는 **큰 오차에 민감하게 반응하여, 더 강력한 학습 방향을 유도**하게 됩니다.

- 예를 들어, MAE에서는 1의 오차든 7의 오차든 그 차이를 절댓값으로만 취급하지만,
- MSE에서는 7의 오차가 49으로 계산되므로, **큰 오차가 모델에 더 크게 반영**되게 됩니다.

- 그림에서는 MSE의 개념을 시각적으로 표현하였습니다.
- 파란 점에서부터 예측 선까지의 거리(오차)를 제곱한 면적으로 표현하고 있으며,
- 붉은 사각형이 클수록 해당 오차가 크고, 모델은 이 오차를 줄이기위해 더 큰 보정을 수행한다 라고 생각하시면 됩니다.

- MSE는 큰 오차에 **민감하게 반응해야 하는 모델**을 만들고자 할 때
  
- 혹은 이상치를 적극적으로 고려하고, **정밀한 예측이 중요한 경우**에 주로 활용됩니다:

---

**MAE와 MSE의 차이 요약**

- MAE는 **모든 오차를 균등하게 처리**하므로, **이상치에 덜 민감**합니다.
- MSE는 **오차를 제곱**하여 반영하기 때문에, **이상치나 큰 오차에 민감하게 반응**합니다.
- 따라서, 사용자는 분석 목적에 따라 두 지표 중 **하나를 선택하거나, 둘 모두를 참고하여 종합적으로 판단**하는 것이 바람직합니다.

---

**실전 활용 팁**

- 머신러닝 경진대회나 실무 분석에서는 종종 **MAE와 MSE 둘 다를 계산하여 보고서에 함께 제시**하는 경우가 많습니다.
- MSE가 높은데 MAE는 낮다면, 일부 큰 이상치가 전체 평가에 영향을 주고 있다는 의미로 해석할 수 있습니다.
- 반대로 MSE와 MAE의 차이가 크지 않다면, 데이터가 상대적으로 고르게 분포되어 있다고 판단할 수 있습니다.
- 또한 MSE의 단위는 원래의 데이터 단위가 **제곱**이 되므로, 직관적인 해석이 어려울 수 있다는 점도 함께 고려해야 합니다.
  - 이럴 때는 RMSE(제곱근 평균 제곱 오차)를 활용하여 원래 단위로 환산하기도 합니다.

---

[7:00 / 25:00]



**1.3.2 분류분석에서의 성능평가 지표**

- 다음으로는 **분류모델의 성능을 평가하는 다양한 지표들**에 대해 알아보겠습니다.
- 회귀 문제에서는 예측값과 실제값의 차이를 수치화하여 평가하지만,
- 분류 문제에서는 **예측한 클래스가 실제 클래스와 얼마나 일치하는지**를 기준으로 모델의 성능을 판단합니다.
- 하지만 이진 분류 문제에서 단순히 **정확도만을 가지고 모델의 성능을 판단하는 것은 위험할 수 있습니다.**
- 특히 클래스 불균형이 심한 경우에는 높은 정확도를 보여도 **실제 예측 성능은 매우 낮을 수 있기 때문**입니다.
- 따라서 분류 분석에서는 **정확도 외에도 정밀도, 재현율, F1 점수, ROC 곡선 및 AUC** 등의 다양한 지표를 종합적으로 고려해야 합니다.

---

**정확도 (Accuracy)**

- 먼저 가장 기본적인 개념인 **정확도**부터 살펴보겠습니다.
- 정확도는 전체 예측 중에서 **예측이 맞은 비율**을 의미합니다.
- 즉, 모델이 얼마나 맞췄는지를 간단히 판단할 수 있는 지표입니다.
- 수식으로 보면, 전체 데이터 중 **정답으로 예측한 건수의 비율**입니다.

- 매우 쉽고 명확해 보이는 수식이지만 그만큼 치명적인 단점, 한계도 존재합니다.

[Next]

- 즉, 겉으로는 정확도가 높아 보이지만, 실제 질병이 있는 환자는 모두 놓치게 되는 매우 **위험한 모델**이 됩니다.
- 따라서 **정확도 하나만으로 모델 성능을 판단하는 것은 매우 위험할 수 있습니다**.
- 이로인해 다른 측정 지표인  **정확도, 정밀도, 재현율, F1 점수**등 복합적인 관점으로 평가가 이루어져야 하는데요.
- 이러한 지표 연산을 위해 위해 혼동행렬이 필요합니다.

[3:00 / 28:00]

---

**혼동행렬 (Confusion Matrix)**

- 혼동행렬은 분류 모델이 **어떤 종류의 예측 오류를 발생시키는지**를 구체적으로 보여주는 도표입니다.
- 행은 실제 클래스, 열은 예측 클래스에 해당하며, 2x2 형태로 네 가지 값을 가집니다:

  1. **TP (True Positive)**: Positive를 맞게 예측
  2. **TN (True Negative)**: Negative를 맞게 예측
  3. **FP (False Positive)**: 실제는 Negative인데 Positive로 잘못 예측
  4. **FN (False Negative)**: 실제는 Positive인데 Negative로 잘못 예측
- 이 혼동행렬을 기반으로 **앞서 설명한 정확도뿐 아니라 더 복합적인 관점으로 평가하는 지표인 정밀도, 재현율, F1 점수** 등을 모두 계산할 수 있습니다.
- 즉, 혼동행렬은 **정확도를 넘어서 모델의 약점을 구체적으로 진단**할 수 있는 도구입니다.

[3:00 /31:00]

---

**정밀도 (Precision)**

- 그래서 혼동행렬을 통해 더 복합적인 관점으로 분류 모델을 평가하기 위한 첫번째는 **정밀도**입니다.
- 정밀도는 모델이 True로 예측한 것 들 중 실제 True인 것의 비율이다 라고 적어놓았는데요
- 모델이 True로 예측한 것들은 TP와 FP 두개의 합이라고 볼 수 있으며,
- 모델이 True로 예측한 것 중 실제 True인 것은 TP입니다.
- 따라서 수식은 이렇게 되구요
- 여기서 키 포인트는 바로 FP입니다.
- 물론 TP도 중요한 지표이긴 하나 이는 늘어나봤자 분자와 분모가 동시에 늘어나는 것이기에 정밀도에 큰 영향을 미칠 수 없습니다.
- 따라서 FP가 커질수록 정밀도는 낮아지거나 FP가 작아질수록 정밀도는 높아지는 등 FP에 따라 큰 영향을 받는 성능 지표라고 볼 수 있습니다.



- 다음은 정밀도에 대한 예시입니다.
- 예시는 스팸 분류 모델을 두개 만들었고, 총 100개의 메일을 스팸과 스팸이 아닌것으로 분류할것이고 그에 따라 정밀도를 계산한다 라고 되어 있습니다.
- 먼저 첫번째 모델의 혼동행렬을 살펴보면 전체 데이터는 총 100개임을 확인하였고
- 모델이 스팸이다라고 예측한 것중에 실제로 스팸인 것은 80개
- 스팸이 아니었던 것은 7개임을 확인할 수 있습니다.
- 이를 통해 정밀도를 계산해보면 87분의 80으로 0.919의 수치를 갖게 되구요.
- 다음으로 두번째 모델의 혼동행렬을 살펴보겠습니다.
- 역시나 총데이터의 합은 100임을 확인할 수 있고
- 모델이 스팸메일이다 라고 말한 데이터가 총 80개로 앞서 87개보다 조금 줄었습니다.
- 그리고 이에 따라 모델이 스팸이다라고 얘측한 것 중 실제 스팸인 것은 75개로 5개가 줄었으며
- 모델이 스펨이다라고 얘측한 것 중 실제 스팸이 아니었던것은 5개로 2개가 줄었습니다.
- 이를 정밀도 식에 따라 계산해보면 80분의 75로 0.938의 수치를 갖게 됨을 확인할 수 있습니다.
- 스팸을 스팸이다라고 얘기한 TP의 개수가 줄었으나 정밀도 관점에서 성능은 올라간 것을 볼 수 있네요.
- 이를 통해 스팸이라고 예측했지만 스팸이 아닌 경우가 더 조금 줄었어도 성능지표에 더 큰 영향을 미치는 점을 확인할 수 있었습니다.
- 즉, 정밀도는 FP에 민감하게 반응한다는 점을 알 수 있었구요.
- 또한 한 가지 더 생각해봐야 할 점은, **모델 2를 선택하여 ‘스팸이 아니다’라고 예측해 필터링되지 않은 메일들이 늘어난다 해도**,
- 이는 사용자 입장에서 **크게 불편하지 않을 수도 있습니다.**
- **왜냐하면, 그 메일이 정말로 스팸이라면 **사용자가 직접 지우거나 무시하면 되기 때문**이죠.**
- **하지만 **정반대로**, **모델이 “이건 스팸이야”라고 판단해서 필터링해버렸는데,** **실제로는 중요한 메일이었다면 어떻게 될까요?**
- 이 경우는 **정말 중요한 정보가 유실될 수 있고, 심각한 피해로 이어질 수도 있습니다.** 이렇게 **스팸이라고 판단한 결과가 틀렸을 때** 즉, FP가 늘어났을 때 더 큰 문제가 발생하기 때문에,
-  **중요한 메일을 실수로 스팸으로 분류하는 것과 같이 FP가 늘어나는 것이 더 치명적인 서비스**에서는,
- **정밀도를 우선 고려하는 것이 바람직**합니다.

[3:30 / 34:30]

---

**재현율 (Recall)**

- 혼동행렬을 통해 더 복합적인 관점으로 분류 모델을 평가하기 위한 두 번째 지표는 **재현율(Recall)**입니다.

- 재현율은 **실제로 True인 값들 중에서 모델이 얼마나 잘 True로 예측했는가**를 나타내는 지표입니다.

- 즉, **실제 Positive 중에서 얼마나 놓치지 않고 잘 잡아냈는가**가 핵심이죠.

- 수식으로 보면, 재현율은 다음과 같이 계산됩니다:

- 여기서 모델이 실제 Positive를 맞춘 건 TP이고, 놓친 건 FN이기 때문에

-  **FN가 많아질수록 재현율은 급격히 낮아지는 특성**이 있습니다.

  

- 다음은 재현율에 대한 예시입니다.
- 예시는 **암 환자를 분류하는 모델** 두 개를 비교하고 있으며,
- 총 **100명의 환자**를 진단한 결과를 기반으로 재현율을 계산하고 있습니다.
- **📌 모델 1의 혼동행렬을 살펴보면:**
- 실제 암 환자 중 모델이 암이라고 판단한 경우: **7명 (TP)**
- 실제 암 환자인데 놓친 경우: **2명 (FN)**
- 따라서 실제 암 환자는 총 **9명**이고, 재현율은 0.778로 나타납니다.
- 다음으로 **📌 모델 2의 혼동행렬을 살펴보면:**
- 암 환자를 암이라고 예측한 경우: **10명 (TP)**
- 놓친 경우: **3명 (FN)**
- 이때 재현율은 모델이 암환자를 더 잘 예측했어도 0.769로 모델 1보다는 낮은 성능을 보이고 있습니다.
- 이를 통해 확인할 수 있는 점은, 재현율은 모델이 실제 암환자를 암환자가 아니다라고 판단하는 **FN에 민감하게 반응**한다는 점입니다.
- 암 환자를 놓치는 것(FN)은 **잠재적으로 생명을 위협할 수 있는 중대한 문제**입니다.
- 반면, 암이 아닌 사람을 암 환자로 잘못 분류하는 경우는 **추가 검사로 충분히 확인이 가능**하겠죠.
- 즉, FN을 줄여야 하는 크리티컬한 상황에서는 정확도보다 재현율을 메트릭으로 설정해야 합니다.

[2:30/ 37:00]

---

**정밀도와 재현율의 상충관계 (Trade-off)**

- 정밀도와 재현율은 일반적으로 **트레이드오프 관계**에 있습니다.
- 즉, **임계값(Threshold)을 조정하면 한쪽 지표를 높이는 대신 다른 쪽은 낮아지는 현상**이 발생합니다.
  - 이때 임계값은 분류모델이 내놓은 확률이 몇퍼센트 이상이면 참으로 보겠다 라는 그 퍼센트에 해당하게 됩니다.

- 따라서 예를 들어 임계값을 낮추면 재현율은 높아지지만 정밀도는 떨어질 수 있습니다.
- 반대로 임계값을 높이면 정밀도는 상승하지만 재현율은 떨어질 수 있습니다.
- 따라서 분석 목적에 따라 어떤 지표를 더 중요하게 볼지 판단하고,
  - 필요시 두 지표를 **적절히 조화롭게 고려하는 것이 중요**합니다.

[2:30 / 39:30]

---

**F1 Score**

- 그래서 나온 개념인 F1 점수는 **정밀도와 재현율의 조화 평균**입니다.
- 두 지표 중 하나라도 너무 낮으면, F1 점수도 함께 낮아지기 때문에,
- 두 지표를 **균형 있게 고려하고자 할 때 유용한 성능 지표**입니다.
- 특히 **정밀도와 재현율의 중요도가 비슷한 경우**에 추천됩니다.

[1:00 / 40:30]

---

**ROC 곡선과 AUC 점수**

- 마지막으로 알아볼 지표는 **ROC 곡선과 AUC 점수**입니다.

**1. ROC 곡선**

- ROC 곡선은 분류기의 **임계값을 조정하면서 FPR과 TPR이 어떻게 변하는지를 시각화**한 그래프입니다.
- x축은 FPR(False Positive Rate), y축은 TPR(True Positive Rate)입니다.
- 완벽한 분류 모델이라면, ROC 곡선이 왼쪽 상단에 가깝게 치우쳐야 합니다.
- 따라서 ROC 곡선은 모델의 분류 능력을 **시각적으로 직관적으로 비교할 수 있는 도구**로 사용됩니다.

**2. AUC 점수**

- AUC는 ROC 곡선 아래 면적(Area Under the Curve)을 의미하며,
- 그 값은 0에서 1 사이의 값을 가집니다.
- AUC가 1에 가까울수록 **모델의 분류 성능이 우수**하다고 볼 수 있습니다.
- AUC가 0.5에 가까우면 이는 **무작위 수준의 분류기**와 같다는 의미입니다.

- AUC는 다양한 클래스 비율이나 임계값 설정에도 비교적 영향을 덜 받기 때문에,
- **모델 간의 성능 비교를 공정하게 진행할 수 있는 지표**로 널리 활용됩니다.

---

**정리하며**

- 분류 문제에서 성능 평가 지표는 단순한 정확도 하나로는 부족하며,
- **정밀도, 재현율, F1 점수, ROC 및 AUC**를 함께 고려해야 모델의 성능을 올바르게 해석할 수 있습니다.
- 실제 업무에서는 문제의 특성에 따라 **정밀도 중심의 모델을 선택할지, 재현율 중심의 모델을 선택할지**가 달라질 수 있습니다.
- 따라서 지표 하나만 보고 판단하기보다는, **분석 목적에 따라 핵심 지표를 선정하고, 다양한 지표를 함께 해석하는 시각이 필요**합니다.



- 이제 우리는 머신러닝을 위해 데이터를 확인하는 것부터, 시각화하는것, 전처리하는것, 적합한 모델을 설정하는것
- 그리고 마지막으로 평가하는 것 까지 모든 단계를 이론적으로 학습했습니다.
- 이제 다음시간부터는 실제 사례에 이를 적용해서 감을 익혀보도록 하겠습니다.

[47:00]

