아이스브레이킹

- 10분?
- 안녕하세요 여러분 금요일이네요
- 다들 컨디션은 괜찮으신가요?
- 네, 저는 일단 금요일이지만 앞으로 8시간 동안 떠들어야해서 지금 당장은 컨디션이 썩 좋진 않구요
- 빨리 끝내고 치킨먹고싶네요
- 아무튼 오늘 수업 시작에 앞서서 아마 뒤에는 좀 빨리 끝날거같아서 LLM 관련 내용도 간단히 전달해드릴거같은데
- 아이스브레이킹으로 어제 첫 시간에 제가 데이터 쪽으로 커리어를 바꿨다가 다시 응용어플리케이션 개발 포지션으로 돌아온 얘기를 좀 해볼까 합니다.

https://www.samsungsds.com/kr/insights/ai-strategy-for-your-company.html

- 내 얘기
- 다행스럽게도 앞서 공부했던 내용들이 llm 응용 위해서 필요한 경우가 생기더라구요
- 
- Llm이 짱이니까 쓰기만하면된다.
- 알고질문하는것과 모르고 질문하는것에 대한 차이

[15분]





**1. 머신러닝에 대한 이해**

**1.1 머신러닝이란 무엇인가**

- 이번에는 **머신러닝이란 무엇인지, 그리고 왜 중요한지** 그리고 어떤 절차로 이루어지는지에 대해 자세히 알아보겠습니다.
- 어제 1강의 웜업 단계에서 머신러닝은 사람이 데이터를 분석하여 규칙을 수작업으로 만들지 않아도, **컴퓨터가 데이터 안에 숨어있는 규칙과 패턴을 스스로 학습하여 결과를 예측하는 기술**이라고 말씀드렸습니다.
- 이는 우리가 스팸메일 분류 예시를 통해 확인해 보았죠.
- 전통적인 프로그래밍에서는, 입력 데이터를 주고 사람이 명확하게 정의한 규칙을 통해 출력을 얻는 방식이었다면,
- 머신러닝은 **입력과 출력 데이터를 주면, 컴퓨터가 스스로 그 사이의 규칙을 학습해냅니다**.
- 이처럼 머신러닝은 명시적인 프로그래밍 없이도 복잡한 문제 해결이 가능하다는 점에서 **현대 데이터 분석의 핵심 도구**로 자리잡고 있습니다.

- 최근에는 이미지 인식, 자연어 처리, 의료 진단, 금융 사기 탐지, 추천 시스템 등 다양한 분야에서 머신러닝이 활발히 사용되고 있으며,
- 특히 파이썬 언어의 발전과 함께 scikit-learn, XGBoost, LightGBM, TensorFlow, PyTorch 등 **고성능 라이브러리를 통해 누구나 쉽게 모델을 개발하고 학습시킬 수 있는 환경**이 조성되었습니다.

- 이제 머신러닝은 특정 전문가만이 다루는 기술이 아니라, **모든 데이터 분석가에게 필요한 필수 역량**이라 해도 과언이 아닙니다.

[2분/ 17]



**1.2 머신러닝 분석 프로세스**

- 다음으로는 머신러닝 분석이 **어떤 순서로 진행되는지**, 그 전체 흐름을 단계별로 살펴보겠습니다.
- 머신러닝 프로젝트는 단순히 알고리즘만을 적용하는 것이 아니라, **데이터 수집에서부터 모델 평가에 이르기까지 여러 복합적인 과정을 포함**합니다.
- 이 과정을 이해하고 체계적으로 접근해야만 **안정적이고 정확한 결과를 얻을 수 있습니다**.



[3분/ 20]

---

- 다음은 머신러닝 분석 프로세스 상세입니다.
- 약간 재방송같겠지만..
- 오늘 수업에서는 여러분들이 직접 미션을 수행하면서 데이터 분석을 진행해볼것이기 때문에
- 다시한번 절차에대해서 자세히 설명드리고자 합니다.

**Step 1. 데이터 확인 (Data Understanding)**

- 가장 먼저 해야 할 일은 **데이터의 속성과 구조를 파악하는 작업**입니다.
- 분석 대상이 되는 데이터셋을 불러온 뒤, **변수들의 타입, 분포, 누락값 여부, 데이터의 양과 품질**을 확인합니다.
- 특히 머신러닝에서는 **독립변수(X)와 종속변수(y)**를 명확히 구분하는 것이 중요합니다.

- 종속변수가 있는 경우, 그 특성에 따라 분석 접근법이 달라집니다:
  - **연속형** 종속변수이면 → 회귀분석
  - **범주형** 종속변수이면 → 분류분석
  - **종속변수가 없다면** → 비지도 학습(군집, 차원 축소 등)

- 이때 변수의 유형을 잘못 파악하게 되면, 적절하지 않은 분석 방법을 적용하게 되어 모델 성능에 심각한 영향을 줄 수 있으므로,
- **변수별로 데이터 타입, 수치 분포, 중복 여부 등을 꼼꼼히 확인하는 습관**이 필요합니다.

- 또한, 독립변수 중에 **범주형 변수(categorical)**가 있는 경우에는 이후 인코딩 처리가 필요하기 때문에 미리 구분해두는 것이 좋습니다.

[2:30/ 22:30]

---

**Step 2. EDA (Exploratory Data Analysis)**

- 두 번째 단계는 **탐색적 데이터 분석, 즉 EDA**입니다.
- 이 단계는 **데이터의 본질을 직관적으로 파악**하는 과정으로, 본격적인 분석에 앞서 **데이터에 대한 감각을 익히는 매우 중요한 절차**입니다.

- EDA의 목적은 다음과 같습니다:
  - 데이터의 분포 파악 (히스토그램, 커널 밀도 추정 등)
  - 변수 간 관계 확인 (산점도, 상관계수, 쌍변량 시각화)
  - 이상치(outlier), 결측치(missing value)의 유무 및 위치 확인
  - 잠재적인 패턴 혹은 문제점 발견

- 특히 변수의 특성에 따라 **적절한 시각화 기법을 선택하는 것이 중요**합니다.
  - 수치형 변수는 히스토그램, 박스플롯 등을 사용하고,
  - 범주형 변수는 막대그래프나 파이차트를 활용합니다.

- 분석 방향이나 가설 수립에도 EDA가 핵심 역할을 합니다.
- 예를 들어, 특정 변수 간의 상관성이 높게 나타난다면 그 변수들을 함께 고려해 예측 모델을 설계할 수 있고,
- 데이터가 특정 군집으로 나뉘어 있다면 비지도 학습으로 접근하는 방향도 고려해볼 수 있습니다.

[1:30 / 24:00]

---

**Step 3. 데이터 전처리 (Data Preprocessing)**

- 세 번째는 **전처리 단계**입니다. 이 단계는 말 그대로 **데이터를 분석과 모델 학습에 적합한 상태로 정제하는 과정**입니다.
- 전처리를 제대로 수행하지 않으면, 아무리 좋은 알고리즘을 써도 **성능이 낮게 나올 수 있습니다**.

- 주요 작업 항목은 다음과 같습니다:

1. **결측치 처리**:
   - 평균, 중앙값 대체 또는 제거
   - 모델 기반 예측, KNN 대체 등 고급 기법
2. **이상치 처리**:
   - 시각화를 통한 탐지 (박스플롯, IQR 등)
   - 제거하거나, 극단값 처리 혹은 로그 변환 등
3. **범주형 변수 인코딩**:
   - 원핫인코딩(One-Hot Encoding): 순서가 없는 범주형 변수
   - 라벨 인코딩(Label Encoding): 순서가 있는 변수
4. **스케일링(정규화, 표준화)**:
   - MinMaxScaler: 0~1 범위로 변환
   - StandardScaler: 평균 0, 표준편차 1로 정규화
   - 모델에 따라 스케일링의 중요성이 크기 때문에 반드시 확인
5. **샘플링**:
   - 클래스 불균형 문제를 해결하기 위해 언더샘플링 또는 오버샘플링을 고려

---

**Step 4. 모델 학습 (Model Training)**

- 네 번째는 **모델을 학습시키는 단계**입니다.
- 전처리된 데이터를 바탕으로, 분석 목적에 부합하는 머신러닝 알고리즘을 적용합니다.

- 대표적인 알고리즘은 다음과 같습니다:

1. **회귀 분석 (Regression)**:
   - 선형회귀, 릿지, 라쏘, 결정트리 회귀, XGBoost 회귀 등

2. **분류 분석 (Classification)**:
   - 로지스틱 회귀, 의사결정나무, 랜덤포레스트, SVM, KNN, XGBoost 등

3. **비지도 학습 (Unsupervised)**:
   - K-평균, DBSCAN, PCA, t-SNE 등

- 또한, 모델의 성능을 향상시키기 위해 **하이퍼파라미터 튜닝**을 수행합니다.
  - GridSearchCV, RandomizedSearchCV, Bayesian Optimization 등 다양한 방식이 있습니다.

- 이 과정에서 중요한 것은 **단일 모델 성능에만 의존하지 않고 여러 모델을 비교하고 교차 검증하는 습관**입니다.

---

**Step 5. 성능 평가 (Evaluation)**

- 마지막 단계는 **학습된 모델이 얼마나 잘 작동하는지를 평가하는 단계**입니다.
- 이때 사용하는 데이터는 반드시 **훈련에 사용되지 않은 평가용 데이터셋(test set)**이어야 하며,
- 평가 지표는 문제 유형에 따라 달라집니다.

---



## 1.3 성능평가 기법

- 이번에는 **머신러닝 모델의 성능을 평가하는 방법**, 그 중에서도 **회귀 분석에서 주로 사용되는 성능 지표**에 대해 중점적으로 알아보겠습니다.
- 머신러닝은 데이터를 기반으로 학습하여 예측을 수행하는 기술이지만, 중요한 것은 **그 예측이 얼마나 실제값과 가까운가**를 평가하는 것입니다.
- 즉, 모델이 잘 학습되었는지를 수치적으로 평가해야만, 모델 개선 방향을 도출하거나 여러 모델 중 최적 모델을 선택할 수 있습니다.
- 이러한 평가를 위해 사용하는 것이 바로 **성능평가지표(Evaluation Metric)**이고, 회귀 문제에서는 **실제값과 예측값 간의 오차(error)**를 기반으로 다양한 지표가 사용됩니다.

---

**1.3.1 회귀분석의 기본 개념**

- 회귀 분석에서 모델의 성능은, **예측값과 실제값이 얼마나 차이가 나는지**에 따라 결정됩니다.
- 그런데 이 차이를 단순히 모두 더하게 되면, 양의 오차와 음의 오차가 상쇄되어 총합이 0이 되어버릴 수도 있습니다.
- 예를 들어, 하나는 +2, 하나는 -2의 오차라면 평균은 0이 되겠지만, 실제로는 두 번의 오류가 있었던 셈입니다.
- 따라서 이를 해결하기 위해 우리는 **절댓값 또는 제곱**을 사용하여 오차를 모두 양수로 만든 뒤 평균을 구하는 방식을 사용합니다.
- 이때 사용되는 대표적인 지표가 **MAE(Mean Absolute Error)**와 **MSE(Mean Squared Error)**입니다.
- 두 지표 모두 예측값과 실제값의 차이를 기반으로 성능을 수치화하지만, 오차를 처리하는 방식에서 중요한 차이를 갖습니다.

---

**1.3.2 MAE (Mean Absolute Error)**

- 먼저, **MAE**에 대해 알아보겠습니다.
- MAE는 **실제값과 예측값 사이의 차이의 절댓값**을 모두 구한 다음, 그 평균을 내는 방식입니다.
- 다시 말해, 각 예측이 실제값에서 평균적으로 **얼마만큼 벗어나 있는지를 직관적으로 나타내는 지표**라고 할 수 있습니다.
- 예를 들어, MAE가 3이라는 것은, 예측값이 평균적으로 실제값과 3만큼의 차이를 가진다는 뜻입니다.

- MAE는 오차의 크기를 **직관적으로 해석할 수 있다는 장점**이 있습니다.
- 특히, 큰 오차와 작은 오차에 **동등한 가중치**를 부여하기 때문에, 이상치에 덜 민감하다는 특징을 가지고 있습니다.

- 예제 그림을 보면, 각 파란 점은 실제값이고, 녹색 선은 회귀 모델의 예측 직선입니다.
- 빨간 수직선은 각 점에서 예측값까지의 거리, 즉 **절댓값 오차**를 의미합니다.
- 이 모든 오차의 평균이 바로 MAE가 됩니다.

- 따라서 MAE는 다음과 같은 상황에서 적합하게 사용됩니다:
  - 이상치(outlier)가 많은 데이터에서 오차를 **균등하게 평가**하고 싶을 때
  - 실제적인 오차의 크기를 명확하게 전달하고자 할 때

---

**1.3.3 MSE (Mean Squared Error)**

- 다음으로는 **MSE**입니다.
- MSE는 MAE와 비슷하게 오차를 측정하지만, 차이점은 **오차를 제곱한 뒤 평균을 낸다는 점**입니다.
- 이렇게 하면, **오차가 클수록 그에 대한 패널티가 훨씬 더 커지게 됩니다.**
- 즉, MSE는 **큰 오차에 민감하게 반응하여, 더 강력한 학습 방향을 유도**하게 됩니다.

- 예를 들어, MAE에서는 1의 오차든 10의 오차든 그 차이를 절댓값으로만 취급하지만,
- MSE에서는 10의 오차가 100으로 계산되므로, **큰 오차가 모델에 더 크게 반영**되게 됩니다.

- 두 번째 그림에서는 MSE의 개념을 시각적으로 표현하였습니다.
- 파란 점에서부터 예측 선까지의 거리(오차)를 제곱한 면적으로 표현하고 있으며,
- 붉은 사각형이 클수록 해당 오차가 크고, 모델의 성능은 나빠진다는 의미가 됩니다.

- MSE는 다음과 같은 상황에서 활용됩니다:
  - 큰 오차에 **민감하게 반응해야 하는 모델**을 만들고자 할 때
  - 이상치를 적극적으로 고려하고, **정밀한 예측이 중요한 경우**에 적합

---

**MAE와 MSE의 차이 요약**

- MAE는 **모든 오차를 균등하게 처리**하므로, **이상치에 덜 민감**합니다.
- MSE는 **오차를 제곱**하여 반영하기 때문에, **이상치나 큰 오차에 민감하게 반응**합니다.
- 따라서, 사용자는 분석 목적에 따라 두 지표 중 **하나를 선택하거나, 둘 모두를 참고하여 종합적으로 판단**하는 것이 바람직합니다.

---

**실전 활용 팁**

- 머신러닝 경진대회나 실무 분석에서는 종종 **MAE와 MSE 둘 다를 계산하여 보고서에 함께 제시**하는 경우가 많습니다.
- MSE가 높은데 MAE는 낮다면, 일부 큰 이상치가 전체 평가에 영향을 주고 있다는 의미로 해석할 수 있습니다.
- 반대로 MSE와 MAE의 차이가 크지 않다면, 데이터가 상대적으로 고르게 분포되어 있다고 판단할 수 있습니다.
- 또한 MSE의 단위는 원래의 데이터 단위가 **제곱**이 되므로, 직관적인 해석이 어려울 수 있다는 점도 함께 고려해야 합니다.
  - 이럴 때는 RMSE(제곱근 평균 제곱 오차)를 활용하여 원래 단위로 환산하기도 합니다.

---

**정리하며**

- 회귀 분석에서 성능 평가 지표는 모델이 얼마나 잘 예측했는지를 수치적으로 보여주는 매우 중요한 도구입니다.
- **MAE는 직관적인 평균 오차**, **MSE는 큰 오차에 민감한 지표**로 각각의 성격을 잘 이해하고,
- 분석 목적에 따라 적절한 지표를 선택하여 활용하는 것이 중요합니다.
- 이후 실습에서는 실제 예측 결과를 바탕으로 MAE와 MSE를 직접 계산해보면서, **어떤 상황에서 두 지표가 어떻게 다른 평가를 내리는지**를 확인해 보도록 하겠습니다.





**1.3.2 분류분석에서의 성능평가 지표**

- 다음으로는 **분류모델의 성능을 평가하는 다양한 지표들**에 대해 알아보겠습니다.
- 회귀 문제에서는 예측값과 실제값의 차이를 수치화하여 평가하지만,
- 분류 문제에서는 **예측한 클래스가 실제 클래스와 얼마나 일치하는지**를 기준으로 모델의 성능을 판단합니다.
- 하지만 이진 분류 문제에서 단순히 **정확도만을 가지고 모델의 성능을 판단하는 것은 위험할 수 있습니다.**
- 특히 클래스 불균형이 심한 경우에는 높은 정확도를 보여도 **실제 예측 성능은 매우 낮을 수 있기 때문**입니다.
- 따라서 분류 분석에서는 **정확도 외에도 정밀도, 재현율, F1 점수, ROC 곡선 및 AUC** 등의 다양한 지표를 종합적으로 고려해야 합니다.

---

**정확도 (Accuracy)**

- 먼저 가장 기본적인 개념인 **정확도**부터 살펴보겠습니다.
- 정확도는 전체 예측 중에서 **예측이 맞은 비율**을 의미합니다.
- 즉, 모델이 얼마나 맞췄는지를 간단히 판단할 수 있는 지표입니다.
- 수식으로 보면, 전체 예측 중 **정답으로 예측한 건수의 비율**입니다.

- 하지만 중요한 점은, **정확도는 클래스 분포에 매우 민감하다는 점**입니다.
- 예를 들어, 어떤 질병이 전체 인구 중 3%의 확률로 발생하는 상황을 생각해보겠습니다.
- 이때 모든 환자에 대해 ‘질병 없음’이라고 예측하면 정확도는 97%가 됩니다.
- 겉으로는 정확도가 높아 보이지만, 실제 질병이 있는 환자는 모두 놓치게 되는 매우 **위험한 모델**이 됩니다.
- 따라서 **정확도 하나만으로 모델 성능을 판단하는 것은 매우 위험할 수 있습니다**.
- 이로인해 다른 측정 지표인  **정확도, 정밀도, 재현율, F1 점수**등 복합적인 관점으로 평가가 이루어져야 하는데요.
- 이러한 지표 연산을 위해 위해 혼동행렬이 필요합니다.

---

**혼동행렬 (Confusion Matrix)**

- 혼동행렬은 분류 모델이 **어떤 종류의 예측 오류를 발생시키는지**를 구체적으로 보여주는 도표입니다.
- 행은 실제 클래스, 열은 예측 클래스에 해당하며, 2x2 형태로 네 가지 값을 가집니다:

  1. **TP (True Positive)**: Positive를 맞게 예측
  2. **TN (True Negative)**: Negative를 맞게 예측
  3. **FP (False Positive)**: 실제는 Negative인데 Positive로 잘못 예측
  4. **FN (False Negative)**: 실제는 Positive인데 Negative로 잘못 예측

- 이 혼동행렬을 기반으로 **정확도, 정밀도, 재현율, F1 점수** 등을 모두 계산할 수 있습니다.
- 즉, 혼동행렬은 **정확도를 넘어서 모델의 약점을 구체적으로 진단**할 수 있는 도구입니다.

---

**정밀도 (Precision)**

- 다음은 **정밀도**입니다.
- 정밀도는 **모델이 Positive라고 예측한 것들 중에서, 실제로도 Positive인 것의 비율**을 말합니다.
- 즉, Positive 예측이 얼마나 정확했는지를 나타냅니다.
- 정밀도는 특히 **Positive 오답이 문제가 되는 경우**에 중요하게 사용됩니다.
  - 예: 실제로는 스팸이 아닌 메일을 스팸으로 잘못 분류하면 사용자가 중요한 메일을 놓칠 수 있음
- 따라서 **잘못된 Positive 예측이 비용이 큰 문제를 일으킬 때**, 정밀도를 우선적으로 고려해야 합니다.

---

**재현율 (Recall)**

- 재현율은 **실제로 Positive인 것들 중에서, 모델이 얼마나 잘 찾아냈는지**를 나타냅니다.
- 정밀도는 예측 중심이라면, 재현율은 **실제 중심의 평가 지표**입니다.
- 민감도(Sensitivity), 또는 TPR(True Positive Rate)라고도 불리며,
  - 예: 암환자를 놓치지 않고 모두 찾아내는 것이 중요한 경우
- 실제 Positive를 Negative로 잘못 분류하면 심각한 문제가 발생할 수 있기 때문에,
  - **False Negative를 줄이는 것이 우선이라면 재현율을 중요하게 고려**해야 합니다.

---

**정밀도와 재현율의 상충관계 (Trade-off)**

- 정밀도와 재현율은 일반적으로 **트레이드오프 관계**에 있습니다.
- 즉, **임계값(Threshold)을 조정하면 한쪽 지표를 높이는 대신 다른 쪽은 낮아지는 현상**이 발생합니다.
  - 이때 임계값은 분류모델이 내놓은 확률이 몇퍼센트 이상이면 참으로 보겠다 라는 그 퍼센트에 해당하게 됩니다.

- 따라서 예를 들어 임계값을 낮추면 재현율은 높아지지만 정밀도는 떨어질 수 있습니다.
- 반대로 임계값을 높이면 정밀도는 상승하지만 재현율은 떨어질 수 있습니다.
- 따라서 분석 목적에 따라 어떤 지표를 더 중요하게 볼지 판단하고,
  - 필요시 두 지표를 **적절히 조화롭게 고려하는 것이 중요**합니다.

---

**F1 Score**

- 그래서 나온 개념인 F1 점수는 **정밀도와 재현율의 조화 평균**입니다.
- 두 지표 중 하나라도 너무 낮으면, F1 점수도 함께 낮아지기 때문에,
- 두 지표를 **균형 있게 고려하고자 할 때 유용한 성능 지표**입니다.
- 특히 **정밀도와 재현율의 중요도가 비슷한 경우**에 추천됩니다.

---

**ROC 곡선과 AUC 점수**

- 마지막으로 알아볼 지표는 **ROC 곡선과 AUC 점수**입니다.

**1. ROC 곡선**

- ROC 곡선은 분류기의 **임계값을 조정하면서 FPR과 TPR이 어떻게 변하는지를 시각화**한 그래프입니다.
- x축은 FPR(False Positive Rate), y축은 TPR(True Positive Rate)입니다.
- 완벽한 분류 모델이라면, ROC 곡선이 왼쪽 상단에 가깝게 치우쳐야 합니다.
- 따라서 ROC 곡선은 모델의 분류 능력을 **시각적으로 직관적으로 비교할 수 있는 도구**로 사용됩니다.

**2. AUC 점수**

- AUC는 ROC 곡선 아래 면적(Area Under the Curve)을 의미하며,
- 그 값은 0에서 1 사이의 값을 가집니다.
- AUC가 1에 가까울수록 **모델의 분류 성능이 우수**하다고 볼 수 있습니다.
- AUC가 0.5에 가까우면 이는 **무작위 수준의 분류기**와 같다는 의미입니다.

- AUC는 다양한 클래스 비율이나 임계값 설정에도 비교적 영향을 덜 받기 때문에,
- **모델 간의 성능 비교를 공정하게 진행할 수 있는 지표**로 널리 활용됩니다.

---

**정리하며**

- 분류 문제에서 성능 평가 지표는 단순한 정확도 하나로는 부족하며,
- **정밀도, 재현율, F1 점수, ROC 및 AUC**를 함께 고려해야 모델의 성능을 올바르게 해석할 수 있습니다.
- 실제 업무에서는 문제의 특성에 따라 **정밀도 중심의 모델을 선택할지, 재현율 중심의 모델을 선택할지**가 달라질 수 있습니다.
- 따라서 지표 하나만 보고 판단하기보다는, **분석 목적에 따라 핵심 지표를 선정하고, 다양한 지표를 함께 해석하는 시각이 필요**합니다.



- 이제 우리는 머신러닝을 위해 데이터를 확인하는 것부터, 시각화하는것, 전처리하는것, 적합한 모델을 설정하는것
- 그리고 마지막으로 평가하는 것 까지 모든 단계를 이론적으로 학습했습니다.
- 이제 다음시간부터는 실제 사례에 이를 적용해서 감을 익혀보도록 하겠습니다.



