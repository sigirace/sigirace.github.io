[3:00]

[15분 실습]

[10분 설명]



**Warm Up – 데이터 전처리의 중요성**

- 이번에는 **분석 전 반드시 선행되어야 하는 데이터 전처리(Data Preprocessing)**에 대해 간단히 알아보겠습니다.
- 사실 데이터를 분석하거나 모델링을 하기 전에, **그 데이터를 분석에 적합하도록 잘 다듬어놓는 과정**이 먼저 필요합니다.
- 이걸 무시하고 진행하면 아무리 좋은 알고리즘을 써도 결과가 왜곡되거나, 정확도가 낮게 나오는 경우가 정말 많아요.

**좋은 재료가 좋은 결과를 만든다**

- 햄버거를 만들기 위해 생고기와 조리된 고기가 있습니다.
- 당연히 좋은 맛을 내는 햄버거를 만들기 위해서는 가공된 고기가 들어가야겠죠
- 이때 햄버거를 데이터 분석이라고 한다면, 고기를 조리하는 과정이 바로 데이터 전처리입니다.
- 이는 즉, 날것의 데이터를 그대로 사용하는 것보다 전처리를 통해야만 좋은재료로 거듭나고 좋은 결과로 이루어진다 로 보시면 될 듯합니다.

**목적을 향한 정확한 준비**

- 여자 아이가 ATM기를 사용하려하는데, 동전과 지폐를 고민하고 있습니다.

- 아마 동전을 가지고 가면 ATM기기는 동작하지 않겠죠.

- 이때 ATM기는 모델이라고 생각하시면 되고, 동전과 지폐는 데이터라고 볼 수 있습니다.

- 즉, 사용할 모델에 맞는 데이터를 **잘 준비해두는 것이 전체 분석의 출발점**이라는 메시지를 담고 있어요.

  

**데이터 전처리란 무엇인가?**

- 데이터 전처리는 쉽게 말하면 **분석에 적합하도록 데이터를 정리하고 다듬는 작업**이에요.
- 우리가 직접 데이터를 수집하지 않고, **현장에서 생성된 원본 데이터를 그대로 사용할 경우**엔 이상치, 결측치, 오류가 섞여 있을 가능성이 높아요.
- 이런 데이터를 정제하지 않고 분석에 바로 쓰게 되면, **분석 모델이 왜곡되거나, 비효율적인 결과가 나올 수밖에 없습니다.**

**데이터 전처리의 주요 종류**

- 아래는 전처리 과정에서 흔히 수행하는 작업들을 정리해놓은 것입니다.

| **구분**          | **설명**                                                     |
| ----------------- | ------------------------------------------------------------ |
| **데이터 클리닝** | 결측치 채우기, 이상치 제거, 중복 제거 등 기본적인 정리 작업  |
| **데이터 통합**   | 서로 다른 소스의 데이터를 하나로 합치는 작업                 |
| **데이터 변환**   | 스케일 조정, 정규화, 파생 변수 생성 등                       |
| **데이터 축소**   | 필요한 변수만 선택하거나, 차원을 축소하는 작업               |
| **샘플링**        | 너무 많은 데이터가 있을 경우 일부만 추출하거나 샘플을 균형 있게 조정 |
| **데이터 분할**   | 분석이나 모델링을 위해 train/test 셋으로 나누는 작업         |

**결론**

- 결국 데이터 전처리는 **분석의 시작을 위한 준비운동이자, 전체 성과의 50% 이상을 좌우하는 핵심 과정**이에요.
- **좋은 모델을 쓰는 것보다 더 중요한 건, 좋은 데이터를 제공하는 것**이라는 점 꼭 기억하셔야 합니다.
- 이 강의에서도 앞으로 실습이나 분석을 할 때마다 항상 전처리 단계를 먼저 진행하게 될 텐데요,
- **그만큼 분석에 있어 가장 필수적인 단계**이라고 생각하시면 됩니다.

[5:00]



**5. 데이터 전처리**

- 그럼 데이터 전처리에 대한 강의를 시작해보도록 하겠습니다.
- 시작하기 전에 데이터 전처리는 분석에 사용할 재료인 데이터를 알맞은 형태로 가공하는 과정임을 앞서 웜업에서 설명드렸었습니다.
- 그래서 결국 어쩔수없이 분석 모델에 관련된 이야기가 중간중간 나오게 될텐데요
- 즉, 어떤 분석모델에는 어떤식으로 전처리하는 것이 효과적이다. 라는 관점으로 전처리 과정을 설명드릴 예정입니다.
- 그런데 우리는 모델에 대해서 1강에서 간단히 소개만드리고 심도있게 학습하지 않았죠, 그러니 너무 모델에 집중해서 보실 필요는 없구 대충 어떤 상황에서는 이런게 좋다 라는 관점으로 들어주시면 좋을 것 같습니다.

**5.1 이상치 확인 및 정제**

**5.1.1 이상치란?**

- 처음으로는 데이터 전처리 중에서도 **이상치(outlier)**를 어떻게 정의하고, 또 어떻게 찾아내는지에 대해 알아보겠습니다.
- 우리가 데이터를 다룰 때 종종 어떤 값이 유난히 튀는 경우를 보게 되는데요,
- 이런 값들은 대개 **측정 오류, 입력 실수, 혹은 극단적인 상황에서 발생한 값**일 가능성이 높습니다.
- 문제는 이런 이상치가 분석 결과에 **불필요한 영향을 주거나 왜곡된 해석을 유발할 수 있다**는 점이에요.
- 따라서 분석 전 반드시 **이상치를 탐지하고 필요한 경우 정제하거나 제거하는 작업**이 필요합니다.



- 그럼 **이상치는 왜 문제가 될까요?**
- 이상치는 단순히 보기만 튀는 게 아니고, 실제로 분석 모델에도 **큰 영향을 줍니다.**
- 특히 **평균 기반 계산 예를들어 선형 회귀, PCA 등**을 할 때는 소수의 이상치가 평균값을 크게 왜곡할 수 있기때문에 전체 결과를 왜곡시킬 수 있어요.
- 그래서 사전에 **이상치를 탐지하고, 필요하면 제외하거나 적절히 처리**해야 합니다.

- **이상치의 예시를 한번 볼까요?**
- 예를 들어 어떤 항목의 대부분 값이 1~10 사이에 분포하고 있는데, 거기서 갑자기 300이나 500 같은 값이 나온다면?
- 이건 분명 뭔가 문제가 있는 값일 가능성이 높겠죠.
- 또는 예를 들어 혈압 데이터인데, 값이 0으로 되어 있다면 이건 입력 오류일 가능성도 있습니다.

- 그럼 **어떻게 이상치를 찾을 수 있을까요?**
- 이상치를 찾는 방법은 여러 가지가 있지만, 여기서는 가장 널리 쓰이는 방법인 **IQR 방식**을 사용해볼게요.
- IQR은 사분위수 범위를 의미합니다.
- 1사분위수(Q1)와 3사분위수(Q3)를 기준으로
- **Q1 - 1.5×IQR보다 작거나 Q3 + 1.5×IQR보다 큰 값**은 이상치로 간주합니다.
- 이 방법은 **데이터의 분포에 민감하지 않고, 전형적인 극단값을 잘 걸러주는 장점**이 있어요.

**예제 설명**

- 예시로는 와인 데이터셋을 이용해서 color_intensity 변수에 이상치가 있는지 확인해보도록 하겠습니다.
- 데이터를 먼저 불러오도록 할게요
  - 코드 읽기

- 그리고 앞서 이상치를 파악하는 EDA 과정인 boxplot을 그려보도록 하겠습니다.
- boxplot 결과를 확인해보면, 대부분의 값이 일정한 범위 안에 몰려 있고,
- 위쪽에 몇 개 점으로 찍힌 값들이 보이죠? 바로 저 값들이 **수염 밖에 있는 이상치**입니다.
- 이런 시각화만으로도 이상치를 파악할 수 있지만,
- 실제로 어떤 값들이 이상치인지 구체적으로 알고 싶다면 **IQR 수식**을 이용해서 계산하는 것이 더 정확합니다.

**IQR 방식으로 이상치 추출**

- IQR 수식을 통해 이상치를 확인하는 함수를 코드로 만들어보겠습니다.
  - 코드해석
    - 앞서 Q1과 Q3를 통해 IQR을 계산한다고 설명드렸습니다.
    - 따라서 percentile 함수를 통해 이를 구할 수 있구요

- 다음으로 구한 이상치 함수를 통해 실제 이상치를 확인해보면
- color_intensity 값이 **10.8, 11.75, 13.0**처럼 일반적인 범위를 벗어난 것을 확인할 수 있습니다.

**5.1.2 이상치 처리 – 제거 또는 대체**

- 다음으로는 탐색한 이상치를 **제거하거나 대체하는 방식**으로 데이터를 정제하는 방법에 대해 알아보겠습니다.
- 즉, **이상치를 발견한 후엔 어떤 방식으로 처리할 수 있는지**를 얘기해보겠습니다..

**1. 이상치 제거 방식**

- 첫 번째 방법은 이상치를 **아예 데이터셋에서 제거하는 방법**입니다.

- 코드 해석
  - 보통 이상치를 제거하기 위해서는 IQR 기준으로 이상치라고 판단된 인덱스 번호를 추출하고,
  - 그 인덱스에 해당하는 데이터를 통째로 삭제하도록 합니다.



- 이상치 제거 방식은 단순하고 직관적인 방식인데, 주의할 점이 하나 있습니다.
- 데이터 양이 많고 이상치가 극소수일 때는 유용하지만,
- **데이터 자체가 적거나 이상치가 많을 경우엔 정보 손실이 클 수 있습니다.**
- 저는 이상치가 약 10% 미만이면 그냥 제거를 해버리는 편인데 너무 많은 이상치가 발생한다면 두가지를 고려해봐야합니다.
- 첫번째로 도메인 지식으로 보아 이상치가 아닐 수 있는지입니다.
- 예를들어 분석가인 제가 봤을때는 수식을 통해 데이터를 이상치라고 판단하지만
- 실제 업무를 하시는 분들은 이게 이상치라기보단 어떠한 케이스에 실제로 발생할 수 있는 값일 수 있으며 중요하다고 볼 수 있습니다.
- 따라서 도메인 지식으로 이상치가 아니면 제거하지 않는 첫번쨰 방식을 고려해볼 수 있구요
- 두번쨰로는 너무 많이 제거를 할 수 없으니 대체가 가능한지 입니다.

**2. 이상치 대체 방식**

- 그래서 살펴볼 두 번째 방식은 데이터를 아예 제거하지 않고, **값을 대체하는 방식**입니다.
- 이는 보통 이상치를 **결측치(NaN)**로 먼저 바꿔주고,
- 그다음에 원하는 값으로 대체하는 방식인데요, 대표적으로 **평균값, 중앙값, 혹은 예측 모델 기반 값**으로 채우는 경우가 많습니다.
- 여기서는 간단하게 평균값으로 대체해보도록 하겠습니다.
- 코드해석
  - 이상치를 NaN으로 바꾸고 나서, 평균값을 구해 그 자리 채워주면 됩니다.



- **그렇다면 이상치 제거/ 대체 중 어떤 방식을 써야 할까요?**
- 이건 사실 데이터의 특성과 분석 목적에 따라 달라요.
- **모델이 데이터에 민감한 경우에는 제거하는 편이 낫구요**,
- **데이터가 희소한 경우, 즉 한 줄의 데이터라도 소중한 경우엔 대체**가 적절합니다.
- 그리고 무엇보다 중요한 건, 무작정 제거하거나 대체하는 게 아니라,
- **왜 이 데이터를 제거했는지, 왜 이렇게 채웠는지에 대한 근거를 명확히 남기는 것**이에요.
- 이는 분석의 신뢰도를 높이고, 이후 결과 해석에도 중요한 영향을 줍니다.

**정리하며 마무리**

- 다시한번 정리하자면 이상치 처리에는 대표적으로 **제거**와 **대체** 두 가지 방법이 있습니다.
- 제거는 깔끔하지만 데이터 손실 가능성이 있고, 대체는 유연하지만 대체 값 선정 기준에 따라 분석 결과가 달라질 수 있죠.
- 결국 중요한 건 **데이터에 따라 가장 합리적인 방식으로 처리**하고, 그 과정을 **투명하게 기록**하는 거예요.

[8:30 / 13:30]



## 5.2 범주형 변수 처리

- 우리는 앞서 변수의 종류에 대한 내용을 알아보았습니다.
- 다시 한 번 복습을 하자면, 변수의 종류에는 크게 **범주형과 수치형**이 있는데요,
- **범주형 변수**들은 말 그대로 **‘그룹이나 분류를 나타내는 값’**이라고 보시면 됩니다.
- 예를 들어 ‘성별’, ‘지역’, ‘등급’, ‘제품명’ 같은 것들이죠.
- 그런데 이 범주형 변수는 **컴퓨터 입장에서 그대로는 사용할 수 없는 데이터**입니다.
- 왜냐하면 대부분의 모델들은 **수치 연산 기반의 알고리즘**으로 작동하기 때문입니다.
- 즉, 숫자 계산을 통해 패턴을 찾아내고 예측을 수행하는 구조이기 때문에,
- 문자열로 되어 있는 범주형 데이터는 모델이 이해할 수 없게 됩니다.
- 그래서 반드시 필요한 과정이 바로 **범주형 변수를 수치형으로 변환해주는 ‘인코딩’ 과정**입니다.
- 따라서 우리는 인코딩의 대표적인 두가지 라벨 인코딩과 원핫인코딩에 대해 배워볼것입니다.



### 1. 라벨 인코딩(Label Encoding)

- 첫번쨰로는 **범주형 변수**, 그 중에서도 **라벨 인코딩** 방식에 대해 알아보겠습니다.
- 범주형 변수는 ‘a’, ‘b’, ‘c’처럼 문자의 형태를 가진 값들이 많기 때문에,
- 앞서 설명하였듯 모델에 입력하기 전에 **숫자로 변환해주는 작업**이 필요합니다.
- 이때 사용할 수 있는 가장 기본적인 방법이 바로 **라벨 인코딩(Label Encoding)**입니다.

**라벨 인코딩이란?**

- 라벨 인코딩은 **각 범주형 값을 정수로 치환해주는 방식**입니다.
- 예를 들어 ‘a’, ‘b’, ‘c’라는 범주가 있다면 각각을 0, 1, 2처럼 숫자로 바꿔주는 방식이죠.
- 중요한 건 **변환의 결과인 숫자는 크기나 순서를 나타낼 수 있기에**
- **변환의 대상이 이에 합당한 경우에만 사용하는 것이 바람직하다**는 점입니다.
- 다시 말해, 범주 간에 **실제로 순서가 존재하는 경우**,
- 예를 들어 ‘낮음’, ‘보통’, ‘높음’이나, ‘초급’, ‘중급’, ‘고급’과 같이
- **서열(ordinality)이 있는 변수라면 라벨 인코딩이 적절한 선택**이 될 수 있습니다.

- 예시를  통해 알아보도록 하겠습니다.

  - 우선 ‘b’, ‘a’, ‘c’, ‘d’, ‘a’, ‘b’와 같은 범주형 문자열이 담긴 리스트가 있습니다.

  - 이 리스트를 sklearn의 LabelEncoder를 통해 변환하면,

  - 각 고유 값이 사전순 기준으로 자동 인코딩됩니다.

  - 이때 인코딩되는 과정은 우리의 데이터를 인코더라는 모델이 학습 하듯이 진행되는데요

  - 이 학습이라는 키워드가 파이썬에서는 보통 fit, train으로 나타내곤 합니다.

  - 따라서 fit이라는 키워드가 나왔음을 기억해주시구요

  [코드]

  - 인코더를 확인하면 이런식으로 라벨인코더에 대한 정보가 예쁘게 나옴을 볼 수 있구요

  [코드]

  - 인코딩된 라벨의 결과를 살펴보면 중복이 제거되며 각 개별의 문자가 클래스로 정의되었음을 확인할 수 있습니다.

  - 다음으로는 이 인코딩 모델을 활용하여 라벨을 숫자로 변환하는 작업을 살펴보겠습니다.

  - 이떄, transform() 메서드를 사용하면 해당 리스트를 숫자 배열로 바꿀 수 있습니다.

  [코드]

  - 또, inverse_transform() 메서드를 사용하면 **숫자 값을 다시 원래 문자열로 복원**할 수도 있어요.

  - 이처럼 라벨 인코딩은 **간단하게 문자열 데이터를 정수로 매핑하고 다시 되돌리는 기능**까지 제공합니다.

  [코드]

  

- 라벨 인코딩은 **범주형 데이터를 정수로 바꿔주는 가장 간단한 인코딩 방식**입니다.

- 하지만 모델이 숫자를 크기또는 순서로 오해할 수 있는 위험이 있기에 순서 정보가 있는 변수에 적용할 경우에만 사용하는 것이 적합합니다.

[3:30 / 17:00]

**5.2.2 원핫 인코딩 (One-Hot Encoding)**

- 이번에는 범주형 변수를 수치형으로 바꾸는 또 다른 대표적인 기법인 **원핫 인코딩**에 대해 알아보겠습니다.
- 앞에서 살펴봤던 라벨 인코딩은 범주형 값을 0, 1, 2 같은 정수로 단순히 치환하는 방식이었다면,
- 원핫 인코딩은 **각 범주를 열(column)로 분리해서 0과 1의 값으로 표현**하는 방식입니다.
- 그렇다면 **왜 원핫 인코딩이 필요할까요?**
- 라벨 인코딩은 간단하지만, 숫자 간의 **순서나 크기 의미를 포함하고 있는 것처럼 오해될 수 있는 문제**가 있습니다.
- 예를 들어 ‘Red’=0, ‘Green’=1, ‘Blue’=2처럼 인코딩된 경우, 기계는 마치 ‘Blue’가 ‘Green’보다 2배 크다고 해석할 수 있죠.
- 이런 잘못된 해석을 막기 위해서는, **범주 간에 순서가 없을 때**는 원핫 인코딩을 적용하는 것이 더 안전합니다.

- **원핫 인코딩의 동작 방식**은 각 범주를 개별적인 열로 분리한 뒤, **해당하는 위치에만 1을 부여하고 나머지는 0으로 채웁니다.**
- 예를 들어 색상이라는 컬럼에 해당하는 값이 ‘Red’, ‘Green’, ‘Blue’라고 하면,
- 원핫 이코딩의 수행 결과는 순서대로 1, 0, 0 / 0, 1, 0 / 0, 0, 1과 같이 각 행마다 **고유한 이진 벡터**로 표현될 수 있습니다.
- 여기서 어떤 값에 1이 들어가는지는 사실 중요하지 않으며 다만, 이 세 범주가 구분이 된다라는 점에 유의하여 보시길 바랍니다.

- 실제 방법은 예시를 통해 알아보도록 하겠습니다.

  - 사과 바나나 배 망고라는 유일한 값을 가진 라벨이라는 컬럼이 있다고 가정해보겠습니다.
  
  [코드]

  - 이때 원핫인코딩을위해 sklearn의 원핫인코더를 통해 변환하게 되면 데이터를 학습하는 개념으로 인코딩을 수행하게 됩니다.
  - 따라서 역시 fit이라는 키워드가 나옴을 확인할 수 있구요
  
  [코드]
  
  - 인코딩의 결과를 보면 여러가지 속성이 있는 것을 볼 수 있는데요
  
  - 주요하게 볼 것은 여기 피처 네임과 카테고리입니다.
  
  - 카테고리가 앞서 말씀드린 유일한 값을 가지는 데이터라고 보시면 됩니다.
  
  - 그 이후 우리는 이 원핫인코딩 모델을 사용해서 가지고 있는 데이터를 변환시키는 과정을 수행합니다.
  
  [코드]
  
  - 그 결과는 배열이 됨을 확인할 수 있구요
  
  - 우리는 이 배열을 원본 데이터 프레임에 추가해주어야되기 때문에 다시 데이터 프레임의 형태로 변환을 해주어야합니다.
  
  [코드]
  
  - 변환의 결과는 다음과 같은 데이터 프레임이 될 것이구요
  
  - 이를 원본 데이터프레임의 인덱스 기반으로 재생성한 것이기 때문에 앞서 배운 concat 방식을 통해 쉽게 변환된 데이터 프레임을 생성하는 과정이었습니다.
  
  [코드]
  
  - 마지막으로 라벨인코딩 방식과 동일하게 원래의 범주형 데이터로 변환하는 것도 가능합니다.



- 즉,  **원핫 인코딩은** 각 범주 간의 **순서와 거리 개념이 사라지기 때문에**, 잘못된 수치적 해석을 피할 수 있습니다.
- 반면 **원핫 인코딩의 단점**은 **범주의 개수가 너무 많을 경우 열이 폭발적으로 늘어날 수 있다는 것**입니다.
- 예를 들어 1000개의 고유한 직업군이 있다면, 1000개의 열이 생기는 셈이죠.
- 이런 상황에서는 **차원 축소 기법**이나 **빈도 기반 필터링** 등의 후처리를 고려해볼 수 있습니다.
- 따라서 보유한 데이터 중 범주형데이터의 속성에서 **범주의 개수가 많지 않고**, **순서가 없는 명목형 데이터(nominal)**의 경우에는 원핫 인코딩을 우선 고려하시는 것이 좋습니다.
- 반면 범주 간의 **순위나 크기 관계가 존재하는 경우(예: 학력 수준, 등급 등)**에는 라벨 인코딩이 더 적합할 수 있습니다.
- 항상 모델이 범주형 값을 어떻게 해석할지 고려하면서, **해당 인코딩 기법이 문제에 적절한지 판단하는 것이 중요**합니다.



- 정리하고 넘어가도록 하겠습니다.
- 우리는 이번 섹션에서 데이터 인코딩 방법 중 대표적인 두 가지, **라벨 인코딩과 원핫 인코딩**에 대해 배워보았는데요.
- 언제 어떤 인코딩을 사용하는지는 **데이터의 속성**, 즉 **범주 간의 순서 유무**에 따라 결정된다고 말씀드렸습니다.
- 그런데 여기에는 단순히 데이터 해석의 문제를 넘어서, **우리가 사용하는 모델의 구조와 특성**도 함께 고려되어야 합니다.
- 왜냐하면 이 인코딩 방식이 **수치 기반 모델**, 그리고 **트리 기반 모델이나 딥러닝 모델**에서 **어떻게 받아들여지고 어떤 영향을 미치는지**에 따라 성능이 달라질 수 있기 때문입니다.
- 예를 들어, 숫자의 크기나 거리 개념을 그대로 해석하는 **선형 회귀나 로지스틱 회귀 같은 수치 모델**에서는 라벨 인코딩이 더 직관적이고 간결한 방식이 될 수 있고요,
- 반대로, **분기 기준만을 따지는 트리 기반 모델**이나 **벡터를 처리하는 데 익숙한 딥러닝 모델**에서는 **범주 간 순서를 인식할 필요가 없기 때문에 원핫 인코딩이 더 적합한 경우가 많습니다.**
- 결국 중요한 건, **인코딩을 수행하는 목적과 모델의 방향성에 따라 데이터를 준비해야 한다는 점**입니다.
- 따라서 앞으로는 단순히 범주형이니까 라벨로 할까, 원핫으로 할까 고민하는 수준을 넘어서서, 
- **이 데이터를 어떤 모델에 넣을 건지 그리고 어떤 관점으로 해석되어야 하는지를 함께 고려하시는 것이 훨씬 더 효과적인 접근**이 될 수 있습니다.

[5:00 / 22:00]
