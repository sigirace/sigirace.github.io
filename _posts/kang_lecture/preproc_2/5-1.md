**Warm Up – 데이터 전처리의 중요성**

- 이번에는 **분석 전 반드시 선행되어야 하는 데이터 전처리(Data Preprocessing)**에 대해 간단히 알아보겠습니다.
- 사실 데이터를 분석하거나 모델링을 하기 전에, **그 데이터를 분석에 적합하도록 잘 다듬어놓는 과정**이 먼저 필요합니다.
- 이걸 무시하고 진행하면 아무리 좋은 알고리즘을 써도 결과가 왜곡되거나, 정확도가 낮게 나오는 경우가 정말 많아요.

**좋은 재료가 좋은 결과를 만든다**

- 첫 번째 그림을 보시면, **냉동 상태의 고기, 패티, 빵**을 재료로 햄버거를 만든 뒤 **최종적으로는 고급 스테이크 수준으로 품질을 높이는 과정**이 표현되어 있어요.
- 이건 데이터를 전처리해서 **더 좋은 형태로 바꾸는 과정**과 매우 비슷합니다.
- 즉, 원재료가 아무리 많아도 **가공되지 않으면 쓸모 없듯**, 데이터도 **깨끗하고 구조화된 형태여야 제대로 된 분석이 가능**하다는 거죠.

**목적을 향한 정확한 준비**

- 두 번째 이미지는 **현실에서 데이터를 정리하지 않고 분석하려는 경우**를 보여줍니다.

- 여자 아이가 ATM기를 사용하려하는데, 동전과 지폐를 고민하고 있습니다.

- 아마 동전을 가지고 가면 ATM기기는 동작하지 않겠죠.

- 이때 ATM기는 모델이라고 생각하시면 되고, 동전과 지폐는 데이터라고 볼 수 있습니다.

- 즉, 사용할 모델에 맞는 데이터를 **잘 준비해두는 것이 전체 분석의 출발점**이라는 메시지를 담고 있어요.

  

**데이터 전처리란 무엇인가?**

- 데이터 전처리는 쉽게 말하면 **분석에 적합하도록 데이터를 정리하고 다듬는 작업**이에요.
- 우리가 직접 데이터를 수집하지 않고, **현장에서 생성된 원본 데이터를 그대로 사용할 경우**엔 이상치, 결측치, 오류가 섞여 있을 가능성이 높아요.
- 이런 데이터를 정제하지 않고 분석에 바로 쓰게 되면, **분석 모델이 왜곡되거나, 비효율적인 결과가 나올 수밖에 없습니다.**

**데이터 전처리의 주요 종류**

- 아래는 전처리 과정에서 흔히 수행하는 작업들을 정리해놓은 것입니다.

| **구분**          | **설명**                                                     |
| ----------------- | ------------------------------------------------------------ |
| **데이터 클리닝** | 결측치 채우기, 이상치 제거, 중복 제거 등 기본적인 정리 작업  |
| **데이터 통합**   | 서로 다른 소스의 데이터를 하나로 합치는 작업                 |
| **데이터 변환**   | 스케일 조정, 정규화, 파생 변수 생성 등                       |
| **데이터 축소**   | 필요한 변수만 선택하거나, 차원을 축소하는 작업               |
| **샘플링**        | 너무 많은 데이터가 있을 경우 일부만 추출하거나 샘플을 균형 있게 조정 |
| **데이터 분할**   | 분석이나 모델링을 위해 train/test 셋으로 나누는 작업         |

**결론**

- 결국 데이터 전처리는 **분석의 시작을 위한 준비운동이자, 전체 성과의 50% 이상을 좌우하는 핵심 과정**이에요.
- **좋은 모델을 쓰는 것보다 더 중요한 건, 좋은 데이터를 제공하는 것**이라는 점 꼭 기억하셔야 합니다.
- 이 강의에서도 앞으로 실습이나 분석을 할 때마다 항상 전처리 단계를 먼저 진행하게 될 텐데요,
- **그만큼 분석에 있어 가장 필수적인 기초 체력 훈련**이라고 생각하시면 됩니다.







**5. 데이터 전처리**

- 그럼 데이터 전처리에 대한 강의를 시작해보도록 하겠습니다.

**5.1 이상치 확인 및 정제**

**5.1.1 이상치란?**

- 처음으로는 데이터 전처리 중에서도 **이상치(outlier)**를 어떻게 정의하고, 또 어떻게 찾아내는지에 대해 알아보겠습니다.
- 우리가 데이터를 다룰 때 종종 어떤 값이 유난히 튀는 경우를 보게 되는데요,
- 이런 값들은 대개 **측정 오류, 입력 실수, 혹은 극단적인 상황에서 발생한 값**일 가능성이 높습니다.
- 문제는 이런 이상치가 분석 결과에 **불필요한 영향을 주거나 왜곡된 해석을 유발할 수 있다**는 점이에요.
- 따라서 분석 전 반드시 **이상치를 탐지하고 필요한 경우 정제하거나 제거하는 작업**이 필요합니다.



- 그럼 **이상치는 왜 문제가 될까요?**
- 이상치는 단순히 보기만 튀는 게 아니고, 실제로 분석 모델에도 **큰 영향을 줍니다.**
- 특히 **평균 기반 계산 예를들어 선형 회귀, PCA 등**을 할 때는 소수의 이상치가 평균값을 크게 왜곡할 수 있기때문에 전체 결과를 왜곡시킬 수 있어요.
- 그래서 사전에 **이상치를 탐지하고, 필요하면 제외하거나 적절히 처리**해야 합니다.



- **이상치의 예시를 한번 볼까요?**
- 예를 들어 어떤 항목의 대부분 값이 1~10 사이에 분포하고 있는데, 거기서 갑자기 300이나 500 같은 값이 나온다면?
- 이건 분명 뭔가 문제가 있는 값일 가능성이 높겠죠.
- 또는 예를 들어 혈압 데이터인데, 값이 0으로 되어 있다면 이건 입력 오류일 가능성도 있습니다.



- 그럼 **어떻게 이상치를 찾을 수 있을까요?**
- 이상치를 찾는 방법은 여러 가지가 있지만, 여기서는 가장 널리 쓰이는 방법인 **IQR 방식**을 사용해볼게요.
- IQR은 사분위수 범위를 의미합니다.
- 1사분위수(Q1)와 3사분위수(Q3)를 기준으로
- **Q1 - 1.5×IQR보다 작거나 Q3 + 1.5×IQR보다 큰 값**은 이상치로 간주합니다.
- 이 방법은 **데이터의 분포에 민감하지 않고, 전형적인 극단값을 잘 걸러주는 장점**이 있어요.



**예제 설명**

- 예시로는 와인 데이터셋을 이용해서 color_intensity 변수에 이상치가 있는지 확인해보도록 하겠습니다.
- 데이터를 먼저 불러오도록 할게요
  - 코드 읽기



- 그리고 앞서 이상치를 파악하는 EDA 과정인 boxplot을 그려보도록 하겠습니다.
- boxplot 결과를 확인해보면, 대부분의 값이 일정한 범위 안에 몰려 있고,
- 위쪽에 몇 개 점으로 찍힌 값들이 보이죠? 바로 저 값들이 **수염 밖에 있는 이상치**입니다.
- 이런 시각화만으로도 이상치를 파악할 수 있지만,
- 실제로 어떤 값들이 이상치인지 구체적으로 알고 싶다면 **IQR 수식**을 이용해서 계산하는 것이 더 정확합니다.



**IQR 방식으로 이상치 추출**

- IQR 수식을 통해 이상치를 확인하는 함수를 코드로 만들어보겠습니다.
  - 코드해석
    - 앞서 Q1과 Q3를 통해 IQR을 계산한다고 설명드렸습니다.
    - 따라서 percentile 함수를 통해 이를 구할 수 있구요



- 다음으로 구한 이상치 함수를 통해 실제 이상치를 확인해보면
- color_intensity 값이 **10.8, 11.75, 13.0**처럼 일반적인 범위를 벗어난 것을 확인할 수 있습니다.







**5.1.2 이상치 처리 – 제거 또는 대체**

- 다음으로는 구한 이상치를 **제거하거나 대체하는 방식**으로 데이터를 정제하는 방법에 대해 알아보겠습니다.
- 앞에서 이상치를 탐지하는 방법, 특히 **IQR 방식으로 이상치를 찾는 방법**까지는 살펴봤죠.
- 그렇다면 이제 실제 분석을 할 때, **이상치를 발견한 후엔 어떤 방식으로 처리할 수 있는지** 살펴볼 차례입니다.



**1. 이상치 제거 방식**

- 첫 번째 방법은 이상치를 **아예 데이터셋에서 제거하는 방법**이입니다.

- 코드 해석
  - 보통 이상치를 제거하기 위해서는 IQR 기준으로 이상치라고 판단된 인덱스 번호를 추출하고,
  - 그 인덱스에 해당하는 데이터를 통째로 삭제하도록 합니다.



- 이상치 제거 방식은 단순하고 직관적인 방식인데, 주의할 점이 하나 있습니다.
- 데이터 양이 많고 이상치가 극소수일 때는 유용하지만,
- **데이터 자체가 적거나 이상치가 많을 경우엔 정보 손실이 클 수 있습니다.**
- 실제로 데이터를 삭제하고 shape을 비교해보면,
- 총 178개의 샘플 중 4개가 삭제되어 174개가 남은 걸 확인할 수 있네요.
- 저는 이상치가 약 10% 미만이면 그냥 제거를 해버리는 편인데 너무 많은 이상치가 발생한다면 두가지를 고려해봐야합니다.
- 도메인 지식으로 보아 이상치가 아닐 수 있는지
- 너무 많이 제거를 할 수 없으니 대체가 가능한지 입니다.





**2. 이상치 대체 방식**

- 그래서 살펴볼 두 번째 방식은 데이터를 아예 제거하지 않고, **값을 대체하는 방식**입니다.
- 이는 보통 이상치를 **결측치(NaN)**로 먼저 바꿔주고,
- 그다음에 원하는 값으로 대체하는 방식인데요, 대표적으로 **평균값, 중앙값, 혹은 예측 모델 기반 값**으로 채우는 경우가 많습니다.
- 여기서는 간단하게 평균값으로 대체해보도록 하겠습니다.
- 코드해석
  - 이상치를 NaN으로 바꾸고 나서, 평균값을 구해 그 자리 채워주면 됩니다.



- 결과적으로 이상치였던 인덱스들에는 **동일한 평균값이 채워졌고**, 데이터셋은 그대로 유지됨을 확인할 수 있습니다.





- **그렇다면 이상치 제거/ 대체 중 어떤 방식을 써야 할까요?**
- 이건 사실 데이터의 특성과 분석 목적에 따라 달라요.
- **모델이 민감한 경우에는 제거**,
- **데이터가 희소하거나 결측치로 처리하고 싶은 경우엔 대체**가 적절하겠죠.
- 그리고 무엇보다 중요한 건, 무작정 제거하거나 대체하는 게 아니라,
- **왜 이 데이터를 제거했는지, 왜 이렇게 채웠는지에 대한 근거를 명확히 남기는 것**이에요.
- 이는 분석의 신뢰도를 높이고, 이후 결과 해석에도 중요한 영향을 줍니다.



**정리하며 마무리**

- 다시한번 정리하자면 이상치 처리에는 대표적으로 **제거**와 **대체** 두 가지 방법이 있습니다.
- 제거는 깔끔하지만 데이터 손실 가능성이 있고, 대체는 유연하지만 대체 값 선정 기준에 따라 분석 결과가 달라질 수 있죠.
- 결국 중요한 건 **데이터에 따라 가장 합리적인 방식으로 처리**하고, 그 과정을 **투명하게 기록**하는 거예요.









**5.2 범주형 변수 처리**



**5.2.1 라벨 인코딩(Label Encoding)**

- 이번에는 **범주형 변수**, 그 중에서도 **라벨 인코딩** 방식에 대해 알아보겠습니다.
- 범주형 변수는 ‘a’, ‘b’, ‘c’처럼 문자의 형태를 가진 값들이 많기 때문에,
- 모델에 입력하기 전에 **숫자로 변환해주는 작업**이 필요합니다.
- 이때 사용할 수 있는 가장 기본적인 방법이 바로 **라벨 인코딩(Label Encoding)**입니다.



**라벨 인코딩이란?**

​	•	라벨 인코딩은 **각 범주형 값을 정수로 치환해주는 방식**입니다.

​	•	예를 들어 ‘a’, ‘b’, ‘c’라는 범주가 있다면 각각을 0, 1, 2처럼 숫자로 바꿔주는 방식이죠.

​	•	중요한 건 **변환된 숫자 자체는 크기나 순서의 의미가 없다는 것**입니다.

​	•	숫자 0이 1보다 작다고 해서 ‘a’가 ‘b’보다 작거나 우선이라는 뜻은 아니기 때문에,

이 점은 해석할 때 반드시 주의하셔야 합니다.

**실습 예시 설명**

​	•	우선 ‘b’, ‘a’, ‘c’, ‘d’, ‘a’, ‘b’와 같은 범주형 문자열이 담긴 리스트가 있습니다.

​	•	이 리스트를 sklearn의 LabelEncoder를 통해 변환하면,

각 고유 값이 사전순 기준으로 자동 인코딩됩니다.

​	•	예제에서는 a → 0, b → 1, c → 2, d → 3 순서로 변환되었고,

이후 transform() 메서드를 사용하면 해당 리스트를 숫자 배열로 바꿀 수 있습니다.

​	•	또, inverse_transform() 메서드를 사용하면 **숫자 값을 다시 원래 문자열로 복원**할 수도 있어요.

​	•	이처럼 라벨 인코딩은 **간단하게 문자열 데이터를 정수로 매핑하고 다시 되돌리는 기능**까지 제공합니다.

**주의할 점**

​	•	다만 라벨 인코딩은 순서 정보가 없는 변수에 적용할 경우,

모델이 **숫자의 크기를 순서로 오해할 수 있는 위험이 있습니다.**

​	•	특히 트리 계열 모델(RandomForest, XGBoost 등)은 이 영향을 덜 받지만,

선형 모델(Logistic Regression, Linear Regression 등)에서는 성능 저하나 편향이 생길 수 있습니다.

​	•	따라서 **순서가 없는 범주형 변수에는 원-핫 인코딩(one-hot encoding)**을 사용하는 것이 더 적합할 수 있습니다.

**정리**

​	•	라벨 인코딩은 **범주형 데이터를 정수로 바꿔주는 가장 간단한 인코딩 방식**입니다.

​	•	사이킷런의 LabelEncoder를 활용하면 손쉽게 변환할 수 있고,

나중에 원래 값으로 되돌리는 것도 가능해서 활용도가 높습니다.

​	•	하지만 변수의 **숫자값이 순서로 오해될 수 있다는 점을 항상 유의**하셔야 하며,

데이터와 모델의 특성에 맞게 인코딩 방식을 선택하는 것이 중요합니다.

필요하시면 이후에 이어질 **원-핫 인코딩**, **수치형 변환 시 주의사항**,

**파이프라인 적용 예시** 등도 스크립트 형식으로 구성해드릴 수 있습니다!



