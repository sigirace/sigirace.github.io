{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 전처리 미션(1): 호텔 객실 취소 예측\n",
    "\n",
    "주어진 예약 데이터를 통해 취소될 객실인지 예측을 하는 분석 모델을 생성해봅니다.\n",
    "\n",
    "👀 **데이터 컬럼 소개**\n",
    "\n",
    "| 컬럼명                           | 설명                                                                 |\n",
    "|----------------------------------|----------------------------------------------------------------------|\n",
    "| **is_canceled**                  | 예약이 취소되었는지 여부를 나타내는 이진 변수 (0: 비취소, 1: 취소)    |\n",
    "| **lead_time**                    | 예약 날짜와 실제 도착 날짜 사이의 일수                                |\n",
    "| **stays_in_weekend_nights**      | 주말 동안 머무는 밤의 수                                              |\n",
    "| **stays_in_week_nights**         | 평일 동안 머무는 밤의 수                                              |\n",
    "| **is_repeated_guest**            | 반복 방문자인지 여부를 나타내는 이진 변수 (0: 처음 방문, 1: 반복 방문) |\n",
    "| **previous_cancellations**       | 과거에 취소한 예약 횟수                                              |\n",
    "| **previous_bookings_not_canceled** | 과거에 취소하지 않은 예약 횟수                                      |\n",
    "| **booking_changes**              | 예약 후 변경된 횟수                                                  |\n",
    "| **days_in_waiting_list**         | 대기 명단에 있는 일수                                                |\n",
    "| **adr**                          | 평균 일일 요금 (Average Daily Rate)                                   |\n",
    "| **deposit_type**                 | 보증금의 종류를 나타내는 범주형 변수                                   |\n",
    "\n",
    "## 2.1 EDA(데이터 탐색)\n",
    "\n",
    "### 2.1.1 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 데이터 불러오기\n",
    "hotel = pd.read_csv(\"./data/hotel.csv\")\n",
    "# 데이터 확인\n",
    "hotel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 데이터 개요 확인하기\n",
    "\n",
    "💥 **MISSION**\n",
    "\n",
    "> Dataframe의 info, describe 기능을 활용하여 주어진 데이터를 해석해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_info = hotel.info()\n",
    "hotel_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_desc = hotel.describe()\n",
    "hotel_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔬 **데이터 요약 결과 해석**\n",
    "\n",
    "\n",
    "1. 📌 **is_canceled**\n",
    "   - (값) 0-예약이 취소되지 않음/ 1-예약이 취소 됨 \n",
    "   - (평균값) 0.12\n",
    "   - ☞ **전체 예약 중 약 12%가 취소됨을 의미하고 이는 target 데이터의 불균형을 뜻함**\n",
    "\n",
    "2. **lead_time**\n",
    "   - (결측치) 5개\n",
    "   - (평균) 85.98일/ (최소값)0일/ (최대값) 629일\n",
    "   - ☞ **의미상 2년전 예약하는 경우는 없을 것 같기에 이상치 판단 필요**\n",
    "\n",
    "3. **stays_in_weekend_nights**\n",
    "\t- (평균) 0.89일/ (최대값) 13일\n",
    "\n",
    "4. **stays_in_week_nights**\n",
    "\t- (평균) 2.38일/ (최대값) 30일\n",
    " \n",
    "5. **is_repeated_guest**\n",
    "   - (값) 0-첫 고객/ 1-기존 고객\n",
    "   - (결측치) 358개\n",
    "   - (평균) 3.8\n",
    "   - ☞ **예약 고객 중 약 3.8%가 기존 고객임을 의미하고 이는 feature 데이터의 불균형을 뜻함**\n",
    "\n",
    "6. **previous_cancellations**\n",
    "   - (평균) 0.03회/ (최대값) 26회\n",
    "   - ☞ **취소를 26번한 것은 의미적으로도 어색하고 평균과 차이가 많이 나기 때문에 이상치인지 판단 필요**\n",
    "\n",
    "7. **previous_bookings_not_canceled**\n",
    "   - (평균) 0.17회/ (최대값) 66회\n",
    "\n",
    "8. **booking_changes**\t\n",
    "\t- (평균) 0.27회/ (최대값) 17회\n",
    "\n",
    "9.  **days_in_waiting_list**\n",
    "   - (평균) 1.98일/ (최대값) 379일\n",
    "   - ☞ **평균과 차이가 많이 나기 때문에 이상치인지 판단 필요**\n",
    "\n",
    "10. **adr (Average Daily Rate)**\n",
    "   - (결측치) 1063개\n",
    "   - (평균) 101.41/ (최소값) -6.38/ (최대값) 451.50\n",
    "   - ☞ **요금이 음수일 수 없으니 이상치 확실함**\n",
    "\n",
    "11. **deposit_type**\n",
    "   - ☞ **범주형 데이터이기에 고유값 확인 필요**\n",
    "\n",
    "✅ 예측 목적인 is_cancled가 범주형이기에 분류(classificiation) 분석을 수행함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 시각화\n",
    "\n",
    "**1. 수치형 변수 시각화**\n",
    "\n",
    "💥 **MISSION**\n",
    "\n",
    "> list에 수치형 변수들을 정의해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형\n",
    "continuous_columns = ['lead_time', 'stays_in_weekend_nights', 'stays_in_week_nights', \n",
    "                      'previous_cancellations', 'previous_bookings_not_canceled', \n",
    "                      'booking_changes', 'days_in_waiting_list', 'adr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📍 **히스토그램**\n",
    "- 수치형 변수들을 히스토그램으로 시각하여 이상치에 대한 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(15, 4))\n",
    "\n",
    "for i, column in enumerate(continuous_columns):\n",
    "\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    hotel[column].plot(kind='hist', bins=20, ax=axes[row, col], color='skyblue', edgecolor='black')\n",
    "    axes[row, col].set_title(f'Histogram of {column}')\n",
    "    axes[row, col].set_xlabel(column)\n",
    "    axes[row, col].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📍 **상자 그림**\n",
    "- 히스토그램으로 분포를 파악해보았지만 이상치를 완벽하게 구분해 낼 수 없기에 상자 그림으로 이상치를 명확히 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(15, 4))\n",
    "\n",
    "for i, column in enumerate(continuous_columns):\n",
    "\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    sns.boxplot(x=hotel[column], ax=axes[row, col], color='skyblue')\n",
    "    axes[row, col].set_title(f'Box plot of {column}')\n",
    "    axes[row, col].set_xlabel(column)\n",
    "    axes[row, col].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔬 **수치형 변수 시각화 결과 해석**\n",
    "\n",
    "- 상자 그림으로 표현시 모든 변수에서 이상치를 포함하고 있음\n",
    "- 데이터 상으로는 이상치로 보이나 연속적으로 나타나있기 때문에 업무적으로는 이상치가 아닐 수 있음\n",
    "- 각 변수에서 너무 동떨어진 몇개의 포인트만을 제거하는 보수적인 이상치 제거 방식 적용\n",
    "\n",
    "**2. 범주형 변수 시각화**\n",
    "\n",
    "💥 **MISSION**\n",
    "\n",
    "> list에 범주형 변수들을 정의해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['is_canceled', 'deposit_type', 'is_repeated_guest']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📍 **막대그래프**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "\n",
    "for i, column in enumerate(categorical_columns):\n",
    "\n",
    "    hotel[column].value_counts().sort_index().plot(kind='bar', ax=axes[i], color='skyblue')\n",
    "    axes[i].set_title(f'Bar Plot of {column}')\n",
    "    axes[i].set_xlabel(column)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔬 **범주형 변수 시각화 결과 해석**\n",
    "\n",
    "- 모든 범주형 변수가 불균형임을 확인\n",
    "- deposit_type은 범주형 변수처리 필요\n",
    "\n",
    "**3. 그룹별 평균 시각화**\n",
    "- 분류 문제일 경우 그룹별로 데이터를 시각화하여 파악하는 작업이 효과적일 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹별 평균\n",
    "is_canceled = hotel.groupby('is_canceled').mean()\n",
    "is_canceled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📍 **그룹별 막대 그래프**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹별 막대 그래프\n",
    "fig, axes = plt.subplots(3, 3, figsize=(16, 12))\n",
    "\n",
    "columns = is_canceled.columns.to_list()\n",
    "\n",
    "for i, column in enumerate(columns):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    sns.barplot(x=is_canceled.index, y=column, data=is_canceled, ax=axes[row, col])\n",
    "    axes[row, col].set_title(f'Average {column}')\n",
    "    axes[row, col].set_xlabel(\"is_canceled\")\n",
    "    axes[row, col].set_ylabel(f'Average {column}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔬 **그룹별 평균 시각화 결과 해석**\n",
    "\n",
    "- 예약 취소하지 않음/ 예약 취소 간의 그룹별 평균이 차이가 클 수록 분류에 영향을 많이 미칠 것으로 보임\n",
    "- 모델의 성능이 좋지 못하면 그룹간 평균 차이가 없는 데이터를 피쳐에서 삭제해보는 방법 고려\n",
    "\n",
    "## 2.2 데이터 전처리\n",
    "\n",
    "### 2.2.1 결측치 탐색 및 처리\n",
    "\n",
    "**1. 결측치 탐색**\n",
    "\n",
    "💥 **MISSION**\n",
    "\n",
    "> 컬럼별 결측치의 개수를 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📍**결측치 비율 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in hotel.columns:\n",
    "    if hotel[col].isna().sum() > 0:\n",
    "        print(\"*\"*15)\n",
    "        print(\"결측치 컬럼 :\", col)\n",
    "        print(\"결측치 비율 : {}%\".format(hotel[col].isna().sum()/len(hotel)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔬 **결측치 탐색 결과 해석**\n",
    "\n",
    "- lead_time 결측치 비율이 작기에 제거해도 무방해 보임\n",
    "- is_repeated_guest는 시각화를 통해 대부분이 0이 었으니 0으로 대체하여도 무방해 보임\n",
    "- adr은 수치형이기 때문에 평균값으로 대체\n",
    "  \n",
    "**2. 결측치 처리**\n",
    "\n",
    "💥 **MISSION**\n",
    "\n",
    "> lead_time, is_repeated_guest, adr 컬럼에 대해 근거를 가지고 결측치 처리해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel.dropna(subset=['lead_time'], axis=0, inplace=True)\n",
    "hotel['is_repeated_guest'].fillna(0, inplace = True)\n",
    "hotel['adr'].fillna(hotel['adr'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lead_time은 결측치의 비율이 낮기 때문에 단순 삭제\n",
    "- is_repeated_guset는 시각화 결과 대부분이 0이었기에 대체\n",
    "- adr은 수치형이기 때문에 평균으로 대체\n",
    "\n",
    "📍 **결측치 처리 결과**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 이상치 탐색 및 처리\n",
    "\n",
    "**1. 이상치 탐색**\n",
    "\n",
    "📍 **IQR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr_outliers = pd.DataFrame()\n",
    "\n",
    "for column in continuous_columns:\n",
    "    Q1 = hotel[column].quantile(0.25)\n",
    "    Q3 = hotel[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    # IQR 기준으로 이상치 데이터 필터링\n",
    "    outliers_in_column = hotel[((hotel[column] < (Q1 - 1.5 * IQR)) | (hotel[column] > (Q3 + 1.5 * IQR)))]\n",
    "    # 이상치 데이터를 iqr_outliers 데이터프레임에 추가\n",
    "    iqr_outliers = pd.concat([iqr_outliers, outliers_in_column], axis=0).drop_duplicates()\n",
    "\n",
    "iqr_outliers    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📍 **상위 n%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = pd.DataFrame()\n",
    "\n",
    "for column in continuous_columns:\n",
    "    # 각 연속형 변수에 대해 상위 95%에 해당하는 임계값 계산\n",
    "    threshold = hotel[column].quantile(0.99)\n",
    "    # 임계값보다 큰 데이터만 필터링하여 이상치로 판단\n",
    "    outliers_in_column = hotel[hotel[column] > threshold]\n",
    "    # 이상치 데이터를 outliers 데이터프레임에 추가\n",
    "    outliers = pd.concat([outliers, outliers_in_column], axis=0).drop_duplicates()\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💥 **MISSION**\n",
    "\n",
    "> IQR 방식과 n% 방식의 이상치 비율을 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"이상치 비율 iqr:\", len(iqr_outliers)/len(hotel)*100)\n",
    "print(\"이상치 비율 n%:\", len(outliers)/len(hotel)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔬 **이상치 탐색 결과 해석**\n",
    "\n",
    "- 시각화를 통해 이상치로 보여도 데이터들이 연속적으로 존재하여 업무적으로는 이상치가 아닐 수 있음을 확인\n",
    "- iqr 방식을 수행하면 너무 많은 데이터가 제거됨\n",
    "- 비즈니스 로직을 모르기 때문에 보수적으로 이상치 제거\n",
    "\n",
    "**2. 이상치 제거**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"원본 데이터셋 개수\", len(hotel))\n",
    "for column in continuous_columns:\n",
    "    # 각 연속형 변수에 대해 상위 percent 95%에 해당하는 임계값 계산\n",
    "    threshold = hotel[column].quantile(0.99)\n",
    "    # 임계값보다 작은 데이터만 필터링\n",
    "    hotel = hotel[hotel[column] <= threshold]\n",
    "print(\"이상치 처리 후 개수\", len(hotel))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 범주형 변수 처리\n",
    "\n",
    "**1. 인코딩**\n",
    "\n",
    "💥 **MISSION**\n",
    "\n",
    "> deposit_type에 대해 알맞은 범주형 변수 처리 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hotel은 순서형 변수가 아닌 명목형 변수이므로 원핫인코딩을 사용하여 변환\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 원핫 인코딩 객체 생성 및 학습\n",
    "oh = OneHotEncoder(sparse_output=False)\n",
    "oh.fit(hotel[['deposit_type']])\n",
    "\n",
    "# 원핫 인코딩 수행\n",
    "oh_encoded = oh.transform(hotel[['deposit_type']])\n",
    "\n",
    "# 데이터프레임으로 변환, 열 이름 지정\n",
    "oh_hotel = pd.DataFrame(oh_encoded.astype('int'), columns=oh.get_feature_names_out(['deposit_type']), index=hotel.index)\n",
    "\n",
    "oh_hotel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 데이터 병합**\n",
    "\n",
    "💥 **MISSION**\n",
    "\n",
    "> hotel 데이터에서 변환을 수행한 deposit_type 컬럼은 삭제하고, 인코딩 수행한 변수를 열 기준으로 concat 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel = pd.concat([hotel.drop('deposit_type', axis=1), oh_hotel], axis=1)\n",
    "hotel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔬 **범주형 변수처리 결과 해석**\n",
    "\n",
    "- deposit_type에 3개의 범주형 데이터가 있었고, 이를 원핫 인코딩을 통해 변환\n",
    "- 3개의 범주형 데이터를 3개의 컬럼으로 나타내게 변환하고 이를 원본 데이터에 병합\n",
    "\n",
    "### 2.2.4 데이터 분할\n",
    "\n",
    "💥 **MISSION**\n",
    "\n",
    "> hotel 데이터를 train(0.7)/ validation(0.2)/ test(0.1) 비율로 분할 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 분할\n",
    "train_data, test_data = train_test_split(hotel, test_size = 0.2, random_state=1004, stratify=hotel['is_canceled'])\n",
    "validation_data, test_data = train_test_split(test_data, test_size = 0.5, random_state=1004, stratify=test_data['is_canceled'])\n",
    "\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "validation_data.reset_index(drop=True, inplace=True)\n",
    "test_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print('train data :', train_data.shape)\n",
    "print('validation data :', validation_data.shape)\n",
    "print('test data :', test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 데이터 스케일링\n",
    "\n",
    "**1. 데이터 범위 확인**\n",
    "\n",
    "💥 **MISSION**\n",
    "\n",
    "> train_data의 요약 통계 정보를 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔬 **데이터 범위 확인 결과 해석**\n",
    "\n",
    "- lead_time, days_in_waiting_list, adr 변수가 다른 값에 비해 큰값을 가지고 있음을 확인\n",
    "\n",
    "**2. 스케일링 수행(훈련 데이터)**\n",
    "\n",
    "💥 **MISSION**\n",
    "\n",
    "> train_data에 알맞은 스케일링 수행해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 분석이기에 standard scaling을 사용하여 데이터 스케일링\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale_columns = ['lead_time', 'days_in_waiting_list', 'adr']\n",
    "\n",
    "StdScaler = StandardScaler()\n",
    "# Train 데이터의 fitting과 스케일링\n",
    "StdScaler.fit(train_data[scale_columns])\n",
    "scaled_data = StdScaler.transform(train_data[scale_columns])\n",
    "\n",
    "# 데이터프레임 변환\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=scale_columns)\n",
    "scaled_train_data = pd.concat([train_data.drop(scale_columns, axis=1), scaled_df], axis=1)\n",
    "scaled_train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. 스케일링 적용(검증, 테스트 데이터)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증용 데이터 스케일링 적용\n",
    "scaled_data = StdScaler.transform(validation_data[scale_columns])\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=scale_columns)\n",
    "scaled_val_df = pd.concat([validation_data.drop(scale_columns, axis=1), scaled_df], axis=1)\n",
    "\n",
    "scaled_val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 스케일링 적용\n",
    "scaled_data = StdScaler.transform(test_data[scale_columns])\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=scale_columns)\n",
    "scaled_test_df = pd.concat([test_data.drop(scale_columns, axis=1), scaled_df], axis=1)\n",
    "\n",
    "scaled_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.6 데이터 불균형 문제 처리\n",
    "\n",
    "**1. Target 불균형 확인**\n",
    "\n",
    "💥 **MISSION**\n",
    "\n",
    "> train_data에서 Target인 is_canceled의 비율을 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio0 = round(len(train_data[train_data['is_canceled']==0])/len(train_data)*100, 2)\n",
    "ratio1 = round(len(train_data[train_data['is_canceled']==1])/len(train_data)*100, 2)\n",
    "print('0 비율: {}%'.format(ratio0))\n",
    "print('1 비율: {}%'.format(ratio1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 오버샘플링 수행**\n",
    "\n",
    "💥 **MISSION**\n",
    "\n",
    "> is_canceled 컬럼을 기준으로 오버샘플링 수행해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "# 오버샘플링 수행\n",
    "oversample = RandomOverSampler() \n",
    "\n",
    "# 데이터 분할\n",
    "x = scaled_train_data.drop('is_canceled', axis=1)\n",
    "y = scaled_train_data['is_canceled']\n",
    "\n",
    "x_over, y_over = oversample.fit_resample(x, y)\n",
    "print(Counter(y_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔬 **오버샘플링 결과 해석**\n",
    "\n",
    "- 오버샘플링을 통해 0과 1의 비율을 동등하게 만듦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 예측 모델 생성\n",
    "\n",
    "### 2.3.1 선형 모델 생성 및 학습 (통계기반)\n",
    "\n",
    "📍 **Support Vector Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC() # 선형 커널 사용\n",
    "svc.fit(x_over, y_over)\n",
    "\n",
    "print('train 정확도 :', svc.score(x_over, y_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 트리기반 모델 생성 및 학습\n",
    "\n",
    "📍 **RandomForestClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1004)\n",
    "rf.fit(x_over, y_over)\n",
    "\n",
    "print('train 정확도 :', rf.score(x_over, y_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 분석 모델 성능 평가\n",
    "\n",
    "분석 수행시 validation 데이터로 평가를 하며 모델의 파라미터 혹은 변수를 수정하는 튜닝 과정을 거친 뒤, test 데이터로 평가합니다. 이번 실습에서는 튜닝은 생략하고 validation 데이터와 test 데이터를 함께 test 데이터로 구성하여 최종 평가를 수행합니다.\n",
    "\n",
    "**1. 데이터 병합**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행 기준으로 병합\n",
    "total_test_data = pd.concat([scaled_val_df, scaled_test_df], axis=0)\n",
    "total_test_data.reset_index(drop=True, inplace=True)\n",
    "total_test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 데이터 분할**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = total_test_data.drop('is_canceled', axis=1)\n",
    "y_test = total_test_data['is_canceled'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 성능 평가(1)\n",
    "\n",
    "📍**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# svc 모델 성능 평가\n",
    "print('SVC 성능평가')\n",
    "y_pred=svc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('test 정확도 :', svc.score(X_test, y_test))\n",
    "\n",
    "# rf 모델 성능 평가\n",
    "print('RF 성능평가')\n",
    "y_pred=rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('test 정확도 :', rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔬 **Confusion Matrix 성능평가 결과 해석**\n",
    "\n",
    "**1. Accuracy (정확도): 0.89**\n",
    "- 전체 3777개의 샘플 중 89%를 모델이 올바르게 예측했습니다.\n",
    "\n",
    "**2. Macro Average: 각 클래스의 성능을 동일하게 고려한 평균입니다. 클래스 1의 성능이 낮아, 전체적인 성능이 낮아집니다.**\n",
    "- Precision: 0.74\n",
    "- Recall: 0.70\n",
    "- F1-score: 0.72\n",
    "\n",
    "**3. Weighted Average: 각 클래스의 샘플 수를 가중치로 사용하여 계산된 평균입니다. 클래스 0의 샘플 수가 많기 때문에, 클래스 0의 성능이 전반적인 평균에 더 큰 영향을 미칩니다.**\n",
    "- Precision: 0.88\n",
    "- Recall: 0.89\n",
    "- F1-score: 0.89"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 성능 평가(2)\n",
    "\n",
    "📍**ROC, AUC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# 테스트 데이터에 대한 예측 확률 계산\n",
    "y_pred_prob = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ROC 커브 계산\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# AUC 계산\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# ROC 커브 그리기\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
