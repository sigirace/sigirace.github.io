{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pandas 기초\n",
    "\n",
    "## 3.1 Pandas 데이터 구조\n",
    "\n",
    "- Pandas에서 제공하는 데이터 구조는 Series와 DataFrame이 있음\n",
    "\n",
    "### 3.1.1 Series\n",
    "\n",
    "- 각 값에 `라벨(인덱스)`이 있고 `하나의 데이터 형식`으로 이루어진 `1차원 배열`\n",
    "- `라벨`로 데이터에 접근 할 수 있음\n",
    "\n",
    "### 3.1.2 DataFrame\n",
    "\n",
    "- 행과 열에 라벨이 있는 2차원 배열 ☞ Excel\n",
    "- 각 `열`은 `서로 다른 데이터 타입`을 지닐 수 있음\n",
    "\n",
    "<p align=\"center\"><img src=\"https://github.com/sigirace/page-images/blob/main/kang_lectures/python_preprocessing/s_p.png?raw=true\" width=\"600\" height=\"300\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 DataFrame 기본\n",
    "\n",
    "Pandas의 DataFrame을 사용하여 분석하기 위한 가장 첫 단계는 데이터를 호출하고 데이터의 내용과 요약, 통계정보를 확인하는 것입니다. 데이터나 분석 도구에 따라 컬럼명이나 컬럼의 타입을 변경해야 할 때도 있습니다.\n",
    "\n",
    "### 3.2.1 Pandas 사용 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- as 문법을 통해 pandas를 별칭 pd로 사용\n",
    "\n",
    "### 3.2.2 DataFrame 선언하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📍 **DataFrame 생성의 다양한 방법**\n",
    "\n",
    "Case1. 배열 사용\n",
    "\n",
    "- columns 인자를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "array = [['kor', 80],['math',70]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><img src=\"https://github.com/sigirace/page-images/blob/main/kang_lectures/python_preprocessing/array.png?raw=true\" width=\"200\" height=\"150\"></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(array, columns=['subject', 'score'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case2. dictionary를 사용\n",
    "- dictionary의 value는 배열 형태여야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'subject':['kor', 'math'], 'score':[80, 70]})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 DataFrame 출력하기\n",
    "\n",
    "- `sklearn` 패키지의 기본 제공 데이터 세트인 iris 데이터를 불러오고 출력\n",
    "- `head()`, `tail()` 함수를 사용해 데이터를 부분적으로 확인\n",
    "- 함수의 인자로 아무 숫자도 지정하지 않으면 컬럼명을 포함하여 6줄을 출력\n",
    "\n",
    "📍 **sklearn 패키지**\n",
    "\n",
    "scikit-learn은 Python에서 데이터 과학과 머신러닝을 위한 강력한 라이브러리입니다. 데이터 전처리, 모델 학습, 평가, 그리고 다양한 머신러닝 알고리즘을 제공하여 데이터 분석과 모델링 작업을 쉽게 수행할 수 있도록 도와줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임의 상위 행만 확인\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임의 하위 행만 확인\n",
    "iris.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 DataFrame 요약 및 통계 확인하기\n",
    "\n",
    "- 데이터의 내용을 확인했다면 그 이후에 데이터프레임의 요약, 통계정보를 확인함\n",
    "- `info()` 함수를 통해 `총 데이터의 건수`, `각 컬럼의 데이터 형식` 그리고 `결측치의 건수`를 확인할 수 있음\n",
    "- 수치형 컬럼이 존재하는 경우 `describe()`함수를 사용하여 수치형 컬럼들의 `n-percentile` 분포도, 평균값, 최대값, 최소값을 확인할 수 있음\n",
    "- 이러한 과정은 `EDA`에 속함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔬 **info 함수 결과해석**\n",
    "\n",
    "- iris 데이터는 150개의 행과 4개의 컬럼을 가지고 있음\n",
    "- 각 컬럼의 이름은 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'\n",
    "- `Non-Null Count`가 모두 `non-null` 이므로 `결측값`을 가지고 있지 않음\n",
    "- 모든 데이터의 타입은 `float64`로 실수형 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔬 **describe 함수 결과해석**\n",
    "\n",
    "- describe를 확인하는 경우 주로 mean, min, max를 확인\n",
    "- iris의 sepal length (cm) 컬럼의 범위는 4.3~7.9\n",
    "- petal width (cm) 컬럼의 범위는 0.1~2.5 ☞ 크기가 매우 작은 것이 존재함\n",
    "\n",
    "\n",
    "✏️ **더 알아보기** <br>\n",
    "- 😗 : 상대적으로 값이 작은 컬럼이 모델에 미치는 영향이 어떻게 되나요?\n",
    "- 😀 : 데이터 값의 크기가 상대적으로 작은 경우 실제로 큰 관계가 있더라도 다른 컬럼들에 비해 분석모델에 영향을 덜 미칠 수 있습니다. 따라서 모델링 전 변수가 관계로만 영향을 미칠 수 있도록 전처리를 수행해야 합니다.\n",
    "\n",
    "### 3.2.5 DataFrame 인덱스 핸들링\n",
    "\n",
    "- 인덱스의 추가/변경/삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 데이터프레임 확인\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index를 list로 변경하여 확인\n",
    "list(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index 수정\n",
    "df.index = ['A', 'B']\n",
    "\n",
    "# 인덱스가 변경된 데이터프레임 확인\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 **set_index**\n",
    "\n",
    "DataFrame 내의 열을 인덱스로 변경<br>\n",
    "> DataFrame.set_index(keys, drop=True, append=False, inplace=True)\n",
    "\n",
    "- keys: 인덱스로 사용하고자 하는 컬럼의 이름을 문자형으로 입력\n",
    "- drop: 인덱스로 세팅한 컬럼을 DataFrame 내에서 삭제할지를 결정\n",
    "- append: 기존에 존재하던 인덱스를 삭제할지, 유지할지를 결정\n",
    "- inplace: 원본 객체를 변경할지를 결정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 열을 인덱스로 지정 후 삭제\n",
    "# 기존의 인덱스는 삭제됨\n",
    "# 원본 df를 영구히 변경\n",
    "df.set_index('subject', drop=True, append=False, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 **reset_index**\n",
    "\n",
    "인덱스를 0부터 시작하는 정수로 재설정\n",
    "\n",
    "> DataFrame.reset_index(drop=False, inplace=False)\n",
    "\n",
    "- drop: 기존 인덱스를 DataFrame 내에서 삭제할지, 컬럼으로 추가할지를 결정\n",
    "- inplace: 원본 객체를 변경할지를 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=False, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.6 DataFrame의 열(column) 핸들링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임의 열 확인\n",
    "iris.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임의 열 이름 변경\n",
    "iris.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.8 DataFrame 컬럼의 데이터 타입 확인 및 변경\n",
    "\n",
    "- dtypes를 통해 각 컬럼의 속성을 확인할 수 있음\n",
    "- astype()을 통해 데이터 타입을 변경할 수 있음\n",
    "\n",
    "📍 **데이터프레임의 컬럼**\n",
    "- int: 정수형\n",
    "- float: 실수형, 소수점을 가짐\n",
    "- bool: True or False\n",
    "- datetime: 날짜와 시간 표현\n",
    "- object: 문자열&복합형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 컬럼의 데이터 타입 확인\n",
    "iris.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# astype을 이용한 데이터 타입 변경\n",
    "iris['sepal_length'] = iris['sepal_length'].astype('int')\n",
    "iris.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 row/ column 핸들링\n",
    "\n",
    "데이터프레임은 행과 열이 각각의 label을 가지고 있어 레이블의 이름이나 그 위치를 통해 행 또는 열을 추가하고 삭제할 수 있습니다.\n",
    "\n",
    "### 3.3.1 row/ column의 선택 조회\n",
    "\n",
    "**1. row 선택 조회**\n",
    "- 슬라이싱을 통한 행 선택\n",
    "\n",
    "📌 **슬라이싱**\n",
    "\n",
    "시작과 끝을 지정해 잘라내는 방법, 데이터프레임이 아닌 list 등에서도 사용 가능\n",
    "\n",
    "> DataFrame[n:m]\n",
    "\n",
    "- n번째 행부터 m-1번째 행까지 데이터프레임을 자름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "iris = load_iris()\n",
    "iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# 1번째 행부터 4-1번째 행의 데이터 확인\n",
    "iris[1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터프레임은 0번 인덱스부터 수행함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. column 선택 조회**\n",
    "- 컬럼명 또는 컬럼명의 리스트를 이용함\n",
    "\n",
    "🔥 **key point**\n",
    "- 컬럼명 ☞ Series\n",
    "- 컬럼명 리스트 ☞ DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼명으로 데이터 확인\n",
    "iris['petal length (cm)'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼명의 리스트로 데이터 확인\n",
    "iris[['petal length (cm)', 'petal width (cm)']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 row와 column 선택 조회**\n",
    "\n",
    "- iloc 또는 loc을 사용해 행과 열 모두 지정할 수 있음\n",
    "\n",
    "📌 **iloc**\n",
    "\n",
    "정수로 특정 행과 열을 선택하고 싶은 경우 사용\n",
    "\n",
    "> DataFrame.iloc[row, column]\n",
    "\n",
    "- 인수를 하나만 설정할 경우 행을 지정\n",
    "- 인수를 두 개 설정할 경우 순서대로 행과 열 지정\n",
    "- 인수는 정수, 리스트, 슬라이싱을 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 슬라이싱, 열은 지정하지 않았기에 모든 열을 선택\n",
    "# 1번째 행부터 4-1번째 행의 데이터 확인\n",
    "iris.iloc[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행은 리스트로 특정 인덱스들을 지정\n",
    "# 열은 슬라이싱으로 특정 열 범위 지정\n",
    "iris.iloc[[1,3,5],2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 **loc**\n",
    "\n",
    "레이블(인덱스 이름 혹은 컬럼명)로 행과 열을 선택하고 싶은 경우 사용\n",
    "\n",
    "> DataFrame.loc[row, column]\n",
    "\n",
    "- 인수를 하나만 설정할 경우 행을 지정\n",
    "- 인수를 두 개 설정할 경우 순서대로 행과 열 지정\n",
    "- 인수는 정수, 리스트, 슬라이싱을 사용할 수 있음\n",
    "- loc의 슬라이싱은 일반적인 파이썬의 슬라이싱과 다름 (진짜 시작부터 끝)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc에 대한 이해를 위해 인덱스를 변경\n",
    "iris_index = list(iris.index)\n",
    "iris_index[0] = '파이썬'\n",
    "iris.index = iris_index\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '파이썬' 라벨의 행부터 3번째 행까지 데이터 확인\n",
    "iris.loc['파이썬':3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼명도 슬라이스로 지정할 수 있음\n",
    "iris.loc[['파이썬', 3, 5], 'sepal width (cm)':'petal width (cm)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. 선택한 값 변경하기**\n",
    "\n",
    "- 특정한 위치를 지정했다면 다른 값을 대입해 값을 변경할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 값을 변경할 데이터 확인\n",
    "print(iris.loc['파이썬', 'sepal length (cm)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 값 변경\n",
    "iris.loc['파이썬', 'sepal length (cm)'] = 100\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 row/ column Concat\n",
    "\n",
    "concat은 데이터프레임간의 단순한 연결을 의미합니다. concat을 통해 두 개 이상의 데이터프레임을 열 혹은 행 방향으로 붙일 수 있으며, 이를 통해 열 혹은 행을 추가할 수 있습니다.\n",
    "\n",
    "📌 **concat**\n",
    "\n",
    "> pandas.concat(objs, axis=0, ignore_index=False)\n",
    "\n",
    "- objs: concat을 실행할 객체의 리스트\n",
    "- axis: 0이면 행 추가, 1이면 열 추가\n",
    "- ignore_index: True이면 기존 index를 무시하고 0부터 시작하는 정수로 재설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = pd.DataFrame({'국어':[80,90,70], '수학':[90,70,60]}, index=['홍길동', '김철수', '이영희'])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_student = pd.DataFrame({'국어':[100], '수학':[100]}, index=['엄친아'])\n",
    "new_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행 추가\n",
    "score = pd.concat([score, new_student], axis=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_subject = pd.DataFrame({'과학':[100, 90, 80, 100]}, index=['홍길동', '김철수', '이영희', '엄친아'])\n",
    "new_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 열 추가\n",
    "score = pd.concat([score, new_subject], axis=1)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 row/column 삭제\n",
    "\n",
    "- drop() 함수를 사용하여 행과 열을 삭제할 수 있음\n",
    "- 행과 열 둘다 지정하여 삭제하는 것은 불가능함\n",
    "\n",
    "📌 **drop**\n",
    "\n",
    "> DataFrame.drop(index=None, climns=None, inplace=False)\n",
    "\n",
    "- index: 삭제할 행의 인덱스 혹은 인덱스의 리스트를 지정\n",
    "- columns: 삭제할 컬럼의 이름 혹은 컬럼명의 리스트를 지정\n",
    "- inplace: True이면 작업 수행과 동시에 원본에 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index를 기준으로 행 삭제\n",
    "score = score.drop('엄친아', inplace=False)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column명을 기준으로 열 삭제\n",
    "score = score.drop(columns=['과학'], inplace=False)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 조건에 맞는 데이터 탐색 및 수정\n",
    "\n",
    "### 3.4.1 조건 탐색\n",
    "\n",
    "📌 **데이터프레임 조건 탐색**\n",
    "> DataFrame[조건식]\n",
    "\n",
    "**1. 조건이 하나인 경우**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score[score['국어'] > 80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 조건이 두 개인 경우**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 둘 다 만족해야 함 (and)\n",
    "score[(score['국어'] > 70) and (score['수학'] > 80)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 둘 중 하나만 만족해도 됨 (or)\n",
    "score[(score['국어'] > 85) or (score['수학'] > 85)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 결측값 탐색 및 수정\n",
    "\n",
    "**1. 결측값 탐색**\n",
    "\n",
    "- 결측값 탐색 함수: isna(), isnull()\n",
    "- 결측값이 아닌 값 탐색: notna(), notnull()\n",
    "- 결측값 탐색의 결과는 원본 데이터프레임에 True, False로 나타남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측값 탐색을 위한 결측치 추가\n",
    "new_student = pd.DataFrame({'수학':[100]}, index=['엄친아'])\n",
    "score = pd.concat([score, new_student], axis=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 탐색\n",
    "score.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측이 아닌 값 탐색\n",
    "score.notna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 결측치 합계**\n",
    "\n",
    "- True는 1 False는 0으로 집계\n",
    "- sum()은 컬럼별, sum(axis=1)은 행별 집계 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 탐색 후 결측치 개수 확인 (열별)\n",
    "score.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 탐색 후 결측치 개수 확인 (행별)\n",
    "score.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. 결측값 제거**\n",
    "\n",
    "- dropna()는 결측값이 존재하는 행 또는 열을 삭제\n",
    "\n",
    "📌 **dropna**\n",
    "\n",
    "> DataFrame.dropna(axis=0, how='any', thresh=None, inplace=False)\n",
    "\n",
    "- axis: 0이면 결측값이 포함된 행삭제, 1이면 결측값이 포함된 열 삭제\n",
    "- how: 'any'면 결측값이 존재한 모든 행/열 삭제, 'all'이면 모든 값이 결측값일때 삭제\n",
    "- thresh: 정수 값을 지정하면 결측값이 아닌 값이 그보다 많을 때 행 또는 열을 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 제거\n",
    "# inplace=True로 설정하면 원본 데이터프레임이 변경됨\n",
    "score.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. 결측값 대체**\n",
    "\n",
    "- fillna() 함수를 활용하여 다양한 방법으로 결측값을 대체할 수 있음\n",
    "\n",
    "📌 **fillna**\n",
    "\n",
    "> DataFrame.fillna(value=None, method=None, axis=None, inplace=False)\n",
    "\n",
    "- value: 결측치를 대체할 값 직접 입력\n",
    "- method: 'pad', 'fill'은 이전값 대체, 'backfill', 'bfill'은 다음 값으로 대체\n",
    "- axis: 0이면 행 방향 대체, 1이면 열 방향 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0으로 대체\n",
    "score.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균값으로 대체\n",
    "score.fillna(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전값 대체\n",
    "score.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음값 대체\n",
    "score.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✏️ **더 알아보기** <br>\n",
    "- 😗 : 결측값이 존재하면 지우는 방법과 대체하는 방법 중 무엇을 사용해야 하나요?\n",
    "- 😀 : 데이터 셋이 클 경우 결측값이 약 5%미만이면 지워도 무방하고 그렇지 않다면 적절한 값으로 대체하는 것이 분석 모델의 설명력이 높아집니다.\n",
    "\n",
    "**5. 중복행 삭제**\n",
    "\n",
    "- drop_duplicates() 함수를 사용해 중복을 삭제할 수 있음\n",
    "\n",
    "📌 **drop_duplicates**\n",
    "\n",
    "> DataFrame.drop_duplicates()\n",
    "\n",
    "- inplace가 없으므로 재할당 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복행 생성 ☞ 수학 점수가 중복됨\n",
    "score.loc['이영희' , '수학'] = 70\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼을 지정하지 않은 경우\n",
    "score.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼을 지정\n",
    "score['수학'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 데이터 정렬\n",
    "\n",
    "### 3.5.1 인덱스 기준 정렬\n",
    "\n",
    "📌 **sort_index**\n",
    "\n",
    "> DataFrame.sort_index(asccending=True, inplace=False)\n",
    "\n",
    "- ascending: True-오름차순, False-내림차순"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "# 데이터 불러오기\n",
    "iris = load_iris()\n",
    "# 데이터프레임으로 변환\n",
    "iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 기준 내림차순 정렬\n",
    "iris.sort_index(ascending=False, inplace=True)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 컬럼 기준 정렬\n",
    "\n",
    "📌 **sort_values**\n",
    "\n",
    "> DataFrame.sort_values(by, ascending=True, inplace=False)\n",
    "\n",
    "- by: 정렬 기준으로 사용할 컬럼 혹은 컬럼 리스트\n",
    "  - 리스트일 경우 리스트의 순서대로 우선순위 부여\n",
    "- ascending: True-오름차순, False-내림차순"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sepal length (cm) 컬럼 기준 내림차순 정렬\n",
    "iris.sort_values(by='sepal length (cm)', ascending=False, inplace=True)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼명 리스트로 정렬\n",
    "# 각각 다른 정렬 방식을 적용할 수 있음\n",
    "iris.sort_values(by=['sepal length (cm)', 'sepal width (cm)'], ascending=[False, True], inplace=True)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 데이터 병합\n",
    "\n",
    "앞서 수행한 concat(연결)과 다른 방식인 merge(병합) 방식은 두 데이터프레임이 동시에 가지고 있는 특정한 컬럼의 값인 key를 기준으로 병합을 수행한다.\n",
    "\n",
    "<p align=\"center\"><img src=\"https://github.com/sigirace/page-images/blob/main/kang_lectures/python_preprocessing/merge.png?raw=true\" width=\"800\" height=\"450\"></p>\n",
    "\n",
    "📌 **merge**\n",
    "\n",
    "> pandas.merge(left, right, how='inner', on=None)\n",
    "\n",
    "- left: 왼쪽에 해당하는 데이터프레임\n",
    "- right: 오른쪽에 해당하는 데이터프레임\n",
    "- how: 병합 방식\n",
    "- on: key 컬럼 집합\n",
    "\n",
    "🔥 **Key Point**\n",
    "- 병합은 이미지로 생각하여 수행하면 이해하기 편함\n",
    "- 병합시 key 컬럼은 존재하나 동일한 값이 없는 경우 NaN을 반환함\n",
    "- 병합후 결측치에 대한 처리 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 병합 예시를 위한 데이터프레임 생성\n",
    "product = pd.DataFrame({'product':['a','b','c','d','e'], 'price':[100, 150, 200, 250, 300]})\n",
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 병합 예시를 위한 데이터프레임 생성\n",
    "sale = pd.DataFrame({'product':['a','b','c'], 'sale':[10, 20, 30]})\n",
    "sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join 수행\n",
    "inner = pd.merge(product, sale, on='product', how='inner')\n",
    "inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer join 수행\n",
    "outer = pd.merge(product, sale, on='product', how='outer')\n",
    "outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join 수행\n",
    "left = pd.merge(product, sale, on='product', how='left')\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right join 수행\n",
    "right = pd.merge(product, sale, on='product', how='right')\n",
    "right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📍 **결측치 처리 복습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer 데이터프레임에 대한 결측치 확인\n",
    "outer.isna().sum(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sale 컬럼에 2개의 결측치 있음을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 대체\n",
    "outer.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 세일을 하지 않는 품목으로 할인율 0 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 데이터 요약\n",
    "\n",
    "데이터를 요약하여 원하는 정보를 얻는 것은 데이터가 지닌 값의 특징을 알게 해줍니다. 이와 비슷한 것을 3.2에서 수행해보았는데, 이번 장에서는 세부적으로 데이터를 요약하여 집계하는 방법을 알아보겠습니다.\n",
    "\n",
    "### 3.7.1 그룹화 집계\n",
    "\n",
    "👀 **Definition**\n",
    "> 그룹화는 하나 이상의 데이터를 조건에 따라 여러개 그룹으로 묶는 것\n",
    "\n",
    "- groupby() 함수를 사용함\n",
    "\n",
    "📌 **groupby**\n",
    "\n",
    "> DataFrame.groupby(by=None, axis=0, sort=False, dropna=True).FUN()\n",
    "\n",
    "- by: 그룹을 결정하는 데 사용\n",
    "- axis: 행(0)과 열(1) 지정\n",
    "- sort: 집계된 내용을 정렬할지 여부\n",
    "- dropna: True이면 결측값이 행/열과 함께 삭제, False이면 결측값도 그룹의 키로 처리\n",
    "- FUN: 집계함수\n",
    "\n",
    "🔥 **집계함수**\n",
    "\n",
    "- count(): 값의 개수\n",
    "- sum(): 값들의 합\n",
    "- std(): 표준편차\n",
    "- var(): 분산\n",
    "- min(): 최솟값\n",
    "- max(): 최대값\n",
    "- mean(): 평균값\n",
    "- median(): 중앙값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "IRIS = load_iris()\n",
    "iris = pd.DataFrame(IRIS.data, columns=IRIS.feature_names)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 열 추가\n",
    "# map을 사용해 target 값{0,1,2}을 꽃 이름으로 변환\n",
    "iris['class']  = IRIS.target\n",
    "iris['class'] = iris['class'].map({0:'setosa', 1:'versicolor', 2:'virginica'})\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 집계함수를 이용한 그룹화\n",
    "iris.groupby(by='class').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.2 도수분포표\n",
    "\n",
    "👀 **Definition**\n",
    "> 자료를 몇개의 구간으로 나누고, 나누어진 각 구간에 속한 자료의 개수를 정리한 표\n",
    "\n",
    "- 데이터의 개수가 어떻게 분포되어 있는지 확인\n",
    "- 이 표를 시각화 한 것을 히스토그램이라고 함\n",
    "- value_counts() 함수를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도수분포표\n",
    "pd.Series(iris['class']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✏️ **더 알아보기**\n",
    "- 😗: 자료를 몇개의 구간으로 나눈다고 했는데 이건 개수만 세는 걸까요?\n",
    "- 😀: 수치형 데이터에 대해서 자료를 구간화 할 수 있습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 3등분 하고, 각 구간에 레이블 부여\n",
    "three_cut = pd.qcut(iris['petal width (cm)'], 3, labels=['low', 'medium', 'high'])\n",
    "three_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도수분포표를 만들 새로운 열 추가\n",
    "iris['petal width level'] = three_cut\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['petal width level'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✏️ **더 알아보기**\n",
    "- 😗: 하나의 기준이 아닌 여러개의 기준으로 분포표를 생성할 수 있나요?\n",
    "- 😀: crosstab() 함수를 통해 교차표를 그릴 수 있습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(iris['petal width level'], iris['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 데이터프레임에 함수 적용하기\n",
    "\n",
    "Apply와 Map 함수를 사용하여 데이터의 행 또는 열에 자유롭게 함수를 적용하고 값을 변경할 수 있습니다.\n",
    "\n",
    "- apply/ map 둘 다 동일한 기능 수행\n",
    "- 데이터프레임에 행 또는 열 방향으로 지정한 함수 실행\n",
    "\n",
    "🔥 **꿀팁**\n",
    "- lambda는 apply를 시작할 때 \"lambda 뒤에 오는 변수를 가지고 수행할거야!\"라는 뜻\n",
    "- 이 변수는 하나의 컬럼일 수도 있고 여러 컬럼일 수 도 있으며 다양한 처리를 수행할 수 있음\n",
    "- 대상이 여러 컬럼일 경우 axis=1를 꼭 명시해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나의 컬럼에 대한 수행\n",
    "iris['double sepal'] = iris['sepal width (cm)'].apply(lambda x: x*2)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 컬럼에 대한 수행\n",
    "iris['sepal petal sum'] = iris.apply(lambda x: x['sepal length (cm)'] + x['petal length (cm)'], axis=1)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 문자열 데이터 변환하기\n",
    "\n",
    "데이터프레임의 문자열 데이터를 열 방향으로 한 번에 변환하여 정제할 수 있습니다. 이때 Series의 str이라는 속성을 사용합니다.\n",
    "\n",
    "🔥 **Key point**\n",
    "- str은 Series에 있는 속성, DataFrame에는 없음\n",
    "- DataFrame['컬럼명']은 Series\n",
    "- 즉, 특정 컬럼에 대해 수행할 수 있음\n",
    "\n",
    "\n",
    "### 3.9.1 인덱싱\n",
    "\n",
    "- 슬라이스를 사용한 인덱싱 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터프레임 생성\n",
    "landmark = pd.DataFrame({'name':['광화문','호미곶','첨성대'], 'location':['서울 종로구 사직로 161', '경북 포항시 남구 호미곶면 대보리 150', '경북 경주시 인왕동 839-1']})\n",
    "landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location 문자열의 3번째부터 6번째 문자까지 추출\n",
    "landmark['location'].str[3:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.2 분할\n",
    "- 특정한 값을 기준으로 문자열을 나눌 수 있음\n",
    "- split() 함수 사용 ☞ 결과는 리스트\n",
    "- expand 조건을 통해 분할된 문자열을 별도의 문자열로 변환할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공백을 기준으로 문자열을 나누어 리스트로 반환\n",
    "string_list = landmark['location'].str.split(' ')\n",
    "string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 리스트의 1번째 문자열 반환\n",
    "string_list.str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location 컬럼을 공백을 기준으로 나누어 첫번째 문자열을 새로운 컬럼으로 추가\n",
    "landmark['location_1'] = landmark['location'].str.split(' ').str[0]\n",
    "landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand=True로 설정하여 리스트를 컬럼으로 확장\n",
    "landmark['location'].str.split(' ', expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.3 탐색\n",
    "\n",
    "시작 글자, 끝나는 글자, 포함하는 글자를 기준으로 데이터프레임을 탐색할 수 있습니다. 탐색의 결과는 True/ False로 반환됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서울로 시작하는 행 탐색\n",
    "landmark['location'].str.startswith('서울')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1로 끝나는 행 탐색\n",
    "landmark['location'].str.endswith('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경북이 포함된 행 탐색\n",
    "landmark['location'].str.contains('경북')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.4 치환\n",
    "\n",
    "특정한 데이터를 다른 데이터로 치환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경북을 경상북도로 변경\n",
    "landmark['location'].str.replace('경북', '경상북도')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10 날짜 데이터 핸들링\n",
    "\n",
    "날짜와 시간을 다루기 위해 datetime 모듈의 datetime 패키지를 이용합니다.\n",
    "\n",
    "### 3.10.1 현재 날짜 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 시간에서 년, 월, 일 추출\n",
    "[datetime.today().year, datetime.today().month, datetime.today().day]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10.2 날짜 형식의 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 문자 형식의 데이터프레임을 날짜로 변환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame({'Datetime':['20230101', '20230102', '20230103', '20230104']})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 컬럼 타입 확인\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열을 날짜로 변환\n",
    "df['Datetime'] = pd.to_datetime(df['Datetime'], format='%Y-%m-%d')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 컬럼 타입 확인\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 문자를 날짜로 변환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.strptime('20230101', '%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. 날짜를 문자로 변환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = datetime.today()\n",
    "time.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔥 **날짜 포맷**\n",
    "\n",
    "<p align=\"center\"><img src=\"https://github.com/sigirace/page-images/blob/main/kang_lectures/python_preprocessing/datetime_format.png?raw=true\" width=\"400\" height=\"400\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10.3 날짜 데이터의 연산\n",
    "\n",
    "- datetime 모듈의 timedelta 패키지를 사용하여 시간 연산이 가능함\n",
    "\n",
    "📌 **timedelta**\n",
    "> datetime.timedelta(days=0, seconds=0, microseconds=0, miliseconds=0, minutes=0, hours=0, weeks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "# 오늘로부터 1주일 1일 후 날짜 연산\n",
    "time = datetime.today()\n",
    "time + timedelta(days=1, weeks=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
