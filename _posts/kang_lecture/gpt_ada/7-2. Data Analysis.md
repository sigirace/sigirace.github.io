---
layout: single
title: "데이터 전처리"
toc: true
categories: [GPT Advanced Data Analysis]
tags: [Lecture, Data Preprocessing]

---

# 🌈 데이터 분석 실습

🔗 **한국어 패치 다운로드**

- 💾 [Korea matplotlib]()
- 💾 [나눔고딕 폰트]()

💬 **Chat Prompt**

```
가상환경에 한국어를 사용할 수 있도록 whl 파일과 ttf 파일을 제공하였으니, 아래 과정을 수행하며 한국어 환경 설정 수행

- Code interpreter로 제공한 파일들을 다운로드 및 수행
- 가상환경에 설치 및 한국어를 사용할 수 있도록 설정
- 설치 완료후 테스트 그래프 제시
- 모든 설명은 한국어로 진행
```

🤖 **GPT 출력: Code**

```python
import matplotlib.font_manager as fm
import matplotlib.pyplot as plt

# 폰트 파일 경로
font_path = '/Users/sigi/sigirace.github.io/_posts/kang_lecture/gpt_ada/data/NanumBarunGothic.ttf'

# 폰트 등록
fm.fontManager.addfont(font_path)

# 한글 폰트 설정
plt.rc('font', family='NanumBarunGothic')
```

🧑‍💻: 앞서 저장하였던 데이터를 GPT에 업로드 해주세요!

💬 **Chat Prompt**

```
제시한 데이터는 이커머스회사 olist의 구매기록 데이터를 전처리한 것이다. 이 데이터의 컬럼을 살펴보고 설명해라. 단, 모든 과정에서 설명시 한국어를 사용하고, ace_tools는 사용하지 말아라.
```

 🤖 **GPT 출력: Message**

```
주어진 데이터는 이커머스 회사 Olist의 구매 기록 데이터입니다. 데이터의 컬럼(열)과 그 설명은 다음과 같습니다:

	1.	order_id: 각 주문의 고유 식별자입니다. 이 값은 주문을 식별하는 데 사용됩니다.
	2.	customer_id: 각 고객의 고유 식별자입니다. 이를 통해 고객을 식별할 수 있습니다.
	3.	order_status: 주문의 상태를 나타냅니다. 예를 들어, ‘delivered’는 주문이 배송되었음을 의미합니다.
	4.	order_purchase_timestamp: 주문이 이루어진 날짜와 시간을 나타냅니다.
	5.	product_category: 주문된 상품의 카테고리를 나타냅니다. 예를 들어, ‘furniture_decor’은 가구와 장식품 카테고리입니다.
	6.	payment_method: 고객이 사용한 결제 방법을 나타냅니다. 예를 들어, ‘boleto’는 브라질에서 널리 사용되는 결제 방식 중 하나입니다.
	7.	installments: 할부 횟수를 나타냅니다. 값이 0이면 일시불 결제, 1 이상이면 해당 횟수로 나누어 결제됩니다.
	8.	item_price_usd: 주문된 상품의 가격을 미국 달러(USD)로 나타냅니다.
	9.	shipping_cost_usd: 배송 비용을 미국 달러(USD)로 나타냅니다.
	10.	is_weekend: 주문이 주말에 이루어졌는지를 나타냅니다. 주말이면 ‘True’, 평일이면 ‘False’입니다.
	11.	installment_duration_type: 할부 기간의 유형을 나타냅니다. ‘일시불’이나 ‘단기’ 등의 값이 들어갑니다.

이 데이터는 고객의 주문 기록, 결제 방식, 배송 관련 정보 등을 포함하고 있어, 이커머스 비즈니스 분석에 유용하게 사용될 수 있습니다. 추가적인 분석이나 문의가 필요하시면 말씀해 주세요. 
```

🤖 **GPT 출력: Code**

```python
import pandas as pd

# 데이터 로드
file_path = '/mnt/data/cleaned_olist_order_data.csv'
data = pd.read_csv(file_path)

# 데이터의 첫 몇 행과 컬럼 정보 확인
data_head = data.head()
data_columns = data.columns

data_head, data_columns
```

```
(                           order_id                       customer_id  \
 0  76c6e866289321a7c93b82b54852dc33  f54a9f0e6b351c431402b8461ea51999   
 1  9559e0b00c67d159a266152428f85615  c3498e41d1549d56c4cbde7cbfdabeb3   
 2  35aa6b03b34d8d0a5c1eaae2bb5fcf76  18f5e4ab94b6b5fdcf32dade57defe50   
 3  80dabd6ee5b0e0d7d5672d511ca8cc7e  fbea4ed949b70f597425d14164f82851   
 4  3389e2333066b728a245423a73f3f82c  45c155ac404d868fd8f1d07e8cd916c3   
 
   order_status order_purchase_timestamp product_category payment_method  \
 0    delivered      2017-01-23 18:29:00  furniture_decor         boleto   
 1    delivered      2017-01-30 10:47:00             auto    credit_card   
 2    delivered      2017-01-31 17:40:00             auto    credit_card   
 3    delivered      2017-10-01 20:04:00    health_beauty    credit_card   
 4    delivered      2017-10-01 09:15:00             auto         boleto   
 
    installments  item_price_usd  shipping_cost_usd  is_weekend  \
 0             0        3.781000             3.0495       False   
 1             0       28.101000             3.4200       False   
 2             1        9.498100             2.7588       False   
 3             1       17.098100             3.1141        True   
 4             1       30.305832             2.8690        True   
 
   installment_duration_type  
 0                       일시불  
 1                       일시불  
 2                        단기  
...
 4                        단기  ,
 Index(['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp',
        'product_category', 'payment_method', 'installments', 'item_price_usd',
        'shipping_cost_usd', 'is_weekend', 'installment_duration_type'],
       dtype='object'))
```



## 1. EDA

🧑‍💻: 앞서 배워본 치트키를 사용하여 일변량, 다변량 EDA를 수행하겠습니다.

### 1.1 일변량 EDA

- 하나의 컬럼에 대해서만 분석함

💬 **Chat Prompt**
```
제시한 데이터로 일변량 EDA 수행해줘
```

🤖 **GPT 출력: Message**
```
일변량 탐색적 데이터 분석(EDA)의 결과는 다음과 같습니다:

1. 기초 통계량
- 주문 상태(order_status): 대부분의 주문이 "delivered" 상태로 완료되었습니다.
- 결제 방법(payment_method): 대부분의 고객이 "credit_card"를 결제 방법으로 사용했습니다.
- 할부 횟수(installments): 할부 횟수는 0(일시불)에서 10회까지 다양하며, 평균적으로 2.7회입니다.
- 상품 가격(item_price_usd): 상품 가격의 평균은 약 $18.04이며, 가장 낮은 가격은 $3.78, 가장 높은 가격은 $34.01입니다.
- 배송비(shipping_cost_usd): 배송비의 평균은 약 $3.91이며, 가장 낮은 배송비는 $1.49, 가장 높은 배송비는 $8.88입니다.
- 주말 구매 여부(is_weekend): 데이터에서 대부분의 주문은 평일에 이루어진 것으로 보입니다.
- 할부 기간 유형(installment_duration_type): '단기' 할부가 가장 흔하게 사용되었습니다.

2. 시각화 결과
- 주문 상태 분포: 거의 모든 주문이 'delivered' 상태로 완료되었습니다.
- 결제 방법 분포: 'credit_card'가 가장 많이 사용된 결제 방법입니다.
- 할부 횟수 분포: 대부분의 고객이 1회 할부 또는 일시불을 선택했습니다.
- 상품 가격 및 배송비 분포: 가격과 배송비 모두 정규분포와 유사한 형태를 보이며, 특정 범위 내에 많이 집중되어 있습니다.
- 주말 구매 여부: 대부분의 구매가 평일에 이루어졌음을 알 수 있습니다.
- 할부 기간 유형 분포: '단기' 할부가 가장 일반적입니다.

이 분석 결과는 데이터의 전반적인 분포와 패턴을 이해하는 데 도움이 되며, 추가적인 분석이 필요할 경우 이를 기반으로 심층적인 분석을 진행할 수 있습니다. 추가적으로 궁금한 점이나 더 분석하고 싶은 부분이 있으면 말씀해 주세요.
```

### 1.2 다변량 EDA

- 두 개 이상의 컬럼을 종합하여 인사이트를 도출

💬 **Chat Prompt**
```
제시한 데이터로 다변량 EDA 수행해줘
```

🤖 **GPT 출력: Message**
```
다변량 탐색적 데이터 분석(EDA)의 결과는 다음과 같습니다:

1. 주문 상태별 결제 방법 분포
- 결제 방법과 주문 상태: 대부분의 주문이 'credit_card'로 결제되었으며, 'delivered' 상태인 경우가 대부분입니다. 다른 결제 방법들도 대부분 'delivered' 상태에 해당하지만, 'boleto' 등의 결제 방법은 상대적으로 적은 비율을 차지하고 있습니다.

2. 할부 횟수와 상품 가격의 관계
- 할부와 상품 가격: 할부 횟수가 증가할수록 일부 상품의 가격이 높은 경향을 보입니다. 그러나 가격이 높다고 해서 할부 횟수가 반드시 늘어나는 것은 아니며, 다양한 결제 방식에서 이와 같은 경향을 확인할 수 있습니다.

3. 상품 가격과 배송비의 관계
- 상품 가격과 배송비: 상품 가격이 증가함에 따라 배송비도 약간 증가하는 경향이 있지만, 매우 강한 상관관계는 없습니다. 주말 구매 여부에 따라 이 관계가 달라지지 않으며, 대부분의 주말 구매가 평일 구매와 비슷한 패턴을 보입니다.

4. 상관 행렬
- 상관 관계: 할부 횟수, 상품 가격, 배송비 간의 상관관계를 분석한 결과, 이들 변수 간에는 강한 상관관계가 존재하지 않습니다. 이는 각 변수가 독립적으로 움직일 가능성이 크다는 것을 의미합니다.

이러한 다변량 분석을 통해 변수들 간의 관계를 이해할 수 있으며, 추가적인 분석이나 모델링의 방향을 설정하는 데 도움이 됩니다. 추가로 분석하고 싶은 부분이 있으면 알려주세요!
```





## 2. 분석 주제 선정

### 2.1 아이디어 도출

🧑‍💻: 수행한 EDA를 기반으로 과제를 도출해봅니다.

💬 **Chat Prompt**
```
이 데이터를 기반으로 비즈니스 인사이트를 도출하고 싶어 분석할만한 과제를 제안해줘
```

🤖 **GPT 출력: Message**
```
이 데이터를 기반으로 비즈니스 인사이트를 도출할 수 있는 다양한 분석 과제를 제안드리겠습니다. 이러한 과제를 통해 이커머스 비즈니스의 효율성을 높이고, 고객 경험을 개선할 수 있는 전략적 결정을 내릴 수 있습니다.

1. 고객 세분화 및 맞춤형 마케팅 전략 수립
   - 목표: 고객의 구매 패턴, 결제 방법, 상품 카테고리 선호도 등을 분석하여 고객을 세분화합니다. 각 고객군에 맞춤형 마케팅 캠페인을 기획하여 매출을 극대화할 수 있는 전략을 수립할 수 있습니다.
   - 분석 과제:
     - 고객의 구매 빈도, 평균 구매 금액, 선호 결제 수단을 분석합니다.
     - 고객군별로 자주 구매하는 상품 카테고리와 결제 방식을 파악합니다.
     - 세그먼트별 마케팅 메시지와 프로모션 전략을 제안합니다.

2. 결제 방법 및 할부 옵션의 효율성 분석
   - 목표: 각 결제 방법과 할부 옵션이 매출에 미치는 영향을 분석하여, 더 나은 결제 환경을 제공하고 결제 과정에서의 이탈을 줄이는 방법을 모색합니다.
   - 분석 과제:
     - 결제 방법별 구매 완료율과 평균 주문 금액을 분석합니다.
     - 할부 옵션별로 고객이 어떻게 반응하는지, 그리고 이 옵션이 매출에 미치는 영향을 분석합니다.
     - 특정 결제 방법 또는 할부 옵션이 더 자주 사용되는 특정 상품 카테고리를 파악합니다.

3. 배송비와 고객 만족도 간의 관계 분석
   - 목표: 배송비가 고객의 구매 결정과 만족도에 미치는 영향을 분석하여, 최적의 배송비 정책을 제안합니다.
   - 분석 과제:
     - 상품 가격 대비 배송비의 비율이 높은 경우 고객의 구매 결정에 어떤 영향을 미치는지 분석합니다.
     - 배송비가 무료일 때와 유료일 때의 구매 패턴을 비교합니다.
     - 배송비와 고객 리뷰나 재구매율 사이의 상관관계를 분석합니다.

4. 주문 시간대와 구매 패턴 분석
   - 목표: 고객의 주문 시간대에 따른 구매 패턴을 분석하여, 시간대별로 최적화된 프로모션 전략을 수립합니다.
   - 분석 과제:
     - 주중과 주말, 그리고 특정 시간대(예: 낮 vs 저녁)에 이루어진 주문 패턴을 분석합니다.
     - 특정 시간대에 구매가 집중되는 상품 카테고리를 파악합니다.
     - 시간대별로 매출이 높은 경우 해당 시간대에 맞춤형 프로모션을 기획합니다.

5. 재구매율 및 고객 충성도 분석
   - 목표: 고객의 재구매 패턴을 분석하여 충성도 높은 고객군을 식별하고, 이를 유지하기 위한 전략을 마련합니다.
   - 분석 과제:
     - 특정 결제 방법이나 상품 카테고리에서의 재구매율을 분석합니다.
     - 첫 구매 이후 일정 기간 내에 재구매하는 고객군의 특성을 파악합니다.
     - 충성도 높은 고객에게 특별 혜택을 제공하는 프로그램을 기획합니다.

이와 같은 분석 과제를 통해 얻은 인사이트를 바탕으로, 이커머스 비즈니스의 다양한 측면을 개선하고 더 나은 성과를 달성할 수 있습니다. 각 과제에 대한 추가적인 방향이나 세부적인 분석 방법이 필요하다면 언제든지 도와드리겠습니다.
```

### 2.2 아디이어 구체화

🧑‍💻: 프롬프트를 고도화하여 분석 과제 도출을 구체화 해보겠습니다.

```
아래에는 작업을 수행하기 위해 부여된 Role, 이전에 수행한 Pre-work 그리고 수행해야될 Todo가 있습니다. 요청을 적절하게 완료하는 응답을 작성하세요.

[Role]
이커머스 회사 olist에서 근무하는 데이터 분석가

[Pre-work]
주어진 데이터로부터 일변량, 다변량 EDA를 수행함

[Todo]
EDA 수행결과로부터 인사이트를 도출하기 위한 과제를 선정하여 리포트를 작성한다. 단, 리포트에는 목표, 보유 데이터 중 활용할 수 있는 데이터, 명확한 분석 방법 및 알고리즘이 포함되어야 함

[리포트 작성 예시]

1. 태양광 발전량과 발전 패널의 연식간의 상관관계 분석
목표: 발전 패널의 연식이 태양광 발전량에 주는 영향을 분석하여 교체 및 유지보수 전략을 마련합니다.
활용 데이터(보유)
	- install_date: 발전기 설치 일자
	- gen: 발전량
	- date: 일자
분석 방법
	- 설치일자로부터 연식을 도출하여 연식과 발전량간의 단순 회귀 분석 수행
	- 일자별 발전량을 활용해 시계열 데이터 분석 수행

2. 리조트 객실 취소 인자 분석
목표: 리조트의 객실 취소에 영향을 주는 인자들을 분석하여 오버부킹 전략을 마련합니다.
활용 데이터(보유)
	- is_cancled: 예약 취소 여부
	- price: 객실 가격
	- room_type: 객실 타입
	- 등등
추가 데이터(필요)
	- 주요 행사, 공공 API 호출 필요
	- 등등
분석 방법
	- 취소 여부에 대한 트리 모델을 학습 후 feature importance를 도출함
	- 취소 여부인 범주형 변수와 수치형 변수 간의 t-검정 수행 후 가설에 대한 채택/기각 선택

Let's go!
```

🤖 **GPT 출력: Message**

```
리포트: Olist 이커머스 데이터 분석 및 인사이트 도출

1. 결제 방법에 따른 고객 이탈 분석
목표 결제 방법에 따른 고객의 구매 완료율을 분석하여 이탈이 빈번한 결제 방법을 파악하고, 이를 개선하여 고객 이탈을 줄이기 위한 전략을 마련합니다.

활용 데이터(보유
- order_status: 주문 상태 (e.g., 'delivered', 'canceled')
- payment_method: 결제 방법 (e.g., 'credit_card', 'boleto')
- installments: 할부 횟수

분석 방법 및 알고리즘
- 결제 방법별 이탈률 분석: 결제 방법에 따라 주문이 'canceled'로 끝나는 비율을 계산하여, 어떤 결제 방법이 높은 이탈률을 보이는지 파악합니다.
- 이탈 원인 탐색: 이탈률이 높은 결제 방법에 대해 추가적인 탐색을 수행, 할부 횟수나 상품 가격이 이탈에 영향을 미치는지 확인합니다.
- 로지스틱 회귀 분석**: 결제 방법, 할부 횟수, 상품 가격 등을 독립 변수로 설정하여 이탈 여부를 종속 변수로 하는 로지스틱 회귀 모델을 구축합니다. 이를 통해 결제 방법과 다른 변수들 간의 관계를 정량적으로 평가합니다.

2. 주말 구매 패턴 분석
목표: 주말과 평일의 구매 패턴을 비교 분석하여, 주말에 맞춤형 마케팅 캠페인을 기획하고 매출을 증대시킬 전략을 도출합니다.

활용 데이터(보유)
- order_purchase_timestamp: 주문 일시
- is_weekend: 주말 구매 여부 (Boolean)
- product_category: 상품 카테고리
- item_price_usd: 상품 가격
- payment_method: 결제 방법

분석 방법 및 알고리즘
- 주말 vs 평일 구매 분석: 주말과 평일에 이루어진 주문 건수를 비교하고, 시간대별 주문 패턴을 시계열 분석을 통해 파악합니다.
- 상품 카테고리별 선호도 분석: 주말과 평일에 어떤 상품 카테고리가 더 많이 판매되는지 분석합니다. 이를 통해 주말 특화 상품을 제안할 수 있습니다.
- 주말 맞춤형 마케팅 캠페인 제안: 주말 구매 고객을 타겟으로 하는 할인 프로모션이나 이벤트 전략을 수립합니다.

3. 배송비와 고객 재구매율 간의 상관관계 분석
목표: 배송비가 고객의 재구매율에 미치는 영향을 분석하여, 최적의 배송비 정책을 마련함으로써 고객 충성도를 높이고 재구매를 촉진합니다.

활용 데이터(보유)
- item_price_usd: 상품 가격
- shipping_cost_usd: 배송비
- order_status: 주문 상태
- customer_id: 고객 식별자

분석 방법 및 알고리즘
- 배송비와 재구매율의 상관관계 분석: 고객별로 재구매 여부를 확인하고, 배송비 수준에 따라 재구매율이 어떻게 변하는지 분석합니다.
- 군집 분석: 배송비와 상품 가격을 기준으로 고객을 군집화하여, 각 군집의 재구매 패턴을 파악합니다.
- 회귀 분석: 배송비와 재구매율 간의 관계를 정량적으로 평가하기 위해 회귀 분석을 수행합니다. 이를 통해 배송비 정책이 재구매에 미치는 영향을 평가하고 최적의 배송비 정책을 제안합니다.

이러한 분석을 통해 도출된 인사이트는 Olist의 전략적 의사결정에 기여할 수 있으며, 고객 만족도 및 매출 증대에 중요한 역할을 할 것입니다. 필요한 추가 분석이나 데이터를 요청해 주시면 더욱 구체적인 전략을 제시할 수 있습니다.
```

💡 **Learn!**

>  상황과 역할 그리고 예시를 통해 프롬프트를 작성하면 일반적인 질문보다 구체화된 답변을 받을 수 있습니다.

❣️ **꿀팁**

> GPT는 확률적으로 답변하기 때문에 여러번 질문을 수행하여 원하는 주제를 선택할 수 있습니다.

## 3. 분석 실습

🧑‍💻: 위에서 열심히 프롬프트 작성을 통해 과제를 도출하였으나... 실습을 위해 아래의 과제로 분석을 수행하겠습니다....

### 3.1 범주형 변수간의 관계 분석

- 범주형 변수간의 관계를 분석하기 위해서는 카이제곱 검정을 수행하여 유의확률을 통해 가설을 채택/기각 합니다.

✏️ **분석과제**

> 상품 유형(product_category)과 결제 방식(payment_method)간의 차이가 있는지 파악

💬 **Chat Prompt**
```
상품 유형(product_category)과 결제 방식(payment_method)간의 차이가 있는지 파악

- 가설 도출
- 카이제곱 분석 수행
- 유의확률에 따라 관계 도출
```

🤖 **GPT 출력: Message**
```
상품 유형(product_category)과 결제 방식(payment_method) 간의 관계를 파악하기 위해 아래와 같은 과정을 진행하겠습니다.

1. 가설 도출

먼저, 두 변수 간의 관계를 분석하기 위해 가설을 설정합니다.

	•	귀무가설(H0): 상품 유형(product_category)과 결제 방식(payment_method) 간에는 관계가 없다. 즉, 결제 방식은 상품 유형에 따라 달라지지 않는다.
	•	대립가설(H1): 상품 유형(product_category)과 결제 방식(payment_method) 간에는 관계가 있다. 즉, 결제 방식은 상품 유형에 따라 달라진다.

2. 카이제곱 분석 수행

두 범주형 변수 간의 독립성을 검정하기 위해 카이제곱 검정을 수행합니다. 이를 통해 상품 유형과 결제 방식 간의 관계가 통계적으로 유의미한지 확인할 수 있습니다.

이제 이를 코드로 수행하겠습니다.

3. 카이제곱 분석 결과 해석

카이제곱 검정의 결과는 다음과 같습니다:

	•	카이제곱 통계량(Chi-Square Statistic): 63.98
	•	p-value(유의확률): 0.061
	•	자유도(Degrees of Freedom, dof): 48

4. 유의확률에 따른 관계 도출

	•	유의확률(p-value): p-value는 0.061로, 일반적인 유의수준 0.05보다 크기 때문에 귀무가설을 기각하지 못합니다.
	•	결론: 이 결과는 상품 유형(product_category)과 결제 방식(payment_method) 간에 통계적으로 유의미한 관계가 없다는 것을 의미합니다. 즉, 이 데이터에서는 상품 유형에 따라 결제 방식이 달라지지 않는다고 볼 수 있습니다.

따라서, 상품 유형과 결제 방식 간의 차이는 통계적으로 유의미하지 않으며, 두 변수 간에 독립적인 관계를 가질 가능성이 높습니다.
```

🤖 **GPT 출력: Code**

```python
from scipy.stats import chi2_contingency

# 교차표 생성: product_category와 payment_method
crosstab = pd.crosstab(data['product_category'], data['payment_method'])

# 카이제곱 검정 수행
chi2, p, dof, expected = chi2_contingency(crosstab)

chi2, p, dof, expected
```

```
(63.97918687574001,
 0.06118147058250798,
 48,
 array([[1.55615764e+01, 6.17475369e+01, 9.97536946e-01, 2.69334975e+00],
        [5.95566502e+00, 2.36317734e+01, 3.81773399e-01, 1.03078818e+00],
        [4.80295567e+00, 1.90578818e+01, 3.07881773e-01, 8.31280788e-01],
        [3.84236453e+00, 1.52463054e+01, 2.46305419e-01, 6.65024631e-01],
        [1.15270936e+00, 4.57389163e+00, 7.38916256e-02, 1.99507389e-01],
        [1.92118227e+00, 7.62315271e+00, 1.23152709e-01, 3.32512315e-01],
        [5.76354680e-01, 2.28694581e+00, 3.69458128e-02, 9.97536946e-02],
        [3.55418719e+01, 1.41028325e+02, 2.27832512e+00, 6.15147783e+00],
        [4.66847291e+01, 1.85242611e+02, 2.99261084e+00, 8.08004926e+00],
        [3.84236453e-01, 1.52463054e+00, 2.46305419e-02, 6.65024631e-02],
        [9.60591133e-01, 3.81157635e+00, 6.15763547e-02, 1.66256158e-01],
        [1.92118227e+01, 7.62315271e+01, 1.23152709e+00, 3.32512315e+00],
        [9.60591133e-01, 3.81157635e+00, 6.15763547e-02, 1.66256158e-01],
        [5.76354680e+00, 2.28694581e+01, 3.69458128e-01, 9.97536946e-01],
        [3.26600985e+00, 1.29593596e+01, 2.09359606e-01, 5.65270936e-01],
        [5.95566502e+00, 2.36317734e+01, 3.81773399e-01, 1.03078818e+00],
        [3.45812808e+00, 1.37216749e+01, 2.21674877e-01, 5.98522167e-01]]))
```


💬 **Chat Prompt**
```
상품 유형(product_category)과 결제 방식(payment_method)간의 차이를 시각화로 보여줘
```

🤖 **GPT 출력: Message**
```
위의 시각화는 상품 유형(product_category)과 결제 방식(payment_method) 간의 관계를 보여주는 누적 막대 그래프입니다. 이 그래프를 통해 각 상품 유형별로 어떤 결제 방식이 주로 사용되는지 한눈에 파악할 수 있습니다.

각 막대는 특정 상품 유형에 대해 다양한 결제 방법의 비율을 나타내며, 결제 방식 간의 차이를 시각적으로 비교할 수 있습니다. 추가적인 분석이나 질문이 있으시면 말씀해 주세요. 
```

🤖 **GPT 출력: Code**

```python
import matplotlib.pyplot as plt

# 교차표 생성: product_category와 payment_method
crosstab = pd.crosstab(data['product_category'], data['payment_method'])

# 시각화: Stacked Bar Chart
crosstab.plot(kind='bar', stacked=True, figsize=(14, 8))
plt.title('상품 유형과 결제 방식 간의 관계')
plt.xlabel('상품 유형')
plt.ylabel('주문 수')
plt.legend(title='결제 방식')
plt.show()
```

[image, ki]

💡 **해석**

> 분석 결과 유의미한 차이가 있지 않다고 하였으나, 유의수준을 덜 엄격하게 설정하면 차이가 있다고 볼 수 있습니다.
>
> 즉, 유의수준을 0.1로 설정할 경우, 상품 유형에 따라 결제 방식이 다를 수 있다는 결론을 내릴 수 있고, 이 관계를 바탕으로 추가적인 분석이나 비즈니스 전략을 검토해볼 수 있습니다.

📌 **더 알아보기: 0.05 유의수준 vs 0.1 유의수준**

1. **0.05 유의수준**:
   - **장점**: 더 엄격한 기준을 적용하여, 잘못된 결론을 내릴 가능성을 줄입니다. 연구 결과가 더 신뢰할 수 있게 됩니다.
   - **단점**: 귀무가설을 기각하기 어려워질 수 있습니다. 즉, 실제로 관계가 있는 두 변수 사이에서도 관계를 발견하지 못할 가능성이 있습니다(2종 오류 가능성 증가).
   - 과학 연구, 의학 연구 등에서 사용됩니다. 여기서는 오류의 비용이 높기 때문에 엄격한 기준이 요구됩니다.

2. **0.1 유의수준**:
   - **장점**: 더 관대한 기준을 적용하여, 실제로 관계가 있는 변수들 간의 관계를 더 잘 발견할 수 있습니다. 연구 결과가 더 포괄적일 수 있습니다.
   - **단점**: 귀무가설을 기각할 확률이 높아지기 때문에, 실제로 관계가 없는 두 변수 사이에 관계가 있다고 잘못 결론 내릴 가능성(1종 오류)이 증가합니다.
   -  경제학, 사회학 연구 등에서 사용될 수 있습니다. 이 경우 연구의 초기 단계에서 더 많은 관계를 발견하기 위해 덜 엄격한 기준을 설정할 수 있습니다.



### 3.2 수치형 변수간의 관계 분석

- 수치형 변수간의 관계를 분석하기 위해서, 상관계수 분석 혹은 회귀 분석을 수행할 수 있습니다.

✏️ **분석과제**

> 상품 가격(item_price_usd)과 배송 비용(shipping_cost_usd)간의 관계 분석

💬 **Chat Prompt**

```
상품 가격(item_price_usd)과 배송 비용(shipping_cost_usd)간의 관계를 분석함

- 가설 도출
- 회귀분석 수행
- 유의확률에 따라 관계 도출
```

🤖 **GPT 출력: Message**

```
상품 가격(item_price_usd)과 배송 비용(shipping_cost_usd) 간의 관계 분석

1. 가설 도출

먼저, 두 변수 간의 관계를 분석하기 위해 가설을 설정합니다.

	•	귀무가설(H0): 상품 가격(item_price_usd)과 배송 비용(shipping_cost_usd) 간에는 선형적인 관계가 없다.
	•	대립가설(H1): 상품 가격(item_price_usd)과 배송 비용(shipping_cost_usd) 간에는 선형적인 관계가 있다.

2. 회귀분석 수행

상품 가격이 배송 비용에 미치는 영향을 파악하기 위해 단순 선형 회귀분석을 수행합니다. 독립 변수는 item_price_usd이고, 종속 변수는 shipping_cost_usd입니다.

이제 이를 코드로 수행하겠습니다.

3. 회귀분석 결과 해석

	•	R-squared: 0.034 (3.4%)
	•	이 값은 상품 가격(item_price_usd)이 배송 비용(shipping_cost_usd)의 변동성을 약 3.4% 설명한다는 의미입니다. 이는 매우 낮은 설명력으로, 상품 가격이 배송 비용에 미치는 영향이 크지 않음을 시사합니다.
	•	F-statistic: 28.78
	•	F-통계량은 모델이 유의미한지를 테스트하는 데 사용됩니다. 여기서 F-statistic의 p-value가 1.06e-07로 매우 작기 때문에, 모델이 통계적으로 유의미하다고 결론지을 수 있습니다.
	•	회귀 계수(coef):
	•	상수항(const): 3.0170
	•	이는 기본 배송 비용이 $3.0170임을 의미합니다.
	•	상품 가격(item_price_usd): 0.0496
	•	상품 가격이 $1 증가할 때, 배송 비용은 약 $0.0496 증가하는 것으로 나타났습니다.
	•	p-value:
	•	item_price_usd의 p-value는 0.000으로, 일반적인 유의수준 0.05보다 작습니다. 따라서 상품 가격과 배송 비용 간의 관계가 통계적으로 유의미하다는 결론을 내릴 수 있습니다.

4. 결론 도출

	•	**귀무가설(H0)**는 기각됩니다. 즉, **대립가설(H1)**을 채택할 수 있습니다.
	•	이 결과는 상품 가격(item_price_usd)과 배송 비용(shipping_cost_usd) 간에 통계적으로 유의미한 선형 관계가 있음을 나타냅니다.
	•	그러나, R-squared 값이 매우 낮기 때문에, 상품 가격이 배송 비용의 변동을 설명하는 주요 요인이 아니라는 점도 중요하게 고려해야 합니다. 이는 다른 요인들이 배송 비용에 더 큰 영향을 미칠 수 있음을 시사합니다.

추가적인 분석이나 더 심도 있는 연구가 필요하다면 이를 바탕으로 진행할 수 있습니다. 
```

🤖 **GPT 출력: Code**

```python
import statsmodels.api as sm

# 독립 변수 (상품 가격)
X = data['item_price_usd']
# 종속 변수 (배송 비용)
y = data['shipping_cost_usd']

# 상수항 추가
X = sm.add_constant(X)

# 회귀 분석 수행
model = sm.OLS(y, X).fit()

# 회귀 분석 결과 요약
model_summary = model.summary()
model_summary
```

```
                            OLS Regression Results                            
==============================================================================
Dep. Variable:      shipping_cost_usd   R-squared:                       0.034
Model:                            OLS   Adj. R-squared:                  0.033
Method:                 Least Squares   F-statistic:                     28.78
Date:                Wed, 21 Aug 2024   Prob (F-statistic):           1.06e-07
Time:                        03:12:31   Log-Likelihood:                -1714.9
No. Observations:                 812   AIC:                             3434.
Df Residuals:                     810   BIC:                             3443.
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==================================================================================
                     coef    std err          t      P>|t|      [0.025      0.975]
----------------------------------------------------------------------------------
const              3.0170      0.181     16.678      0.000       2.662       3.372
item_price_usd     0.0496      0.009      5.365      0.000       0.031       0.068
==============================================================================
Omnibus:                      101.241   Durbin-Watson:                   1.791
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              140.130
Skew:                           1.017   Prob(JB):                     3.73e-31
Kurtosis:                       3.069   Cond. No.                         50.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
```

🧑‍💻: 상관계수도 고려해보겠습니다.

💬 **Chat Prompt**
```
상품 가격(item_price_usd)과 배송 비용(shipping_cost_usd)간의 상관관계를 상관계수로 분석해줘
```

🤖 **GPT 출력: Message**
```
상품 가격(item_price_usd)과 배송 비용(shipping_cost_usd) 간의 상관계수는 0.185입니다.

해석:

	•	상관계수 0.185는 두 변수 간에 약한 양의 선형 관계가 있음을 의미합니다. 즉, 상품 가격이 증가할 때 배송 비용도 약간 증가하는 경향이 있지만, 그 관계는 매우 약합니다.
	•	이 값은 변수 간의 선형적 연관성이 크지 않음을 나타내므로, 다른 요인들이 배송 비용에 더 큰 영향을 미칠 수 있습니다.
```

🤖 **GPT 출력: Code**

```python
# 상품 가격과 배송 비용 간의 상관계수를 계산
correlation = data['item_price_usd'].corr(data['shipping_cost_usd'])
correlation
```

```
0.18523538792917865
```

💡 **해석**

> 회귀분석을 통해 두 변수간 통계적으로 유의미한 선형 관계가 있음을 알 수 있었습니다. 그러나 설명력(R-squared)이 낮았고 상관계수또한 낮았기에 아주 약한 관계임을 예상할 수 있습니다. 즉, 다른 요인이나 비선형적인 관계가 있음을 유추할 수 있습니다.

### 3.3 범주형과 수치형 변수간의 관계 분석

- 범주형과 수치형 변수간의 관계는 ANOVA 분석을 통해 알 수 있습니다.

✏️ **분석과제**

> 주말 여부(is_weekend)에 따른 매출의 영향이 있는지 파악

💬 **Chat Prompt**
```
주말 여부(is_weekend)에 따른 매출의 영향이 있는지 파악

- 가설 도출
- Anova 분석 수행
- 유의확률에 따라 관계 도출
```

🤖 **GPT 출력: Message**
```
주말 여부(is_weekend)에 따른 매출(item_price_usd)의 영향 분석

1. 가설 도출

주말 여부에 따라 매출이 차이가 있는지 확인하기 위해 가설을 설정합니다.

	•	귀무가설(H0): 주말 여부(is_weekend)에 따른 매출(item_price_usd)에는 차이가 없다.
	•	대립가설(H1): 주말 여부(is_weekend)에 따른 매출(item_price_usd)에는 차이가 있다.

2. ANOVA 분석 수행

주말과 평일 간의 매출 차이를 분석하기 위해 일원분산분석(ANOVA)을 수행합니다. 이 방법은 두 그룹 간의 평균 차이가 통계적으로 유의미한지 판단하는 데 사용됩니다.

이제 이를 코드로 수행하겠습니다.

3. ANOVA 분석 결과 해석

	•	F-statistic: 0.207
	•	p-value: 0.649

4. 유의확률에 따른 관계 도출

	•	p-value는 0.649로, 일반적인 유의수준 0.05보다 훨씬 큽니다.
	•	결론: 주말 여부(is_weekend)에 따른 매출(item_price_usd)에는 통계적으로 유의미한 차이가 없다는 결론을 내릴 수 있습니다. 즉, 주말과 평일 간의 매출 차이는 통계적으로 의미가 없다고 판단됩니다.

이 결과에 따르면, 주말 여부가 매출에 미치는 영향은 미미하며, 두 그룹 간의 차이는 통계적으로 유의미하지 않습니다. 추가적으로 다른 요인을 고려하여 매출에 영향을 미칠 수 있는 요소를 분석하는 것이 필요할 수 있습니다. 
```

🤖 **GPT 출력: Code**

```python
from scipy.stats import f_oneway

# 주말 여부에 따른 매출을 그룹화
weekend_sales = data[data['is_weekend'] == True]['item_price_usd']
weekday_sales = data[data['is_weekend'] == False]['item_price_usd']

# ANOVA 분석 수행
anova_result = f_oneway(weekend_sales, weekday_sales)
anova_result
```

```
F_onewayResult(statistic=0.20731798058076364, pvalue=0.6489997358230262)
```

💬 **Chat Prompt**
```
주말 여부(is_weekend)에 따른 매출을 시각화해줘
```

🤖 **GPT 출력: Message**
```
위의 그래프는 주말 여부에 따른 평균 매출을 시각화한 것입니다.

	•	평일(0)과 주말(1)의 평균 매출을 비교할 수 있으며, 각 기간에 고객당 평균적으로 얼마의 매출이 발생했는지를 확인할 수 있습니다.

이 그래프를 통해 주말과 평일 중 어느 시기에 더 높은 평균 매출이 발생하는지 파악할 수 있으며, 이는 고객의 구매 패턴을 이해하는 데 도움이 됩니다.

추가적으로 분석이 필요한 부분이 있으면 말씀해 주세요
```

🤖 **GPT 출력: Code**

```python
# 주말 여부에 따른 매출의 평균을 계산합니다.

# 주말 여부에 따른 매출 평균 계산
average_revenue_by_weekend = data.groupby('is_weekend')['item_price_usd'].mean()

# 시각화
plt.figure(figsize=(8, 6))
average_revenue_by_weekend.plot(kind='bar', color=['blue', 'orange'])
plt.title('주말 여부에 따른 평균 매출')
plt.xlabel('주말 여부 (0: 평일, 1: 주말)')
plt.ylabel('평균 매출 (USD)')
plt.xticks([0, 1], labels=['평일', '주말'], rotation=0)
plt.show()
```

[image, anova]

💡**해석**

> 주중, 주말 여부에 따라 총매출은 차이가 있으나, 평균 매출은 차이가 없음을 알 수 있다. 이는 Olist가 이커머스 회사이기 때문에 주말의 영향이 적은 것이라고 해석 할 수 있다.

### 3.4 고객 세그먼트 분석

구매 데이터 기반 고객 세분화는 RFM분석을 수행합니다. 이는 고객별로 R(Recently, 얼마나 최근), F(Frequency, 얼마나 자주), M(Monetary, 얼마나 많이)에 대해 스코어링을 하고 이를 분류함으로 수행됩니다.

✏️ **분석과제**

> 고객 세그먼트 분석을 통해 세분화 전략 수행

💬 **Chat Prompt**
```
제시한 데이터를 통해 RFM 분석을 수행해라

- 각 customer_id 별로 R,F,M을 5점 척도로 스코어링
- 스코어링 시에 설명 포함
```

🤖 **GPT 출력: Message**
```
RFM 분석을 통해 각 고객별로 R(Recency), F(Frequency), M(Monetary) 스코어를 5점 척도로 계산하였습니다.

	•	R_Score: 최근성 점수로, 최근에 구매한 고객일수록 높은 점수(5점)를 받습니다. 오래 전에 구매한 고객일수록 점수가 낮아집니다.
	•	F_Score: 빈도 점수로, 구매 빈도가 높은 고객일수록 높은 점수(5점)를 받습니다. 구매 빈도가 낮은 고객일수록 점수가 낮아집니다.
	•	M_Score: 금액 점수로, 총 구매 금액이 높은 고객일수록 높은 점수(5점)를 받습니다. 구매 금액이 적은 고객일수록 점수가 낮아집니다.

각 고객의 customer_id에 대해 R, F, M 스코어를 계산하여 고객의 가치를 평가할 수 있으며, 이를 통해 마케팅 전략을 세울 수 있습니다.

추가적인 분석이나 다른 작업이 필요하시면 말씀해 주세요! ￼
```

🤖 **GPT 출력: Code**

```python
# Recency (R): 마지막 구매 이후의 경과일
# Frequency (F): 특정 기간 동안의 구매 빈도
# Monetary Value (M): 총 구매 금액

# Recency 계산
data['order_purchase_timestamp'] = pd.to_datetime(data['order_purchase_timestamp'])
last_purchase = data.groupby('customer_id')['order_purchase_timestamp'].max().reset_index()
last_purchase.columns = ['customer_id', 'LastPurchaseDate']

# 분석 기준 날짜 (가장 최근 날짜로 설정)
now = data['order_purchase_timestamp'].max()

# Recency 계산
last_purchase['Recency'] = (now - last_purchase['LastPurchaseDate']).dt.days

# Frequency 계산
frequency = data.groupby('customer_id')['order_id'].count().reset_index()
frequency.columns = ['customer_id', 'Frequency']

# Monetary 계산
monetary = data.groupby('customer_id')['item_price_usd'].sum().reset_index()
monetary.columns = ['customer_id', 'Monetary']

# RFM 데이터를 합침
rfm = last_purchase.merge(frequency, on='customer_id')
rfm = rfm.merge(monetary, on='customer_id')

# R, F, M 각각을 5점 척도로 스코어링
rfm['R_Score'] = pd.qcut(rfm['Recency'], 5, labels=[5, 4, 3, 2, 1])
rfm['F_Score'] = pd.qcut(rfm['Frequency'].rank(method="first"), 5, labels=[1, 2, 3, 4, 5])
rfm['M_Score'] = pd.qcut(rfm['Monetary'], 5, labels=[1, 2, 3, 4, 5])

# 결과를 확인하기 위해 RFM 데이터를 보여줍니다.
print(rfm[['customer_id', 'R_Score', 'F_Score', 'M_Score']].head())
```

```
                        customer_id R_Score F_Score M_Score
0  011a899e735ec86f00f26089cdae09cf       3       1       2
1  0147fbc5c91112d914a4f4a480a0f09e       1       1       5
2  015faf9ec36eccd957c0f2782aab09a4       2       5       5
3  0191e09197e54ad2690c3abd44723c7c       3       1       5
4  0270aff4097536e634627aba39320083       1       1       3
```

🧑‍💻: 스코어링한 RFM 스코어를 기준으로 고객 세분화 세그먼트를 설정합니다.

💬 **Chat Prompt**
```
RFM 스코어를 기준으로 고객 세분화를 해줘

- 세그먼트를 최대한 MECE하게 설계
- 각 세그먼트를 정의하고, 분류 기준을 설명한 후, 고객들을 세그먼트별로 분류
- 각 세그먼트에 특성에 어울리는 네이밍 부여
- 각 세그먼트에 몇명의 고객이 포함되었는지 표기
```

🤖 **GPT 출력: Message**
```
RFM 분석을 기반으로 고객을 다음과 같은 세그먼트로 세분화하였습니다:

	1.	우수 고객: R, F, M 점수가 모두 높은 고객. 매우 가치 있는 고객들입니다. (57명)
	2.	충성 고객: R(최근성)과 F(빈도) 점수가 높은 고객. 꾸준히 구매하는 충성 고객들입니다. (62명)
	3.	VIP 고객: R(최근성)과 M(금액) 점수가 높은 고객. 최근에 큰 금액을 소비한 고객들입니다. (81명)
	4.	잠재 고객: R(최근성) 점수가 높은 고객. 최근에 구매했지만 빈도와 금액이 낮은 고객들입니다. (101명)
	5.	위험 고객: R(최근성) 점수가 낮고, F(빈도)와 M(금액) 점수가 높은 고객. 과거에 가치가 높았지만 현재 이탈 위험이 있는 고객들입니다. (44명)
	6.	이탈 고객: R(최근성) 점수가 낮고, F(빈도) 점수가 높은 고객. 최근 활동이 줄어든 고객들입니다. (72명)
	7.	빈번 구매 고객: F(빈도) 점수가 높은 고객. 자주 구매하지만 금액이 적을 수 있는 고객들입니다. (65명)
	8.	고가 구매 고객: M(금액) 점수가 높은 고객. 구매 빈도는 낮지만 큰 금액을 소비하는 고객들입니다. (76명)
	9.	일반 고객: R, F, M 점수가 모두 중간 정도이거나 낮은 고객들. 특출나지 않은 일반 고객들입니다. (191명)

이 분류를 통해 각 세그먼트에 어떤 고객들이 포함되어 있는지 파악할 수 있으며, 각 세그먼트별로 맞춤형 마케팅 전략을 수립할 수 있습니다. 추가적으로 분석이 필요하거나 다른 도움이 필요하시면 말씀해 주세요!
```

🧑‍💻: 프롬프트를 통해 세그먼트별 전략을 추천받아 봅니다.

💬 **Chat Prompt**
```
아래에는 작업을 수행하기 위해 부여된 Role, 이전에 수행한 Pre-work 그리고 수행해야될 Todo가 있습니다. 요청을 적절하게 완료하는 응답을 작성하세요.

[Role]
이커머스 회사 olist에서 근무하는 마케팅 팀 직원

[Pre-work]
고객 세그먼트를 수행함

[Todo]
각 고객 세그먼트별로 마케팅 전략을 수립하여 보고서 작성

Let's go!
```

🤖 **GPT 출력: Message**
```
Olist 마케팅 전략 보고서

작성자: 마케팅 팀

1. 우수 고객 (57명)

	•	특성: R, F, M 점수가 모두 높은 매우 가치 있는 고객.
	•	마케팅 전략:
	•	VIP 프로그램 도입: 전용 할인, 우선 배송, 맞춤형 서비스 제공.
	•	감사 이벤트: 정기적으로 감사 편지 및 특별 혜택 제공.
	•	리퍼럴 프로그램: 친구 추천 시 보상 제공.

2. 충성 고객 (62명)

	•	특성: 자주 구매하며, 오랜 기간에 걸쳐 꾸준히 활동한 고객.
	•	마케팅 전략:
	•	포인트 제도 강화: 구매 횟수에 따라 포인트 적립률 증가.
	•	제품 리뷰 요청: 리뷰 작성 시 보상 제공.
	•	재구매 유도 캠페인: 재구매 시 특별 할인 제공.

3. VIP 고객 (81명)

	•	특성: 최근에 높은 금액을 소비한 고객.
	•	마케팅 전략:
	•	고가 상품 추천: 프리미엄 상품 및 신규 럭셔리 제품 추천.
	•	맞춤형 서비스: 개인 쇼핑 도우미 서비스 제공.
	•	독점 이벤트: 한정판 제품 또는 이벤트 초대.

4. 잠재 고객 (101명)

	•	특성: 최근 구매는 했지만 빈도와 금액이 낮은 고객.
	•	마케팅 전략:
	•	제품 관심사 분석: 관심 제품에 대한 타겟 광고 제공.
	•	웰컴 오퍼: 첫 구매 이후 재구매 시 추가 할인 제공.
	•	뉴스레터 강화: 새로운 제품 및 할인 소식을 정기적으로 제공.

5. 위험 고객 (44명)

	•	특성: 과거에 가치가 높았지만 현재 이탈 위험이 있는 고객.
	•	마케팅 전략:
	•	리인게이지먼트 캠페인: 개인화된 메일링을 통해 재참여 유도.
	•	재구매 유도 할인: 장바구니에 남아있는 제품에 대한 할인 제공.
	•	휴면 고객 이벤트: 특정 기간 내 구매 시 특별 혜택 제공.

6. 이탈 고객 (72명)

	•	특성: 과거에는 자주 구매했지만 최근 활동이 감소한 고객.
	•	마케팅 전략:
	•	재참여 캠페인: 개인화된 혜택으로 고객의 관심을 다시 끌기.
	•	긴급 할인 제공: 한정 기간 동안 특별 할인을 제공해 재방문 유도.
	•	서비스 피드백 요청: 이탈 원인을 파악하기 위한 설문조사 시행.

7. 빈번 구매 고객 (65명)

	•	특성: 구매 빈도가 높으나, 구매 금액이 적은 고객.
	•	마케팅 전략:
	•	구독 서비스 제안: 정기적인 구매를 위한 구독 서비스 도입.
	•	번들 할인: 다수의 저가 상품을 한 번에 구매 시 할인 제공.
	•	친구 추천 보상: 친구를 추천할 때마다 할인 혜택 제공.

8. 고가 구매 고객 (76명)

	•	특성: 구매 빈도는 낮지만, 구매할 때마다 큰 금액을 소비하는 고객.
	•	마케팅 전략:
	•	맞춤형 제안: 프리미엄 상품 추천 및 맞춤형 서비스 제공.
	•	한정판 제품 소개: 특별한 제품
```

***

## ❤️‍🔥 고생하셨습니다.

[Image, da_end]
