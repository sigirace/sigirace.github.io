---
layout: single
title: "데이터 전처리"
toc: true
categories: [GPT Advanced Data Analysis]
tags: [Lecture, Data Preprocessing]

---

# 🚧 데이터 전처리

앞서 데이터 전처리 과정 수행을 위해 시각화와 연계하여 데이터를 확인해야 한다고 하였습니다. 이번 장에서는 이전 확인하였던 olist 구매기록 데이터를 통해 데이터 전처리를 수행하도록 하겠습니다.

🔗 **한국어 패치 다운로드**

- 💾 [Korea matplotlib]()
- 💾 [나눔고딕 폰트]()

💬 **Chat Prompt**

```
가상환경에 한국어를 사용할 수 있도록 whl 파일과 ttf 파일을 제공하였으니, 아래 과정을 수행하며 한국어 환경 설정 수행

- Code interpreter로 제공한 파일들을 다운로드 및 수행
- 가상환경에 설치 및 한국어를 사용할 수 있도록 설정
- 설치 완료후 테스트 그래프 제시
- 모든 설명은 한국어로 진행
```

🤖 **GPT 출력: Code**

```python
import matplotlib.font_manager as fm
import matplotlib.pyplot as plt

# 폰트 파일 경로
font_path = '/Users/sigi/sigirace.github.io/_posts/kang_lecture/gpt_ada/data/NanumBarunGothic.ttf'

# 폰트 등록
fm.fontManager.addfont(font_path)

# 한글 폰트 설정
plt.rc('font', family='NanumBarunGothic')
```

🧑‍💻: 앞서 저장하였던 데이터를 GPT에 업로드 해주세요!

💬 **Chat Prompt**

```
제시한 데이터는 이커머스회사 olist의 구매기록 데이터이다. 이 데이터의 컬럼을 살펴보고 설명해라. 단, 모든 과정에서 설명시 한국어를 사용하고, ace_tools는 사용하지 말아라
```

🤖 **GPT 출력: Message**
```
제공된 이커머스 회사 Olist의 구매기록 데이터에는 다음과 같은 컬럼들이 포함되어 있습니다:

	1.	order_id: 주문을 식별하기 위한 고유 ID입니다.
	2.	customer_id: 고객을 식별하기 위한 고유 ID입니다.
	3.	order_status: 주문의 상태를 나타냅니다 (예: 완료, 취소 등).
	4.	order_purchase_timestamp: 주문이 이루어진 시간입니다.
	5.	product_category: 제품의 카테고리를 나타냅니다 (예: 전자제품, 의류 등).
	6.	payment_method: 결제 방법을 나타냅니다 (예: 신용카드, 계좌이체 등).
	7.	installments: 할부 횟수를 나타냅니다. 고객이 결제를 몇 번에 나누어 했는지를 나타냅니다.
	8.	item_price_usd: 제품의 가격을 미국 달러로 나타낸 값입니다.
	9.	shipping_cost_usd: 배송 비용을 미국 달러로 나타낸 값입니다.
	10.	installment_divide: 할부로 나눈 결제 금액을 나타냅니다.
	11.	monthly_price: 할부 결제 시 매월 지불해야 하는 금액을 나타냅니다.

이 컬럼들은 각 주문에 대한 세부 정보를 제공하며, 이를 통해 고객 행동 분석, 판매 트렌드 분석 및 기타 비즈니스 인사이트를 도출할 수 있습니다. 추가적인 분석이 필요하시면 말씀해 주세요! 
```

🤖 **GPT 출력: Code**

```python
import pandas as pd

# 데이터 불러오기
file_path = './data/olist_order_dataset_processed.csv'
data = pd.read_csv(file_path)

# 데이터의 컬럼을 살펴보기
columns_info = data.columns
columns_info
```

```
Index(['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp',
       'product_category', 'payment_method', 'installments', 'item_price_usd',
       'shipping_cost_usd', 'installment_divide', 'monthly_price'],
      dtype='object')
```

🧑‍💻: 실습을 위해 앞서 데이터프레임에 함수를 적용하여 생성하였던 변수 2개를 삭제하겠습니다.

💬 **Chat Prompt**

```
installment_divide, monthly_price 두 컬럼은 삭제해줘
```

🤖 **GPT 출력: Message**

```python
installment_divide와 monthly_price 두 컬럼을 성공적으로 삭제하였습니다. 이제 남아 있는 컬럼들은 다음과 같습니다:

	1.	order_id
	2.	customer_id
	3.	order_status
	4.	order_purchase_timestamp
	5.	product_category
	6.	payment_method
	7.	installments
	8.	item_price_usd
	9.	shipping_cost_usd

이제 이 데이터셋을 통해 다양한 분석을 진행할 수 있습니다. 추가로 필요한 작업이 있으면 알려주세요. 
```

🤖 **GPT 출력: Code**

```python
# 'installment_divide', 'monthly_price' 컬럼 삭제
data = data.drop(columns=['installment_divide', 'monthly_price'])

# 삭제 후 컬럼 목록 확인
data.columns
```

```
# 'installment_divide', 'monthly_price' 컬럼 삭제
data = data.drop(columns=['installment_divide', 'monthly_price'])

# 삭제 후 컬럼 목록 확인
data.columns
```



## 1. 결측치 탐색 및 처리

데이터를 적재, 수집하는 과정에서 결측치가 발생할 수 있습니다. 결측치는 데이터 분석시 오류를 발생시키는 주요 원인이기 때문에 전처리 과정을 거쳐야 합니다.

🧑‍💻: 현재 데이터 셋에서 결측치를 확인해 보도록 하겠습니다.


💬 **Chat Prompt**
```
데이터 셋에서 결측치를 확인해주고 컬럼별 결측치의 비율을 알려줘
```

🤖 **GPT 출력: Message**
```
데이터 셋에서 컬럼별 결측치 개수와 결측치 비율은 다음과 같습니다:

	•	item_price_usd: 결측치 99개, 결측치 비율 9.93%
	•	shipping_cost_usd: 결측치 99개, 결측치 비율 9.93%

나머지 컬럼들인 order_id, customer_id, order_status, order_purchase_timestamp, product_category, payment_method, installments 컬럼에는 결측치가 없습니다.

즉, item_price_usd와 shipping_cost_usd 컬럼에만 결측치가 존재하며, 두 컬럼 모두 결측치 비율이 약 9.93%입니다. 추가로 조치가 필요하시다면 말씀해 주세요
```

🤖 **GPT 출력: Code**

```python
# 각 컬럼별 결측치 개수 확인
missing_data = data.isnull().sum()

# 각 컬럼별 결측치 비율 계산
missing_data_percentage = (missing_data / len(data)) * 100

# 결측치 개수와 비율을 데이터프레임으로 정리
missing_data_summary = pd.DataFrame({
    '결측치 개수': missing_data,
    '결측치 비율 (%)': missing_data_percentage
})

print(missing_data_summary)
```

```
                          결측치 개수  결측치 비율 (%)
order_id                       0    0.000000
customer_id                    0    0.000000
order_status                   0    0.000000
order_purchase_timestamp       0    0.000000
product_category               0    0.000000
payment_method                 0    0.000000
installments                   0    0.000000
item_price_usd                99    9.929789
shipping_cost_usd             99    9.929789
```

### 1.2 결측치 처리

결측치를 탐색하여 비율을 확인하였을 때, 일반적으로 5% 이하일 경우 제거하고 5% 이상일 경우 평균, 최빈값 등으로 대체하는 방법을 사용합니다. 이는 데이터의 수가 줄어드는 것을 방지하기 위함입니다. 본 예제에서는 학습을 위해 두 방법 모두 사용하도록 하겠습니다.

🧑‍💻: 데이터 셋에서 `item_price_usd`는 주요 컬럼이기에 결측치를 대체하고 `shipping_cost_usd`는 제거하도록 하겠습니다.

💬 **Chat Prompt**
```
shipping_cost_usd 컬럼의 결측치는 삭제해줘
```

🤖 **GPT 출력: Message**
```
shipping_cost_usd 컬럼에서 결측치가 있는 행을 모두 삭제한 후, 데이터셋의 크기는 (898, 9)로 변경되었습니다. 이제 이 데이터셋은 shipping_cost_usd 컬럼에 결측치가 없는 상태입니다.

추가로 필요한 작업이 있으면 알려주세요.
```

🤖 **GPT 출력: Code**

```python
# shipping_cost_usd 컬럼에서 결측치가 있는 행을 삭제
data_cleaned = data.dropna(subset=['shipping_cost_usd'])

# 삭제 후 데이터프레임의 크기 확인
data_cleaned.shape
```

```
(898, 9)
```

💬 **Chat Prompt**
```
item_price_usd의 결측치는 평균으로 대체해줘
```

🤖 **GPT 출력: Message**
```
item_price_usd 컬럼의 결측치를 해당 컬럼의 평균값으로 대체했습니다. 대체 후에는 더 이상 결측치가 없습니다. 이로써 데이터셋의 결측치 처리가 완료되었습니다.

다른 작업이나 추가 요청이 있으시면 말씀해 주세요. 
```

🤖 **GPT 출력: Code**

```python
# item_price_usd 컬럼의 결측치를 평균 값으로 대체
mean_item_price = data_cleaned['item_price_usd'].mean()
data_cleaned['item_price_usd'].fillna(mean_item_price, inplace=True)

# 결측치 대체 후 결측치 확인
data_cleaned['item_price_usd'].isnull().sum()
```

```
0
```

***

## 2. 이상치 탐색 및 처리

📍 **이상치의 종류**

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/kang_lectures/python_preprocessing/outlier_type.png?raw=true" width="400" height="200"></p>

- 이상치는 측정의 변동성, 실험의 오류, 측정 장비의 이상 등으로 발생할 수 있음
- 이상치는 분석 모델의 성능을 떨어뜨리거나 분석 결과에 악영향을 줄 수 있음 ☞ 제거 혹은 처리 필요

### 2.1 이상치 탐색

🧑‍💻: 먼저 데이터의 요약 통계 정보를 통해 이상치를 확인 해보겠습니다.

💬 **Chat Prompt**

```
제시한 데이터의 요약 통계정보를 통해 이상치가 있는지 확인해줘
```

🤖 **GPT 출력: Message**
```
데이터의 요약 통계 정보를 통해 몇 가지 이상치가 의심되는 값을 확인할 수 있습니다:

	1.	installments (할부 횟수):
	•	최대 값이 999로, 일반적인 할부 횟수를 고려할 때 비정상적으로 큰 값입니다. 일반적인 할부는 12개월, 24개월 정도이므로 999는 이상치일 가능성이 높습니다.
	•	평균은 3.62로, 표준편차가 31.68로 매우 큽니다. 이는 몇몇 값이 전체 데이터를 왜곡할 가능성이 있다는 것을 시사합니다.
	2.	item_price_usd (제품 가격):
	•	최소 값이 $1.805, 최대 값이 $9999.000입니다. 일부 제품의 경우 높은 가격이 있을 수 있지만, $9999는 상당히 높은 가격으로, 특정 데이터 입력 오류나 극단값일 가능성이 있습니다.
	•	표준편차가 $333.61로, 평균 $29.10에 비해 상당히 큽니다. 이는 일부 극단적인 높은 가격이 전체 데이터에 영향을 미쳤을 수 있음을 나타냅니다.
	3.	shipping_cost_usd (배송 비용):
	•	최소 값이 -$9.595로, 배송 비용이 음수인 경우는 비정상적입니다. 이는 데이터 입력 오류일 가능성이 있습니다.
	•	최대 값은 $99999로, 이는 비정상적으로 큰 값입니다. 일반적인 배송비로 보기 어려우므로, 이상치일 가능성이 높습니다.
	•	표준편차가 $3336.87로, 평균 $115.49에 비해 매우 큽니다. 이는 몇몇 값이 데이터의 평균에 상당한 영향을 미치고 있음을 나타냅니다.

이러한 이상치들은 분석 전에 처리해야 할 가능성이 있습니다. 데이터의 특정 값들을 추가적으로 조사하거나, 이상치를 처리하는 방법을 적용하여 분석의 정확성을 높일 수 있습니다. 추가적인 분석이나 특정 데이터 처리 방법이 필요하시면 알려주세요
```

🤖 **GPT 출력: Code**

```python
# 데이터의 요약 통계 정보 확인
summary_stats = data.describe()

# 요약 통계 정보 출력
print(summary_stats)
```

```
       installments  item_price_usd  shipping_cost_usd
count    997.000000      898.000000         898.000000
mean       3.623872       29.099161         115.493469
std       31.681427      333.614822        3336.873052
min        0.000000        1.805000          -9.595000
25%        1.000000       13.110000           2.464300
50%        1.000000       17.098100           3.064700
75%        4.000000       20.898100           5.169425
max      999.000000     9999.000000       99999.000000
```

🧑‍💻: 이를 좀 더 시각화하여 판단하기 쉽도록 해보겠습니다.

💬 **Chat Prompt**
```
수치형 컬럼들에 대해서 개별적으로 box plot 시각화 수행

단, box plot은 개별적으로 수행하 되, 하나의 그리드에 표현
```

🤖 **GPT 출력: Message**
```
위의 그래프는 각 수치형 컬럼에 대한 개별적인 박스 플롯을 보여줍니다. 각 플롯은 컬럼 내 값들의 분포를 시각적으로 표현하며, 이상치를 쉽게 식별할 수 있습니다. 특히 installments, shipping_cost_usd, 그리고 item_price_usd 컬럼에서 이상치가 두드러지게 나타나는 것을 확인할 수 있습니다.

이러한 시각화를 통해 데이터의 특이점이나 이상치를 더 명확하게 파악할 수 있습니다. 추가적인 분석이나 질문이 있으시면 말씀해 주세요!
```

🤖 **GPT 출력: Code**

```python
import matplotlib.pyplot as plt

# 수치형 컬럼 선택
numeric_columns = ['installments', 'item_price_usd', 'shipping_cost_usd']

# 박스 플롯 그리기
plt.figure(figsize=(15, 10))

for i, column in enumerate(numeric_columns, 1):
    plt.subplot(3, 2, i)  # 3x2 그리드로 배치
    plt.boxplot(data[column].dropna())  # NaN 값 제거 후 박스 플롯 그리기
    plt.title(column)

plt.tight_layout()
plt.show()
```

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/kang_lectures/gpt_ada/outliear1.png?raw=true" width="600" height="300"></p>

🧑‍💻: 극단적인 값이 있어 데이터를 파악하기 어려워 보입니다. 상위, 하위 3% 정도 제거하고 데이터를 확인해보겠습니다.

💬 **Chat Prompt**
```
제시한 데이터에서 각 컬럼별 상위, 하위 3% 정도 극단적인 값들을 제거해줘
```

🤖 **GPT 출력: Message**
```
각 수치형 컬럼에서 상위, 하위 3%의 극단적인 값들을 제거한 후의 요약 통계 정보를 확인했습니다. 이 과정을 통해 데이터에서 일부 이상치가 제거되었으며, 통계값들이 더 안정적인 범위로 수렴한 것을 볼 수 있습니다.

예를 들어:

	•	installments: 최대 값이 10으로 줄어들어, 비정상적으로 큰 값이 제거되었습니다.
	•	item_price_usd: 최대 값이 $34.01로 줄어들었으며, 평균과 표준편차가 줄어들어 안정적인 분포를 보입니다.
	•	shipping_cost_usd: 최대 값이 $9.69로 줄어들어, 극단적인 높은 배송 비용이 제거되었습니다.

이제 데이터를 활용한 추가 분석이 가능합니다. 다른 분석 작업이나 추가 요청 사항이 있으시면 알려주세요!
```

🤖 **GPT 출력: Code**

```python
# 각 컬럼별 상위, 하위 3% 극단적인 값들을 제거

def remove_extremes(df, columns, percentile=0.03):
    for column in columns:
        lower_bound = df[column].quantile(percentile)
        upper_bound = df[column].quantile(1 - percentile)
        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]
    return df

# 수치형 컬럼에서 상위, 하위 3% 제거
cleaned_data = remove_extremes(data, numeric_columns)

# 결과 확인
print(cleaned_data.describe())
```

```
       installments  item_price_usd  shipping_cost_usd
count    731.000000      731.000000         731.000000
mean       2.704514       16.681761           3.927773
std        2.853063        6.765804           2.084227
min        0.000000        3.781000           1.485800
25%        1.000000       15.198100           2.601100
50%        1.000000       17.098100           3.100800
75%        4.000000       20.881000           5.123350
max       10.000000       34.008100           9.688100
```

💬 **Chat Prompt**
```
수치형 컬럼들에 대해서 개별적으로 box plot 시각화 수행

단, box plot은 개별적으로 수행하 되, 하나의 그리드에 표현
```

🤖 **GPT 출력: Message**
```
위의 박스 플롯들은 극단적인 값들을 제거한 후 각 수치형 컬럼의 분포를 보여줍니다. 이상치가 제거되면서 플롯이 더 안정적인 형태를 띄고 있으며, 이전보다 데이터의 중심 경향이 더 명확하게 드러납니다.

이제 데이터 분석이 더 신뢰할 수 있는 범위 내에서 진행될 수 있으며, 추가적으로 궁금한 사항이 있거나 다른 작업이 필요하시면 말씀해 주세요!
```

🤖 **GPT 출력: Code**

```python
# 극단값 제거 후 수치형 컬럼들에 대한 박스 플롯 다시 그리기

plt.figure(figsize=(15, 10))

for i, column in enumerate(numeric_columns, 1):
    plt.subplot(3, 2, i)  # 3x2 그리드로 배치
    plt.boxplot(cleaned_data[column].dropna())  # NaN 값 제거 후 박스 플롯 그리기
    plt.title(column)

plt.tight_layout()
plt.show()
```

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/kang_lectures/gpt_ada/outliear2.png?raw=true" width="600" height="300"></p>

🧑‍💻: 다른 변수에 비해 shipping_cost_usd는 outlier가 많은 것으로 보입니다. 이를 IQR 방식을 통해 제거해보겠습니다.

💬 **Chat Prompt**
```
shipping_cost_usd 컬럼에 대해 IQR 방식으로 이상치를 탐색해주고, 이상치의 비율과 상한, 하한에 대해 알려줘
```

🤖 **GPT 출력: Message**
```
shipping_cost_usd 컬럼에 대해 IQR 방식을 사용하여 이상치를 탐색한 결과는 다음과 같습니다:

	•	하한 (Lower Bound): 약 -1.17
	•	상한 (Upper Bound): 약 8.89
	•	이상치 비율: 전체 데이터의 약 2.09%

즉, shipping_cost_usd 값이 -1.17 미만이거나 8.89 초과인 경우가 이상치로 간주됩니다. 이상치는 전체 데이터의 약 2.09%를 차지하고 있습니다.

추가로 궁금한 사항이나 요청이 있으시면 알려주세요.
```

🤖 **GPT 출력: Code**

```python
# IQR 방식으로 이상치 탐색
Q1 = data_cleaned['shipping_cost_usd'].quantile(0.25)
Q3 = data_cleaned['shipping_cost_usd'].quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# 이상치 탐색
outliers = data_cleaned[(data_cleaned['shipping_cost_usd'] < lower_bound) | (data_cleaned['shipping_cost_usd'] > upper_bound)]

# 이상치 비율 계산
outliers_ratio = len(outliers) / len(data_cleaned) * 100

lower_bound, upper_bound, outliers_ratio
```

```
(-1.1715874999999998, 8.8889125, 2.0935960591133003)
```



### 2.2 이상치 처리

이상치를 탐색한 후 제거하거나 평균값, 최빈값 등으로 대체하는 처리 과정이 필요합니다. 이는 데이터 분석가가 도메인 전문가와 협의를 통해 수행하여야 합니다. 본 실습에서는 다양한 처리 방법을 학습하기 위해 임의로 진행하도록 하겠습니다.

🧑‍💻: 데이터에 대해 하한값 미만은 제거하고 상한값 초과 값은 상한값으로 대체하겠습니다.

💬 **Chat Prompt**

```
shipping_cost_usd 컬럼에서 하한값 미만은 제거해줘
```

🤖 **GPT 출력: Message**
```
shipping_cost_usd 컬럼에서 하한값(-1.17) 미만의 데이터를 제거한 후, 데이터셋의 크기는 (812, 9)로 유지되었습니다. 이는 제거된 데이터가 극히 적었음을 의미합니다.

이제 데이터셋이 이상치 제거를 통해 정제되었습니다. 추가로 필요하신 작업이 있으면 말씀해 주세요. 
```

🤖 **GPT 출력: Code**

```python
# item_price_usd 컬럼에서 하한값 이하의 데이터 제거
cleaned_data = cleaned_data[cleaned_data['item_price_usd'] > lower_bound]

# 제거 후 데이터 확인
print(cleaned_data.describe())
```

```
       installments  item_price_usd  shipping_cost_usd
count    656.000000      656.000000         656.000000
mean       2.862805       18.045913           4.052822
std        2.924404        5.722692           2.142393
min        0.000000        6.840000           1.485800
25%        1.000000       15.198100           2.732200
50%        2.000000       17.098100           3.114100
75%        5.000000       20.900000           5.169900
max       10.000000       34.008100           9.688100
```

📌 **더 알아보기: 데이터가 변하지 않은 이유**

- IQR로 구한 하한값보다 데이터의 최소값이 더 크기 때문에 제거되지 않음
- 비율로 연산하기 때문에 -값이 나올 수 있음



💬 **Chat Prompt**

```
shipping_cost_usd 컬럼에서 상한값 초과는 상한값으로 대체해줘
```

🤖 **GPT 출력: Message**
```
shipping_cost_usd 컬럼에서 상한값(8.89)을 초과하는 값을 상한값으로 대체했습니다. 대체 후의 shipping_cost_usd 컬럼의 통계 정보를 보면, 최대값이 상한값으로 조정된 것을 확인할 수 있습니다.

이로써 해당 컬럼의 이상치 처리 작업이 완료되었습니다. 추가로 궁금한 점이나 요청이 있으면 말씀해 주세요. 
```

🤖 **GPT 출력: Code**

```python
# shipping_cost_usd 컬럼에서 상한값 초과하는 데이터를 상한값으로 대체
data_cleaned['shipping_cost_usd'] = data_cleaned['shipping_cost_usd'].apply(
    lambda x: upper_bound if x > upper_bound else x
)

# 상한값 초과 데이터 대체 후 데이터 확인
print(data_cleaned.describe())
```

```
       installments  item_price_usd  shipping_cost_usd
count    812.000000      812.000000         812.000000
mean       2.695813       18.040812           3.911310
std        2.849679        7.608777           2.036154
min        0.000000        3.781000           1.485800
25%        1.000000       15.198100           2.601100
50%        1.000000       17.098100           3.101750
75%        4.000000       22.420000           5.116225
max       10.000000       34.008100           8.888912
```

🧑‍💻: 결측치와 이상치의 처리 결과를 확인해보겠습니다.


💬 **Chat Prompt**
```
결측치 처리와 이상치 처리 결과를 요약해줘
```

🤖 **GPT 출력: Message**
```
결측치와 이상치 처리 과정을 요약하면 다음과 같습니다:

1. 결측치 처리:
- shipping_cost_usd 컬럼:
  - 결측치가 있는 모든 행을 삭제하였습니다. 이로 인해 데이터셋의 크기가 감소했습니다.
- item_price_usd` 컬럼:
  - 결측치를 해당 컬럼의 평균값으로 대체하였습니다.

2. 이상치 처리:
- 상위 및 하위 3% 극단적인 값 제거:
  - 모든 수치형 컬럼(`installments`, `item_price_usd`, `shipping_cost_usd`)에서 상위 및 하위 3%의 극단적인 값을 제거하였습니다.
  
- shipping_cost_usd 컬럼의 IQR 방식 이상치 처리:
  - 하한값: -1.17 미만인 값을 제거하였습니다.
  - 상한값: 8.89를 초과하는 값을 상한값으로 대체하였습니다.

이로써 데이터셋은 결측치와 이상치가 적절히 처리된 상태입니다. 이렇게 정제된 데이터는 보다 신뢰할 수 있는 분석 결과를 도출하는 데 유용할 것입니다.

추가로 궁금한 점이나 요청이 있으시면 알려주세요.
```

***

## 3. Feature Engineering

Feature Engineering은 데이터 분석 및 머신러닝 모델링 과정에서 매우 중요한 단계로, 데이터를 바탕으로 새로운 특성(변수)을 생성하거나 기존 특성을 변형하여 분석의 성능을 향상시키는 과정을 말합니다.

📍**Feature Engineering의 주요 활동**

- **기존 특성 조합**: 여러 특성을 조합하여 새로운 특성을 만듭니다. 예를 들어, 가격과 수량을 곱하여 총 금액(total amount) 특성을 생성할 수 있습니다.
- **날짜/시간 특성 변환**: 날짜 및 시간을 연도, 월, 요일, 시간 등으로 변환해 모델에 유용한 정보를 추가합니다.
- **비율 계산**: 두 특성 간의 비율을 계산하여 새로운 특성을 만듭니다. 예를 들어, 매출과 비용을 이용해 이익률을 생성할 수 있습니다.

### 3.1 날짜 파생변수 생성

날짜는 Feature Engineering에서 가장 쉽게 사용할 수 있는 데이터입니다. 주말, 주중, 오전, 오후, 공휴일 등 만들어 낼 수 있는 경우의 수가 매우 많기 때문입니다. 따라서 분석하고자 하는 도메인에 맞추어 이를 활용하는 것을 추천드립니다.

💬 **Chat Prompt**
```
is_weekend 컬럼을 생성하고 이 값은 order_purchase_timestamp를 통해 주중, 주말로 분리하여 지정해줘
```

🤖 **GPT 출력: Message**
```
order_purchase_timestamp를 기준으로 주중과 주말을 분리하여 is_weekend 컬럼을 생성했습니다. 이 컬럼은 주문이 주말에 발생했을 경우 True, 주중에 발생했을 경우 False 값을 가집니다.

예시로 첫 몇 개의 데이터에서 주중(False)과 주말(True)이 잘 구분된 것을 확인할 수 있습니다. 추가로 작업이 필요하시면 알려주세요.
```

🤖 **GPT 출력: Code**

```python
# is_weekend 컬럼 생성 (주말: True, 주중: False)
data_cleaned['is_weekend'] = data_cleaned['order_purchase_timestamp'].dt.weekday >= 5

# 주중과 주말을 'Weekday'와 'Weekend'로 구분하여 저장
data_cleaned['is_weekend'] = data_cleaned['is_weekend'].apply(lambda x: 'Weekend' if x else 'Weekday')

# 결과 확인
data_cleaned[['order_purchase_timestamp', 'is_weekend']].head()
```

```
  order_purchase_timestamp  is_weekend
0      2017-01-23 18:29:00       False
1      2017-01-30 10:47:00       False
2      2017-01-31 17:40:00       False
3      2017-10-01 20:04:00        True
4      2017-10-01 09:15:00        True
```

💬 **Chat Prompt**
```
is_weekend을 막대 그래프로 시각화해줘
```

🤖 **GPT 출력: Message**
```
 is_weekend 컬럼의 분포를 보여주는 막대그래프입니다. 주중(Weekday)과 주말(Weekend)로 나누어 각각의 주문 빈도를 확인할 수 있습니다. 이를 통해 주중과 주말의 주문 패턴을 비교할 수 있습니다. 추가로 궁금한 사항이 있으면 알려주세요.
```

🤖 **GPT 출력: Code**

```python
# is_weekend 컬럼의 분포를 막대그래프로 시각화
plt.figure(figsize=(8, 6))
data_cleaned['is_weekend'].value_counts().plot(kind='bar', color='lightgreen', edgecolor='black')
plt.title('Distribution of Orders by Weekend')
plt.xlabel('Is Weekend')
plt.ylabel('Frequency')
plt.xticks(ticks=[0, 1], labels=['Weekday', 'Weekend'], rotation=0)
plt.grid(axis='y')
plt.show()
```

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/kang_lectures/gpt_ada/week_result.png?raw=true" width="600" height="400"></p>

### 3.2 추가 파생변수 생성

🧑‍💻: 일단 추가 파생변수를 만들어 놓으면 손해는 보지 않습니다. 데이터 분석의 목적과 방법이 명확치 않으면 GPT를 이용하는 것도 아주 좋은 방법입니다.

💬 **Chat Prompt**
```
데이터를 보고 추가할 수 있는 파생변수를 제안해줘
```

🤖 **GPT 출력: Message**
```
	1.	order_hour:
	•	설명: 주문이 이루어진 시각(시간)입니다. order_purchase_timestamp에서 시간을 추출하여 생성할 수 있습니다.
	•	활용: 특정 시간대에 주문이 집중되는지를 분석할 수 있습니다.
	2.	order_day:
	•	설명: 주문이 이루어진 요일입니다. order_purchase_timestamp에서 요일을 추출하여 생성할 수 있습니다.
	•	활용: 요일별 주문 패턴을 분석할 수 있습니다.
	3.	order_month:
	•	설명: 주문이 이루어진 월입니다. order_purchase_timestamp에서 월을 추출하여 생성할 수 있습니다.
	•	활용: 월별 매출 트렌드를 분석할 수 있습니다.
	4.	total_cost_usd:
	•	설명: 제품 가격과 배송비를 합한 총 비용입니다. item_price_usd와 shipping_cost_usd를 더하여 생성할 수 있습니다.
	•	활용: 고객이 실제로 지불한 총 금액을 분석할 수 있습니다.
	5.	is_high_value_order:
	•	설명: 특정 기준 금액 이상인 주문을 “고가 주문”으로 간주하는 플래그 변수입니다.
	•	활용: 고가 주문을 식별하고, 이러한 주문에 대한 특별한 분석이나 마케팅 전략을 수립할 수 있습니다.
	6.	days_since_order:
	•	설명: 현재 시점으로부터 주문이 이루어진 날짜까지의 일수를 계산한 변수입니다.
	•	활용: 고객의 최신 주문 시점을 파악하고, 재구매를 유도하는 데 사용할 수 있습니다.
	7.	product_category_group:
	•	설명: 제품 카테고리를 대분류로 그룹화한 변수입니다. 예를 들어, 비슷한 제품 카테고리들을 하나의 그룹으로 묶을 수 있습니다.
	•	활용: 제품의 대분류에 따른 구매 패턴을 분석할 수 있습니다.
	8.	payment_installment_type:
	•	설명: 할부 횟수에 따른 결제 유형을 나누는 변수입니다. 예를 들어, installments가 1이면 “일시불”, 2 이상이면 “할부”로 구분할 수 있습니다.
	•	활용: 할부와 일시불 고객의 행동 차이를 분석할 수 있습니다.
```

🧑‍💻: 할부 유형을 구분하여 향후 분석에 활용하는 것도 좋은 아이디어일 것 같습니다.

💬 **Chat Prompt**
```
installments의 분포를 시각화해줘
```

🤖 **GPT 출력: Message**
```
그래프는 installments 컬럼의 분포를 나타냅니다. 각 할부 횟수에 따른 빈도를 확인할 수 있으며, 이를 통해 할부가 얼마나 자주 사용되는지, 어떤 할부 횟수가 가장 많이 사용되는지 파악할 수 있습니다. 추가로 분석하거나 시각화할 부분이 있으면 말씀해 주세요. 
```

🤖 **GPT 출력: Code**

```python
import matplotlib.pyplot as plt

# installments 컬럼의 분포 시각화
plt.figure(figsize=(10, 6))
plt.hist(data_cleaned['installments'], bins=range(int(data_cleaned['installments'].min()), int(data_cleaned['installments'].max()) + 2), edgecolor='black')
plt.title('Distribution of Installments')
plt.xlabel('Number of Installments')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()
```

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/kang_lectures/gpt_ada/halbu.png?raw=true" width="600" height="300"></p>

🧑‍💻: 할부 개월수에 따라 유형을 3등분하여 0:일시불, 1~3:일반, 4~: 장기 로 구분하도록 하겠습니다.


💬 **Chat Prompt**
```
할부 개월수에 따라 유형을 구분하는 컬럼을 생성해줘
- 0개월: 일시불
- 1~3개월: 단기
- 4개월~: 장기
```

🤖 **GPT 출력: Message**
```
installments 컬럼을 기준으로 할부 개월수에 따라 “일시불”, “단기”, “장기”로 구분하는 installment_duration_type 컬럼을 생성했습니다. 이제 이 컬럼을 사용해 할부 유형에 따른 분석을 진행할 수 있습니다. 추가로 필요한 작업이 있으시면 말씀해 주세요.
```

🤖 **GPT 출력: Code**

```python
# 'installment_duration_type' 컬럼 생성: 할부 개월수에 따라 유형 구분
def categorize_installments(installments):
    if installments == 0:
        return '일시불'
    elif 1 <= installments <= 3:
        return '단기'
    else:
        return '장기'

data_cleaned['installment_duration_type'] = data_cleaned['installments'].apply(categorize_installments)

# 새로운 컬럼 확인
print(data_cleaned[['installments', 'installment_duration_type']].head())
```

```
   installments installment_duration_type
0             0                       일시불
1             0                       일시불
2             1                        단기
3             1                        단기
4             1                        단기
```

💬 **Chat Prompt**
```
installment_duration_type을 막대그래프로 시각화해줘
```

🤖 **GPT 출력: Message**
```
installment_duration_type 컬럼의 분포를 보여주는 막대그래프입니다. 할부 유형이 “일시불”, “단기”, “장기”로 구분되어 각각의 빈도를 확인할 수 있습니다. 이 시각화를 통해 어느 유형의 할부가 더 많이 사용되는지 알 수 있습니다. 추가로 분석하거나 궁금한 점이 있으시면 말씀해 주세요.
```

🤖 **GPT 출력: Code**

```python
# installment_duration_type 컬럼의 분포를 막대그래프로 시각화
plt.figure(figsize=(8, 6))
data_cleaned['installment_duration_type'].value_counts().plot(kind='bar', color='skyblue', edgecolor='black')
plt.title('Distribution of Installment Duration Type')
plt.xlabel('Installment Duration Type')
plt.ylabel('Frequency')
plt.xticks(rotation=0)
plt.grid(axis='y')
plt.show()
```

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/kang_lectures/gpt_ada/halbu_result.png?raw=true" width="600" height="300"></p>
