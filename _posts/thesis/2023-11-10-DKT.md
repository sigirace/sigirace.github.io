---
layout: single
title:  'Deep Knowledge Tracing'
toc: true
categories: [Thesis]
tags: [Knowledge Tracing]


---

본 게시물은 [DKT 논문](https://paperswithcode.com/paper/deep-knowledge-tracing)과 [게시글](https://hcnoh.github.io/2019-06-14-deep-knowledge-tracing) 읽고 정리하는 글이다.
{: .notice}

## 0. Abstract

- `Knowledge Tracing(KT)`은 컴퓨터가 지원되는 교육에서는 잘 확립된 문제이다.
- 학생의 지식을 효과적으로 모델링하는 것은 높은 교육적 영향을 가질 수 있지만, 잠재적인 과제들이 많이 있다.
- 이 논문에서는 학생의 학습을 모델링하기 위해 RNN을 사용하는 방식을 살펴본다.
- RNN 계열의 모델은 인간의 지식에 대해 명시적인 인코딩이 필요하지 않는다는 장점이 있다.
- 또한, 학생 지식의 더 복잡한 표현을 찾아 낼 수 있다.
- 신경망을 사용하는 것은 KT 문제의 데이터 셋에서 예측 성능이 크게 향상되었다.
- 학습된 모델은 커리큘럼을 설계하는데 사용될 수 있으며 학생의 과업을 구조적으로 밝혀 낼 수 있다.

 📍**Knowledge Tracing**

- 학습자의 퍼포먼스를 바탕으로 학습자의 지식 수준을 평가하는 task
- 학습자의 퍼포먼스: 학습자가 풀어놓은 문제 풀이의 결과
- 학습자의 지식수준: 학습자가 주어진 문제를 풀어낼 확률

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/thesis/dkt/1.png?raw=true" width="900" height="300"></p>

- KT 모델은 정오답 결과를 바탕으로 전체 문제 세트에 대한 정답률을 예측
- 중요한 것은 문제풀이 순서에 따라 학습자의 학습 효율이 달라질 수 있음

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/thesis/dkt/2.png?raw=true" width="900" height="300"></p>

## 1. Introduce

- 컴퓨터를 활용한 교육은 세계적 수준의 교육에 대한 개방적인 접근과 증가하는 학습 비용을 감소시킨다.
- KT는 학생의 지식을 시간에 따라 모델링하는 작업으로 학생들이 미래의 상호작용을 어떻게 수행할지 예측하는 것이다.
- 이러한 작업은 학생들에게 맞춤형으로 제공될 수 있고, **너무 쉽거나 어려울 것이라고 예측되는 컨텐츠를** `skip` **할 수 있게 한다.**
- 이를 수동으로 수행하는 지능형 교습 시스템은 이미 좋은 결과를 나타내었다.
- 기계학습 솔루션은 높은 수준의 개인화된 튜터링의 이점을 전세계 누구에게나 무료로 제공할 수 있으므로 풍부한 모델을 사용하여 그 수준을 높이는 것이 적절하다.
- 그러나 과거의 연구는 제한적인 기능을 제공하는 1차 `Markov`모델에만 의존하였다.
- 이 논문에서는 KT에 대해 시간적으로 깊고 유연한 신경망인 `Deep Knowledge Tracing(DKT)` 모델을 제시하고 있다.
- 이는 대규모 벡터를 사용하여 학생의 지식을 데이터에서 학습할 수 있도록 하였다.

☀️ **Achievement**

1. KT를 위한 순환 신경망의 새로운 적용을 이끌어 냄
2. KT를 위한 데이터셋의 검증에서 이전 최고 결과에 비해 AUC가 25% 향상됨
3. 전문가의 소견이 필요하지 않음을 입증
4. 개선된 커리큘럼의 생성

### 1.1 Knowledge Tracing

- KT는 time step 0부터 t까지 학생과 교육에 대한 상호작용이 주어졌을 때, t+1 시점을 예측하는 것이다.
- KT에서는 일반적으로 상호작용 x를 학생이 푼 문제에 대한 tag인 q와 그 답변이 맞았는지에 대한 정오 tag인 a를 time step t으로 묶어 다음과 같이 표현한다.

$$
x_t = \{q_t, a_t\}
$$

- 아래 Figure 1은 이에 대한 예시이다.

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/thesis/dkt/3.png?raw=true" width="900" height="300"></p>

- 이는 한 학생이 Khan Academy 8th grade의 수학 교과과정에서 50가지 문제를 푼 것과, 나머지 문제에 대한 예측을 나타낸다.
- 학생은 처음 두 문제를 Square root에 대해 풀었고 모두 정답을 맞췄고, Solving for x-intercept에 대한 문제는 잘못된 답변을 하였다.
- 이후 47문제에서 x-intercept, y-intercept 그리고 graphing 문제들을 풀엇다.
- 각 학생이 문제에 답변을 한 time step t에 모델은 다음 t+1에 학생이 다른 문제를 맞출지 그렇지 않을지에 대해 예측한다.
- 이전의 작업들에서 문제는 전문가가 할당한 단일 개념만을 나타냈다.
- 해당 모델은 전문가의 의견을 활용할 수 있지만 반드시 필요하진 않으며, 논문에서는 이러한 전문가 의견이 없음에도 모델이 자율적으로 학습할 수 있음을 입증하였다.

## 2. Related Work

### 2.1 Bayesian Knowledge Tracing

- `Bayesian Knowledge Tracing(BKT)`는 학생 학습의 시간적(=temporal) 모델을 구축하는 데 가장 널리 사용되는 접근이다.
- `BKT`는 학습자의 잠재된 지식 상태를 이진 변수로 모델링하는 방식으로, 각 변수는 단일 개념에 대한 이해 또는 이해하지 못함을 나타낸다.
- `Hidden Markov Model(HMM)`은 학습자가 주어진 개념에 대한 연습문제를 대답할 때, 옳고 그름에 따라 주어진 이진 변수에 대한 확률을 업데이트한다.
- 또한 해당 모델은 한 번 (어떤 개념에 대한) 스킬이 배워지면 절대 잊혀지지 않는다는 가정을 한다.
- 이 모델에 대한 최근 연구는 추측과 실수 추정의 문맥화, 개별 학습자에 대한 사전 지식 추정, 그리고 문제 난이도 추정을 포함하고 있다.

😗 **BKT vs HMM**

- BKT와 HMM은 엄밀하게 다른 알고리즘
- 그러나 컨셉 자체는 유사하기에 해당 논문에서는 예시를 들어 쓰고 있는 것으로 추측됨 (개인생각)

☀️ **Knowledge Tracing Difficulties**

1. 학생의 이해를 이진으로 표현하는 것이 비현실적
2. Hidden variable들의 의미와 문제에 대한 매핑이 모호할 수 있고, 이는 모델이 문제가 하나의 개념만을 포함하기 어려움을 의미
   - hidden variable: 학습자의 이해도, 흥미와 같이 학습자의 행동에 영향을 미치지만 직접적으로 관찰 및 측정이 어려움
3. 이진 응답 데이터로 모델링 할 수 있는 문제의 종류가 제한적임

### 2.2 Other Dynamic Probabilistics Models

- `Partially Observable Markov Decision Processes(POMDP)`는 학습자가 연구, 공부 등(=open-ended)을 통해 답을 찾아 낼 때, 학습자의 시간에 따른 행동을 모델링 하는 것으로 사용된다.
- `POMDP`는 유연한 프레임워크를 제공함에도 매우 큰 state space를 탐색해야 하는 단점이 있다.
- 따라서 현재 구현된 것들은 제한적이고 하드 코딩으로 이루어진 이산 상태의 공간이다.
- 즉, 실상황을 다루기는 힘들지만 위의 어려움을 극복할 수 있는 잠재력이 있다.
- `Performance Factors Analysis(PFA)` 그리고 `Learning Factors Analysis (LFA)`  프레임워크로 생성된 모델은 간단하지만 BKT에 필적하는 예측력을 보인다.
- `AdaBoost`, `Random Forest` , `linear regression`, `logistic regression` 그리고 `ffnn`이 사용된 모델 조합은 `BKT` 및 `PFA`에 비해 우수한 결과를 보인다.
- 그러나 이러한 앙상블 기법은 정확한 개념 라벨링에 대한 요구사항을 포함하기 때문에 역시나 제한 사항이 있다.
- 최근 연구는 `Item Response Theory(IRT)` 모델과 `Switched Non-linear Kalman filters `를 결합하는 방법이 연구되고 있다.
- 이러한 접근 방식은 유망하지만, 현재는 앞서 어려움보다 더 제한적이고 많은 비용이 예상된다.

### 2.3 Recurrent Neural Networks

- 순환 신경망은 시간에 따라 인공 신경을 연결하기에 유연하고 동적인 모델이다.
- 정보의 전파는 hidden neuron들이 시스템의 입력과 이전의 활성화를 통해 진화한다는 점에서 순환적이다.
- `HMM`과는 달리 `RNN`은 잠재적 상태를 고차원이면서 연속적으로 표현한다.
- 이러한 `RNN`의 표현의 이점은 입력보다 훨씬 뒤의 상태를 예측할 수 있다는 것이다.
- 이를 공식화 한다면 학생의 지식을 추적하는데 더 성공적일 것이라고 기대할 수 있다.

## 3. Deep Knowledge Tracing

- 저자는 인간의 학습은 다양한 속성(=자료, 맥락, 발표, 시간경과 등)에 의해 좌우된다고 생각한다.

- 이러한 속성 중 상당수는 문제에 속성을 할당하거나 그래픽 모델을 구조화 하는 데 있어 원칙만으로는 정령화 하기 어렵다.

  ☞ 인간의 학습은 여러 속성에 의존적이고 이를 정량화 하기는 어려움

- 본 논문에서는 과거 활동을 기반으로 문제에 대한 학생의 반응을 예측하는 task를 수행하기 위해 vanila RNN과 LSTM을 사용한다.

### 3.1 Model

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/thesis/dkt/4.png?raw=true" width="900" height="400"></p>

- RNN 및 LSTM에 대한 내용은 따로 적지 않는다.
- 아직 개념이 확실하지 않다면 [LSTM의 모든것](https://sigirace.github.io/time%20series/LSTM_method/)을 통해 쉽게 확인할 수 있다.

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/thesis/dkt/5.png?raw=true" width="900" height="300"></p>

- `DKT`모델은 다음과 같이 학습자의 퍼포먼스가 입력으로 들어가면 다음 time step에서 전체 문제들에 대한 정답 확률을 도출한다.

### 3.2 Input and Output Time Series

- RNN과 LSTM을 훈련시키기 위해 학생의 상호작용을 고정된 입력 벡터로 변환시켜야 하는데, 상호작용의 성격에 따라 두 가지 방법을 사용하여 이를 수행한다.

- 작은수인 M개의 고유한 연습문제가 있는 데이터셋의 경우 $x_t$를 학생의 상호작용 튜플 $h_t=\{q_t, a_t\}$의 `one-hot encoding`으로 설정한다.

  - $x_t$는 0과 1을 원소로 하고 길이가 2M인 벡터이다.

    ☞ 아래 `one-hot encoding`과정에서 상세히 설명

  - 이때 $q_t$와 $a_t$를 분리하여 별도의 표현을 사용하면 성능이 저하된다.

- 만약 M이 매우 큰 수라면 feature space가 sparse해지기에 `one-hot encoding`은 실용적이지 않다.

- 이러할 경우 $n_{q,a} \sim N(0,I)$인 랜덤한 벡터로 변환시키게 된다.

- 출력 y_t는 문제의 수와 동일한 길이의 벡터이다.

- 각 항목은 학생이 특정 문제에 올바르게 답할 것으로 예상되는 확률이다.

- 따라서 $a_{t+1}$은 $q_{t+1}$에 해당하는 예측이다.

☀️ **Additional**

- d 차원의 k-sparse하게 압축된 상태는 $k\log(d)$의 random linear projection으로 복구 될 수 있다고 함
  - d 차원의 벡터에서 k개 만이 0이 아닌 데이터를 갖고 있음
  - random linear projection은 높은 차원의 데이터를 낮은 차원의 공간으로 매핑하는 절차이며 이때 projection을 위해 사용되는 행렬은 무작위로 생성됨
  - 이러한 방식은 온전한 데이터를 낮은 차원으로 축소하면서도 원본 데이터의 중요한 특징을 유지하는데 도움이 됨
- `one-hot`은 1 sparse한 신호이기 때문에 학생 상호작용 튜플은 $\log(2M)$의 고정된 random gaussian 입력 벡터에 의해 인코딩 될 수 있음

📍 **One-Hot Encoding in DKT**

- 전체 문제 세트가 M개라고 할 때, 현재 time step t에서의 상호작용 튜플은 $h_t=\{q_t, a_t\}$ 임을 위해서 설명함
- 상호작용의 표현은 일반적으로 상호작용 인덱스를 사용하여 아래와 같이 정의할 수 있음

$$
x_t = q_t + M*r_t
$$

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/thesis/dkt/6.png?raw=true" width="900" height="900"></p>

- 최종적으로 아래와 같이 `one-hot encoding`을 수행 할 수 있음

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/thesis/dkt/7.png?raw=true" width="900" height="300"></p>

### 3.3 Optimization

- 목적함수는 모델로부터 관찰된 학생들의 응답 시퀀스의 `negative log likelihood` 를 사용한다.
- $\delta(q_{t+1})$을 time step t+1에서의 `one-hot encoding`이라고 하며, $l$을 `binary cross entropy`라고 한다.

$$
L = \sum_{t}l(y_i^T\delta(q_{t+1}),a_{t+1})
$$

- `mini-batch` 대해 `stochastic gradient descent`를 수행하여 목적함수의 값을 최소화 시킨다.
- 이때 `overfitting` 방지를 위해 $y_t$를 계산시 `dropout`이 $h_t$에 적용되나 $h_{t+1}$에는 적용되지 않는다.
- `backpropagation` 시 `gradient clipling`을 통해 `gradient exploding`을 방지한다.
- 해당 논문의 모든 모델은 `hidden dimension` 을 200, `mini-batch`를 100으로 적용하였다.

☀️ **Inference**

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/thesis/dkt/8.png?raw=true" width="900" height="300"></p>

- 모델의 추론은 위와 같이 `Naive`하게 이루어짐

☀️ **Training**

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/thesis/dkt/9.png?raw=true" width="900" height="300"></p>

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/thesis/dkt/10.png?raw=true" width="900" height="300"></p>

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/thesis/dkt/11.png?raw=true" width="900" height="300"></p>

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/thesis/dkt/12.png?raw=true" width="900" height="300"></p>

## 4. Educational Applications

### 4.1 Improving Curricula

- 앞서 학습 순서에 따라 성취도가 다르다고 소개하였듯, 학생에게 제공할 최상의 학습 항목 순서를 선택할 수 있다.
- 학생과 `hidden knowledge state`가 주어지면, `RNN`에 특정 문제를 할당하여 예상되는 지식 상태를 계산할 수 있다.
- 예를들어 `Figure 1`에서 학생이 50개의 문제에 답한 후, 학생에게 보여줄 수 있는 다음 문제를 테스트하고 그 선택에 따른 예상 지식 상태를 계산할 수 있다.
- 해당 학생에게 예상되는 최적의 다음 문제는 Solving y-intercept를 다시 푸는 것으로 보인다.
- 일반적으로 정확도를 최대화 하기 위해 다음 문제의 순서를 선택하는 것은 `Markov Decision Problem(MDP)`으로 표현할 수 있다.
- `Section 6.1`에서는 이 문제를 `expectimax`를 사용하여 해결할 것이고 이를 두가지 문제 세트에 대해 비교할 것이다.
  - `Mixing`: 다른 주제의 문제가 섞임
  - `Blocking`: 같은 유형의 문제를 일련으로 품

☀️ **Example of Curricula**

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/thesis/dkt/13.png?raw=true" width="900" height="400"></p>

- `score의 평균 `을 `reward`로 사용하여 MDP 문제로 변환할 수 있음
- 위와 같은 상황을 `Tree` 구조로 바꿀 수 있음

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/thesis/dkt/14.png?raw=true" width="900" height="300"></p>

- Tree는 가장 상단에 현재 `State`를 반영하는 `Node`가 존재하며 현재 `Node`로 부터 가능한 `Action`들을 그 다음 단계의 `Node`로 구성할 수 있음
- 위의 예제에서는 총 3문제를 추천할 수 있으며 따라서 `Action`의 가능한 경우의 수는 3가지가 됨
- 여기서 어떤 `Action`을 선택하는지에 대한 문제는 `reward`를 살펴봄으로 해결할 수 있음

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/thesis/dkt/15.png?raw=true" width="900" height="300"></p>

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/thesis/dkt/16.png?raw=true" width="900" height="300"></p>

- 1번 문제를 추천하는 `Action`에 대해서는 그 다음에 얻을 수 있는 `reward`로 두 가지를 고려할 수 있음
- 이 두가지의 확률을 이용해 `reward`의 평균을 구하게 되고 이것의 1번 문제를 추천하는 `Action`에 대한 대표 `reward`가 됨

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/thesis/dkt/17.png?raw=true" width="900" height="300"></p>

- 마찬가지로 다양한 문제에 대해서 수행할 수 있음
- 이는 `Expectimax`라는 `Tree search algorithm`

### 4.2 Discovering Exercise Relationships

- `DKT` 모델은 일반적으로 전문가가 수행하는 데이터의 잠재적 구조나 개념을 발견하는 작업에 적용될 수 있다.
- 즉, 문제간의 구조 혹은 관계를 확인하기 위해 모든 문제쌍 i,j의 영향을 확인할 수 있는 $J_{i,j}$를 생성한다.

$$
J_{i,j}={y(j|i)\over \sum_{k} y(j|k)}
$$

- $y(j|i)$는 문제 i를 맞췄을 때, `RNN`이 계산한 문제 j에 대해 정답을 맞출 확률이다.

- 이는 `Section 6.2`에서 `RNN`에 의해 밝혀진 종속성의 특징이 문제와 관련된 사전 요구 사항을 복구한다는 것을 보여준다.

  ☞ `RNN`은 시간에 따른 데이터의 패턴을 학습하므로, 이를 통해 연습문제들 사이의 종속성을 파악할 수 있으며, RNN이 문제를 수행하기 위해 필요한 사전지식이나 능력을 재현하거나 파악하는데 사용될 수 있다는 것을 의미함

☀️ **Example of Relationships**

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/thesis/dkt/18.png?raw=true" width="900" height="300"></p>

- 이러한 방식으로 모든 문제쌍의 값을 정의할 수 있음
- 정의된 값들을 이용하여 모든 문제들을 Node로 하고 해당하는 J 값을 Edge로 하는 `Directed Graph`를 그릴 수 있게 됨

## 5. Datasets

- 성능을 평가하기 위해 세가지 데이터 셋(simulated, khan academy, benchmark)에서 모델을 테스트한다.
- `metric`은 `AUC`를 사용한다.
- `simulated data`가 아닌 경우 `5-fold cross validation`을 수행하고, `hyper parameters`는 `train data`를 사용하여 튜닝한다.
- 이렇게 `DKT`로 구해진 결과를 `BKT`와 비교하고, 더하여 `DKT`의 결과를 학생이 특정 문제를 맞출 확률의 `marginal` 확률을 단순히 계산하여 예측한 것과 비교한다.

### 5.1 Simulated Data

- 가상의 개념을 배운 가상의 학생들에 대해 얼마나 잘 응답을 할 수 있는지 테스트한다.
- 각 실험의 수행동안 1~5개의 개념으로부터 도출된 50개의 문제를 푼 2,000명의 학생을 생성한다.
- 각 학생은 각 개념에 대해 잠재적 지식 상태를 갖고 있고, 각 문제는 한개의 개념과 난이도를 갖고 있다.
- 학생이 개념에 대한 스킬 $\alpha$를 갖고 있을 경우, 난이도 $\beta$의 문제를 정확하게 풀 확률은 `Item Response Theory(IRT)`로 모델링 할 수 있다.

$$
p(correct|\alpha, \beta) = c + {1-c\over1+e^{-\alpha\beta}}
$$

- 여기서 c는 찍어서 맞출 확률을 의미하며, 0.25로 세팅한다.
- 학생들은 시간에 따라 학습하며 이를 답한 문제에 상응되는 기술로 변환시킨다. ☞ `Affine`
- 개념에 대한 라벨은 제공하지 않으며, 입력은 단순히 문제의 인덱스와 그것이 정확히 답변 되었는지에 대한 여부이다.
- 추가로 2,000명의 시물레이션 된 테스트 학생들에 대해 예측 성능을 평가한다.
- 정확도, 평균 그리고 분산을 이해하기 위해 각 개념의 수에 대해 무작위로 생성된 데이터를 20번 반복하여 수행한다.

👀 **Affine**

>'Affine’은 수학 용어로, 기본적으로 선형 변환 후에 이동 변환을 추가한 것을 의미한다. 해당 논문에서 'simple affine change’는 학생들이 시간이 지남에 따라 학습하면서 그들의 기술 레벨이 선형적으로 변화한다는 것을 의미하는 것으로 보인다. 이는 학습 과정에서 학생의 지식이나 기술이 점진적으로 향상되는 것을 모델링하는 방법이다.

### 5.2 Khan Academy Data

- Khan Academy의 8학년 공통 핵심 커리큘럼에서 익명화된 학생의 문제 풀이 정보를 사용한다.
- 69개의 다른 문제 유형에 대해 47,495명의 학생이 완료한 1.4M의 문제를 포함한다.
- 개인정보는 없었으며 익명화된 데이터는 해당 논문을 위해 작업하는 연구자들만 접근 가능하다.

### 5.3 BenchMark Data

- Assistment 2009~2010 공개 benchmark data를 사용하여 평가한다.
- 이는 초등학교 학생들에게 수학을 동시에 가르치고 평가하는 온라인 튜터이다.
- 본 논문에서 사용한 데이터 중 해당 데이터만이 접근 가능하다.

## 6. Result

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/thesis/dkt/19.png?raw=true" width="900" height="300"></p>

- 모든 데이터 셋에서 DKT는 이전 방법보다 좋은 성능을 보이는 것으로 확인되었다.

- khan 데이터 셋에서는 `LSTM` 신경망 모델을 사용하여 `AUC`가 0.85로 `BKT`의 0.68보다 향상됨을 볼 수 있다.

- Assistments 데이터 셋에 대해서도 25% 향상됨을 보인다.

- `Figure 3(b)`를 보면 랜덤하게 맞출 확률 25%에 비해 약 3배 이상의 확률을 보이는 것으로 나타난다.

- 합성 데이터 셋에 대한 예측 결과는 `DKT`의 능력을 입증한 것이다.

- `Figure 3(a)`를 보면 `LSTM`과 `RNN` 모델 모두 학생의 응답을 `oracle`처럼 잘 예측한다.

  ☞ `oracle`처럼 예측하기 위해서는 잠재개념, 각 문제의 난이도, 학생의 사전 지식 분포, 문제를 푼 후 발생한 affine 변환 같은 함수를 모방해야 한다.

- 반면 `BKT` 예측은 라벨이 없는 개념을 학습하는 매커니즘이 없기 때문에 숨겨진 개념이 증가할 수록 성능이 저하되었음을 볼 수 있다.

👀 **Oracle**

>'Oracle'은 이 컨텍스트에서 완벽한 지식이나 정보를 가진 이론적인 개념을 가리킨다. 즉, 모든 가능한 변수와 결과에 대해 완벽하게 알고 있는 ‘전지전능한’ 시스템을 의미한다. 여기서는 모든 학생의 반응을 완벽하게 예측할 수 있는 시스템을 가리킨다. 이는 모델이 학생의 지식 상태를 완벽하게 이해하고, 그에 따라 학생의 반응을 정확하게 예측할 수 있다는 것을 의미한다.

### 6.1 Expectimax Curricula

- 본 논문에서는 Assistment 데이터 셋에서 30개의 연습문제에 걸쳐 5개의 개념 하위 집합에 대해 문제를 선택하는 다양한 커리큘럼을 테스트하였다.

  ☞ 말이 어려운데 그냥 다양하게 커리큘럼을 생성하여 위에서 설명한 `MDP`문제를 풀었다고 보면 될 듯함

- `Figure 3(c)`를 보면 `blocking`이 `mixing`에 비해 눈에 띄는 이점을 가짐을 볼 수 있다.

  ☞ `blocking`은 같은 개념의 문제를 깊게 푸는 `MDP-1`과 동등한 성능을 보임

- 만약 다음 문제를 선택할 때 더 멀레 보게 되면, `MDP-8`과 같이 더 적은 문제를 풀어도 높은 `KT`를 가능하게 하는 커리큘럼도 만들 수 있을 것이다.

### 6.2 Discovered Exercise Relationships

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/thesis/dkt/20.png?raw=true" width="900" height="700"></p>

- 합성 데이터 셋에서의 예측 정확도를 통해 `DKT` 모델을 사용하여 데이터 셋의 잠재적 구조를 이끌어 낼 수 있다.
- `Figure 4`를 보면 모델의 조건부 영향 그래프는 합성 데이터에 대해 5개의 잠재 개념이 군집화 되어있음을 확인할 수 있다.
- 방향성이 있는 간선은 위의 ` Discovering Exercise Relationships`의 방정식을 통해 계산할 수 있다.
- 여기서 흥미로운 점은 같은 개념의 연습문제가 시간에 따라 멀리 떨어져 발생하는 경우에 대해서도 잘 작동한다는 것이다.
- 예를들어 노드 번호가 순서를 나타낼 경우 문제 5번은 concept 1에서 나왔고 동일 concept의 문제가 22번째에서 나타났어도 둘 간의 강한 연관성이 있음을 확인 할 수 있다.
- 같은 기법을 사용하여 Khan 데이터 셋을 분석했을 때, `Figure 4`를 보면 8학년 공통 핵심 커리큘럼이 서로 어떻게 관련이 있는지 명확히 알 수 있다.
- 이는 `DKT`를 통해 나타난 조건부 관계가 데이터의 기본적인 추세에서 나타나는지 판단하는 실험을 통해 확인할 수 있다.

☀️ **Experiment**

- 측정방법 (1): A를 방금 대답한 후 B를 대답할 확률
- 측정방법 (2): A를 정확하게 대답한 후 B를 정확하게 대답할 확률 (이때, `DKT` 모델을 사용하지 않음)
- 측정방법 (1)과 (2)는 지식 상태 변화를 고려하지 않고 단순히 문제 간의 전환 확률을 측정한 것
- 반면 `DKT`는 학생들으 지식 상태를 동적으로 추적하고 예측
- 이러한 방법으로 생성된 그래프와 `DKT` 모델을 사용한 그래프가 일치하지 않는 것은 `DKT`가 더 정확하게 지식을 추적하고 예측한다는 것을 의미
- 즉, `DKT`로 생성한 조건부 관계가 기본적인 추세가 아님을 의미함

## 7. Discussion

- 이 논문은 `RNN`을 교육 분야의 지식 추적 문제에 적용한 것으로, 기존 분석에 사용되던 데이터 셋에서 `SOTA`를 기록하였다.
- `RNN`을 `KT`에 적용하는 것은 미래 연구의 많은 방향성을 제공하였다.
- 추가적으로 다른 특성들을 입력으로 포함시키거나 다른 교육적 영향을 탐구하거나 여러 가설들을 검증할 수 있다.
- `DKT`는 벡터 입력을 받기 때문에 이론적으로 더 복잡한 학습 활동에 대한 지식을 추적할 수 있을 것이다.

### 7.1 Advantage

- 전문가의 주석이 필요 없음 (=스스로 개념에 대한 패턴을 학습)

  ☞ 전문가가 문제를 푸는 순서를 정하는 등의 고려가 필요하지 않음

- 벡터화 될 수 있는 어떤 학생의 입력에도 작동할 수 있음

### 7.2 Disadvantage

- 온라인 교육환경과 같은 곳에서 사용하는 대량의 훈련 데이터가 필요함

