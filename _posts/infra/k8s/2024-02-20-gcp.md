---
layout: single
title:  'k8s (2) GCP를 사용한 쿠버네티스 실습'
toc: true
categories: [K8S]
tags: [GCP, GKE, Onprem Kubernetes]
---

[데브옵스(DevOps)를 위한 쿠버네티스 마스터](https://www.inflearn.com/course/%EB%8D%B0%EB%B8%8C%EC%98%B5%EC%8A%A4-%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4-%EB%A7%88%EC%8A%A4%ED%84%B0/dashboard) 강의 정리
{: .notice}



## 1. GKE 환경 실습

### 1.1 Project 생성

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/k8s/gcp_practice/gke1.png?raw=true" width="600" height="250"></p>

- 신규 project를 생성

<br>

### 1.2 Kubernetes Engine API 설치

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/k8s/gcp_practice/gke2.png?raw=true" width="600" height="250"></p>

- 메뉴 > Kubernetes Engine
- 생성한 project에 kubernetes engine api 설치
- 사용 버튼 클릭
- 너무 오래 기다리면 새로고침

<br>

### 1.3 클러스터 생성

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/k8s/gcp_practice/gke3.png?raw=true" width="600" height="250"></p>

- 만들기 버튼 클릭

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/k8s/gcp_practice/gke4.png?raw=true" width="600" height="400"></p>

- STANDARD 클러스터로 전환
- 전환 후 만들기 버튼 클릭

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/k8s/gcp_practice/gke5.png?raw=true" width="600" height="100"></p>

- 클러스터 생성 중

📍 **Note1. Standard vs Autopilot**

- Standard: 가상머신(=노드) 생성
- Autopilot: 가상머신(=노드) 없이 컨테이너만으로 서비스 제공, 서버리스 개념

📍**Note2. 리전 vs 영역**

- 리전: 데이터 센터가 있는 위치

- 영역: 데이터 센터

  ☞ 리전은 여러 영역에 배치하여 가용성을 보장하나 비용 발생

📍 **Note3. 제어 영역 버전**

- 버전에 대한 관리를 구글이하냐 내가 하냐 차이

<br>

### 1.4 클러스터 사용

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/k8s/gcp_practice/gke6.png?raw=true" width="600" height="250"></p>

- 클라우드 쉘 활성화
- 클라우드 쉘은 일종의 가상머신으로 클러스터에 원격접속하기 위해 사용
- 쉘은 클러스터와 관계 없으며 별도의 VM

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/k8s/gcp_practice/gke7.png?raw=true" width="600" height="200"></p>

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/k8s/gcp_practice/gke8.png?raw=true" width="600" height="200"></p>

- 연결 명령어 확인 및 실행
- gcloud 명령으로 접속 권한 인증

````
kubectl get nodes
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/k8s/gcp_practice/gke9.png?raw=true" width="600" height="100"></p>

- kubectl: 노드에 접근
- get nodes: node 정보 얻어옴

<br>

### 1.5 애플리케이션 배포

````
kubectl create deploy tc --image=consol/tomcat-7.0 --replicas=5
````

- `kubectl`: Kubernetes 클러스터를 관리하기 위한 커맨드라인 툴
- `create deploy`: 새로운 디플로이먼트를 생성하는 명령어
- `tc`: 생성될 디플로이먼트의 이름
- `--image=consol/tomcat-7.0`: 디플로이먼트에 사용될 컨테이너 이미지를 지정
- `--replicas=5`: 디플로이먼트에 의해 관리될 파드(Pod)의 수를 지정
- 즉, `consol/tomcat-7.0` 이미지를 사용하여 "tc"라는 이름의 디플로이먼트를 생성하고, 이 디플로이먼트는 5개의 복제본을 가진 파드를 클러스터에 배포하도록 Kubernetes에 요청함
- 이를 통해, Tomcat 서버 5개가 실행되는 환경을 구축

````
kubectl expose deploy tc --type=LoadBalancer --port=80 --target-port=8080
````

- 컨테이너를 만든 다음 외부에 노출시키는 명령어
- 쿠버네티스에 배포 되었더라도 외부에 노출되지 않음

````
kubectl get pods,svc
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/k8s/gcp_practice/gke10.png?raw=true" width="600" height="140"></p>

- svc: 서비스로 포트를 외부로 노출시키는 기능을 가지고 있음
- 5대의 pod가 띄워져 있음
- GCP의 LoadBalancer가 공인 IP를 자동으로 받아옴
- 공인 IP에 접속하면 LoadBalancer가 트래픽을 분산해줌

````
kubectl get pods -owide
````

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/k8s/gcp_practice/gke11.png?raw=true" width="800" height="130"></p>

- pod들이 배포된 정보를 알 수 있음
- dq8w-2대, f6v9-2대, ntl9-1대

<br>

### 1.6 삭제

- 비용 부과 되지 않게 삭제

<br>

## 2. VM 환경 설치 가이드



### 2.0 체크리스트

- 호환되는 리눅스 머신: 데비안, 레드햇 기반
- 클러스터의 모든 머신에 걸친 전체 네트워크 연결
- 모든 노드에 대한 고유한 호스트 이름, MAC 주소 및 product_uuid
- 특정 포트 개방

<br>

### 2.1 VM 생성

- 마스터 노드 1대/ 워커 노드 2대
- 가상머신은 2CPU, 4GB 메모리 사용 필요 (최소사양)
- kubelet이 제대로 작동하기 위한 스왑의 비활성화

📍 **스왑의 비활성화**

- 스왑: 메모리에 있는 정보를 오랫동안 쓰지 않은 경우 메모리 관리를 위해 디스크로 보냄
- 쿠버네티스 클러스터 입장에서 리소스에 대한 관리가 효율적으로 되지 않음
- 메모리가 안남아있는데 메모리가 남아있는 것 처럼 보여짐
- 디스크로 내려도 사실 메모리에는 있다고 봐야함

✏️ **모든 노드에서 명령어 실행**

```
sudo swapoff -a # 현재 시스템에 적용
sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab # 리부팅 필수
```

<br>

### 2.2 컨테이너 런타임 설치

- [설치 자료 참고](https://www.itzgeek.com/how-tos/linux/ubuntu-how-tos/install-containerd-on-ubuntu-22-04.html)
- kubelet: 쿠버네티스 설치시 같이 설치되는 데몬으로 containerd를 제어함
  - 이전에는 docker로 containerd를 제어했음
- v 1.26 부터는 호환성 문제가 있어 kubelet과 containerd를 따로 설치

```
sudo apt update
sudo apt install -y ca-certificates curl gnupg lsb-release
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list
```

- Using Docker Repository

```
sudo apt update
sudo apt install -y containerd.io
```

- Install Containerd

```
sudo systemctl status containerd # Ctrl + c를 눌러서 나간다.
```

- 설치 확인

```
cat <<EOF | sudo tee -a /etc/containerd/config.toml
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
SystemdCgroup = true
EOF
```

- Containerd configuration for Kubernetes

```
sudo sed -i 's/^disabled_plugins \=/\#disabled_plugins \=/g' /etc/containerd/config.toml
sudo systemctl restart containerd
```

- containerd 실행

```
ls /var/run/containerd/containerd.sock
```

- 소켓이 있는지 확인

<br>

### 2.3 쿠버네티스

- [설치 자료 참고](https://kubernetes.io/ko/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)
- 위 사이트에서 스크립트를 가져오고 실행

```
cat <<EOF > kube_install.sh
# /etc/apt/keyrings 폴더 생성 및 권한 부여
sudo mkdir -p -m 755 /etc/apt/keyrings

# 1. apt 패키지 색인을 업데이트하고, 쿠버네티스 apt 리포지터리를 사용하는 데 필요한 패키지를 설치한다.
sudo apt-get update
sudo apt-get install -y apt-transport-https ca-certificates curl gpg

# 2. 구글 클라우드의 공개 사이닝 키를 다운로드 한다.
sudo curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

# 3. 쿠버네티스 apt 리포지터리를 추가한다.
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list

# 4. apt 패키지 색인을 업데이트하고, kubelet, kubeadm, kubectl을 설치하고 해당 버전을 고정한다.
sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
EOF
```

- kubernetes 설치 스크립트 작성

```
sudo bash kube_install.sh
kubeadm version # 버전 확인
```

- kubenetes 설치



📍 **kubectl**

- **kubectl**은 Kubernetes 클러스터와 상호작용하기 위한 커맨드 라인 인터페이스(CLI) 도구입니다. 사용자는 kubectl을 사용하여 클러스터에 배포된 애플리케이션을 관리하고, 클러스터 리소스를 조회하며, 클러스터의 상태를 확인할 수 있습니다. kubectl 명령은 Kubernetes API 서버와 통신하여 이러한 작업을 수행합니다.
- 예: 파드 생성, 서비스 조회, 로그 확인 등의 작업을 kubectl을 통해 실행할 수 있습니다.

📍 **kubeadm**

- **kubeadm**은 Kubernetes 클러스터를 쉽게 부트스트랩(초기 설정)하는 데 사용되는 도구입니다. kubeadm init과 kubeadm join 명령어를 사용하여 새로운 클러스터를 생성하거나, 기존 클러스터에 노드를 추가할 수 있습니다. kubeadm은 클러스터의 컨트롤 플레인 구성, 인증서 생성 및 배포, kubeconfig 파일 설정, 네트워크 플러그인의 설치 등 클러스터 구성에 필요한 다양한 작업을 처리합니다.
- 예: kubeadm init으로 새 클러스터의 마스터 노드를 설정하고, kubeadm join으로 워커 노드를 클러스터에 추가합니다.

📍 **kubelet**

- **kubelet**은 모든 Kubernetes 노드에서 실행되는 에이전트입니다. kubelet은 각 노드에 할당된 파드(Pods)를 관리하며, 컨테이너 런타임과 통신하여 파드의 컨테이너가 올바르게 실행되고 있는지를 확인합니다. kubelet은 주기적으로 Kubernetes API 서버로부터 각 노드에 할당된 파드에 대한 정보를 받아, 파드의 컨테이너를 실행하거나 중지하고, 파드 상태를 API 서버에 보고합니다.
- 예: 파드 스펙(PodSpec)에 따라 컨테이너를 시작하고, 파드의 생명주기 이벤트를 관리합니다.

<br>

### 2.4 넷필터 브릿지 설정

- 넷필터 브릿지가 컨테이너간 네트워크 통신 수행 ☞ 활성화 시켜야함
- docker.io는 자동으로 활성화되나 containerd를 직접 설치하기 때문에 활성화 시켜야함

```
sudo -i
modprobe br_netfilter
echo 1 > /proc/sys/net/ipv4/ip_forward
echo 1 > /proc/sys/net/bridge/bridge-nf-call-iptables
exit
```

- 위 명령어는 Linux 시스템에서 NAT(네트워크 주소 변환)를 설정하는데 사용

📍**NAT**

- 단일 공용 IP 주소를 사용해 여러 장치를 인터넷에 연결
- modprobe: 네트워크 스택과 Linux 브리지 간에 패킷을 전달할 수 있도록 하는데 사용되는 커널 모듈 로드

<br>

### 2.5 마스터 노드 초기화

- 다른 노드들이 클러스터에 참여할 수 있도록 제안할 수 있음
- init시에 token이 발행되고, 이를 다른 노드들에게 전달 가능
- token을 받은 노드는 클러스터에 join 할 수 있음
- token에 따라 master/worker 등 차이가 있음

````
sudo kubeadm init
````

<br>

### 2.6 클러스터 사용 초기 세팅 (마스터 노드)

```
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

- 마스터 노드 초기화시 사용자 세팅 명령어 사용

<br>

### 2.7 워커 노드 추가

```
sudo kubeadm join [ip:port] --token [token] --discovery-token-ca-cert-hash sha256:[sha256]
```

- 마스터 노드 초기화시 join 명령어 복붙하여 워커 노드에서 실행



📍**노드 연결 실패 시 점검**

```
sudo kubeadm reset
```

- init이나 join을 잘못 수행한 경우 초기 설정으로 돌아감

```
sudo kubeadm token list
sudo kubeadm token create --print-join-command
```

- token list 확인 및  재발급 (마스터 노드 실행)

<br>

### 2.8 연결된 노드들의 상태 확인

```
kubectl get nodes
```

- 처음에는 NotReady 상태
- 쿠버네티스가 정상적으로 구동되기 위해서는 컨테이너끼리 네트워크를 구성하는 plug-in이 필요

<br>

### 2.9 Pod 네트워크 배포

- 앞서 구성한 유저 설정을 통해 클러스터에 cilium 설치
- [설치 참고 자료](https://kubernetes.io/docs/tasks/administer-cluster/network-policy-provider/cilium-network-policy/)
- 마스터 노드에서 실행

```
curl -LO https://github.com/cilium/cilium-cli/releases/latest/download/cilium-linux-amd64.tar.gz
sudo tar xzvfC cilium-linux-amd64.tar.gz /usr/local/bin
rm cilium-linux-amd64.tar.gz
cilium install
```

- 모든 노드들 상태가 Ready로 변경



📍**Cilium**

Cilium은 CNI로 Linux 컨테이너 관리 플랫폼을(Docker, Kubernetes) 사용하여 배포된 애플리케이션 서비스 간 네트워크 연결을 보호하는 오픈 소스 소프트웨어입니다. 



📍 **CNI**

[CNI](https://github.com/containernetworking/cni)는 컨테이너간의 네트워크를 제어할 수 있는 플러그인을 뜻합니다. 요약하자면, 물리 환경의 네트워크를 기반으로 하여, Container Runtime에서 Container간의 네트워크를 사용하게 도와주는 인터페이스 입니다. 



<br>

## 3. On-prem 배포 실습

### 3.1 VM 생성

[Image vm2]

- 이름: master-1, worker-1, worker-2
- 리전: us-west1
- 영역: us-west1-b

[Image vm3]

- 부팅 디스크 설정

### 3.2 노드 접속

- SSH를 사용한 접속

### 3.3 네트워크 테스트

- ping을 통해 네트워크 테스트
- 내부 IP를 통해 테스트 수행
- 외부 IP는 방화벽으로 접근 불가

### 3.4 VM 환경 설정

### 3.5 배포 테스트

```
kubectl create deploy tc --image=consol/tomcat-7.0 --replicas=5
```

- 위와 동일

```
kubectl expose deploy tc --type=NodePort --port=80 --target-port=8080
```

- type을 NodePort로 지정
- LoadBalancer 기능은 없음

```
kubectl get pod,svc
```

- 포트 확인 후 각 노드들에 대해 접속







