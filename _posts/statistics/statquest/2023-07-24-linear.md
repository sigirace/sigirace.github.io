---
layout: single
title:  '모델 및 해석 기초'
toc: true
categories: [Machin Learning]
tags: [Model, R-square, p-value]
---

본 게시물은 머신러닝의 모델 및 해석의 기초에 대해 소개한다.
{: .notice}

## 1. Model

- 막대한 돈과 시간을 들여 데이터를 수집(=표본 조사)한다고 하여도 세상의 모든 데이터(=모집단)를 아는 것은 불가능
- 따라서 통계적 혹은 머신러닝 **모델**을 통해 알고 싶은 데이터의 근사값을 예측하는 방식이 필요함
  - 통계: 확률 분포를 이용한 근사, 확률분포의 parameter를 알아야함
  - 머신러닝: line fitting, 데이터로부터 예측 line을 만들고 이에 대한 식을 구한 뒤 알고 싶은 값을 대입해 근사치 얻음

## 2. SSR

> SSR(=sum of squared residual, 잔차 제곱 합)은 예측 모델(=선)이 얼마나 잘 예측을 하고 있는가에 대한 정량적 지표가 됨

### 2.1 Least sqaures(=fit a line to the data)

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/statquest/linearreg/lr4.png?raw=true" width="600" height="300"></p>

- 임의의 예측 선으로부터 실제 데이터간의 거리(=residual, 잔차)을 측정함
- 각 거리에 대해 제곱합을 구함

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/statquest/linearreg/lr5.png?raw=true" width="600" height="300"></p>

- 다양한 예측 선에 대해 잔차 제곱합을 구함
- x 축은 예측 선, y 축은 잔차 제곱 합

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/statquest/linearreg/lr7.png?raw=true" width="600" height="300"></p>

- 잔차 제곱합이 가장 낮은(=least squares) 선이 데이터로 부터 얻은 가장 적합한 예측 선
- y절편과 기울기 두가지 파라미터가 필요 (in simple linear regression)

### 2.2 MSE

- SSR은 모델의 예측 성능을 판단하기 위한 굿 아이디어이지만 데이터 수가 많아질수록 값이 커진다는 단점이 존재
  - 잔차 제곱 **합**이기 때문
- 따라서 평균을 통해 데이터가 많아지더라도 일정한 값을 가질 수 있게 하는 Mean Squared Error(평균제곱오차)를 통해 성능을 평가
- 그러나 MSE 또한 데이터의 스케일에 따라 값이 달라지는 문제가 존재 ex) 관측 단위가 M일 경우와 mm일 경우 동일한 데이터임에도 차이가 존재
  - 잔차제곱합이 (관측치-예측치)의 제곱이기 때문에 관측치와 예측치의 크기에 따라 값이 매우 크게 변동


## 3. R-sqaure

> 1. 예측 모델이 평균 예측에 비해 개선된 정도
> 2. 설명 변수로 설명할 수 있는 target(=반응변수)의 변동 비율

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/statquest/linearreg/lr9.png?raw=true" width="600" height="300"></p>

- target들의 평균에 대한 잔차 제곱합을 구함
- 잔차 제곱합의 평균(=MSE, SS(mean)/n)은 target의 변동이라고도 함

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/statquest/linearreg/lr10.png?raw=true" width="600" height="300"></p>

- 동일한 과정을 예측 모델(=line)에 대해서도 진행

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/statquest/linearreg/lr11.png?raw=true" width="600" height="300"></p>

- R-square는 모델이 단순한 평균을 통한 예측보다 얼마나 개선한지에 대한 비율

$$
R^2 = {SSR(mean) - SSR(model) \over SSR(mean)}
$$



### 3.1 Properties

- R-square가 0이면 모델의 예측이 평균과 동일 ☞ 동일하게 좋거나 나쁨
- R-sqaure가 1이면 모델의 예측이 데이터를 완벽히 피팅
- 데이터 셋이 작을 경우 우연히(=데이터가 좋은것들만 있어) R-sqaure가 높게 나올 수 있음
- 즉, 신뢰도가 떨어지는 경우가 존재 ☞ p-value 고려

### 3.2 More

- R-square는 일반적으로 평균과 예측 모델간의 비교를 하는 것이지만 잔차제곱을 할 수 있는 어떠한 모델간의 비교도 가능함

- 일반적으로 모델 성능을 비교할 때 R-square의 값은 0에서 1사이

- 그러나 테스트 데이터로 R-square를 구하면 음수가 나올 수 있음

  ☞ 당연한것.. 일단 학습데이터에 대해 나온 예측치를 평가하는 것이고, 테스트 데이터는 학습시 보지 못한 데이터이기 때문

## 4. P-value

> 1. 귀무가설이 참이라는 가정하에 관측된 통계값 혹은 그보다 큰 값이 나올 확률
> 2. 귀무가설이 참이라는 가정하에 얻은 통계량이 귀무가설을 얼마나 지지하는지 나타낸 확률
> 3. 귀무가설을 기각할 수 있는 근거
>
> ☞ p-value가 낮으면(0.05%) 해당 사건이 일어났다고 보기 어렵기에 귀무가설을 기각하고 대립가설을 채택

### 4.1 Hypothesis test

- 귀무가설($H_0$): 모집단의 특성에 대해 옳다고 제안하는 주장
- 대립가설($H_1$): 귀무가설이 기각되었을 때 채택하는 가설
- 검정통계량: 귀무가설이 참이라는 가정하에 얻은 통계량

📍 **Example**

<p align="center"><img src="https://github.com/sigirace/page-images/blob/main/statquest/linearreg/lr12.png?raw=true" width="600" height="300"></p>

1. 알 수 없는 모집단의 평균(=모평균) $\mu$를 추정하고자 함
2. 이를 위해 알 수 있는 표본들의 평균 $\bar{x}$을 사용함
3. 귀무가설(=주장하는 값)을 세움
4. 검정통계량을 구함 (주어진 문제에 따라 다르며 해당 예제에서는 t-value)
5. 통계표에서 확인하여 검정통계량 보다 클 확률, 영역, p-value를 통해 귀무가설의 기각, 채택 결정

📍 **모평균 추정의 검정 통계량**

- 표본크기가 큰 경우: 표준정규분포 (by 중심극한정리)
- 표본 크기가 작거나 모집단의 분포가 정규분포를 따르지 않는 경우: t-분포

### 4.2 More

- 1종오류: 귀무가설이 참인데 p-value가 낮아 기각한 경우 (거짓 양성)
- 2종오류: 귀무가설이 거짓인데 p-value가 높아 채택한 경우 (거짓 음성)
- p-value는 다름(?)의 크기 차이를 나타내진 않음 ☞ 표현이 맞는지 모르겠네..

### 4.3 P-value of R-square (in linear regression)

- 선형회귀에서 $R^2$의 p-value는 어떤 랜덤(=동일 성질) 데이터에서도 동일하거나 더 높은 $R^2$을 얻을 확률
- 주어진 데이터로 다양한 sample들을 만들어 $R^2$ 구함
- 얻은 $R^2$들의 값을 histogram으로 그리고, 처음 가정한 $R^2$보다 동일하거나 클 확률을 구함
- 단, 이는 빠르게 계산하기 위한 방법으로 전통적인 계산 방식은 아님
