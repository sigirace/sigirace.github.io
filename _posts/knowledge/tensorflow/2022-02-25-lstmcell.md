---
layout: single
title:  'LSTMCell'
toc: true
categories: [TensorFlow]
tags: [tensorflow, timeseries]

---

본 게시물은 tensorflow의 [포스트](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTMCell)를 보고 정리하는 글이다.
{: .notice}

```python
tf.keras.layers.LSTMCell(
    units,
    activation='tanh',
    recurrent_activation='sigmoid',
    use_bias=True,
    kernel_initializer='glorot_uniform',
    recurrent_initializer='orthogonal',
    bias_initializer='zeros',
    unit_forget_bias=True,
    kernel_regularizer=None,
    recurrent_regularizer=None,
    bias_regularizer=None,
    kernel_constraint=None,
    recurrent_constraint=None,
    bias_constraint=None,
    dropout=0.0,
    recurrent_dropout=0.0,
    **kwargs
)
```

### 📌 LSTM vs LSTMCell

- LSTM: recurrent layer로 전체 sequence를 처리 할 수 있음.
- LSTMCell: 전체 sequence 중 한 단계만을 처리하는 object

recurrent layer에는 cell 객체들이 포함되어 있으며, cell에는 각 단계의 계산을 위한 코드가 포함되어 있다. 즉, recurrent layer는 각 cell에게 계산을 위한 명령을 내리고 cell은 이를 수행한다. LSTMCell은 RNN layer의 cell 부분으로 입력되어 LSTM과 동일한 기능을 수행할 수 있다. LSTM 또한 내부 코드는 RNN에 LSTMCell을 포함한 것이다.

### 📌 Args

- units: output의 demension
- activation: cell state 연산시 사용되는 activation function으로 default는 tanh이다. None일 경우 activation이 적용되지 않는다.
- recurrent_activation: input/ forget/ output gate 연산시 사용되는 activation function으로 default는 sigmoid이다. None일 경우 activation이 적용되지 않는다.
- use_bias: layer가 bias를 사용하는지에 대한 여부로 default는 True이다.
- kernel_initializer: input의 선형변환에 사용되는 kernel weight matrix의 initializer이다. (input이 cell 연산되기 전 kernel weight와 연산됨)
- recurrent_initializer: hidden state의 선형변환에 사용되는 recurrent kernel weight matrix의 initializer이다. (hidden state들이 연산되기 전 recurrent kernel weight와 연산됨)
- bias_initializer: bias의 initializer이다.
- unit_forget_bias: forget gate의 bias에 1을 더하며, default 값은 True이다. True시 bias_initializer 또한 True로 세팅된다. (추천)
- kernel_regularizer: kernel weight matrix에 정규화를 적용하며, default는 None이다.
- recurrent_regularizer: recurrent kernel weight matrix에 정규화를 적용하며, default는 None이다.
- bias_regularizer: bias에 정규화를 적용하며, default는 None이다.
- kernel_constraint: kernel weight matrix에 적용하는 제약식이며, default는 None이다.
- recurrent_constraint: recurrent kernel weight matrix에 적용하는 제약식이며, default는 None이다.
- bias_constraint: bias에 적용하는 제약식이며, default는 None이다.
- dropout: input에 적용하는 dropout이며, default는 0이다.
- recurrent_dropout: hidden state에 적용하는 dropout이며, default는 0이다.

### 📌 Example

````python
inputs = tf.random.normal([32, 10, 8])
rnn = tf.keras.layers.RNN(tf.keras.layers.LSTMCell(4))
output = rnn(inputs)
print(output.shape)
````

````
(32, 4)
````

````python
rnn = tf.keras.layers.RNN(
   tf.keras.layers.LSTMCell(4),
   return_sequences=True,
   return_state=True)
whole_seq_output, final_memory_state, final_carry_state = rnn(inputs)
print(whole_seq_output.shape)
print(final_memory_state.shape)
print(final_carry_state.shape)
````

````
(32, 10, 4)
(32, 4)
(32, 4)
````
