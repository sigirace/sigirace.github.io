---
layout: single
title:  'Llama 3.1 í•œêµ­ì–´ Finetuning'
toc: true
categories: [Large Language Model]
tags: [Llama, Fine-Tuning]

---

ì´ë²ˆ í¬ìŠ¤íŠ¸ë¥¼ í†µí•´ unsloth ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ llama 3.1 ëª¨ë¸ finetuningì„ ì‹¤ìŠµí•œë‹¤.
{: .notice}

## ğŸ“Œ ë“¤ì–´ê°€ê¸° ì „ì—..

ğŸ‘€ **Unsloth**

> **Unsloth**ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ íš¨ìœ¨ì ìœ¼ë¡œ ë¯¸ì„¸ ì¡°ì •(fine-tuning)í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ëœ Python ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” íŠ¹íˆ **Llama, Mistral, Phi, Gemma**ì™€ ê°™ì€ ëª¨ë¸ë“¤ì„ ë‹¤ë£¨ë©°, **PEFT**ì„ í†µí•´ **ìµœëŒ€ 5ë°°** ë¹ ë¥´ê²Œ í•™ìŠµì„ ì§„í–‰í•  ìˆ˜ ìˆê³ , ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ë„ **ìµœëŒ€ 80%**ê¹Œì§€ ì ˆê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

**â¤ï¸â€ğŸ”¥ PEFT â¤ï¸â€ğŸ”¥**

- [ì´ì „ í¬ìŠ¤íŠ¸ ê¸€ í™•ì¸](https://sigirace.github.io/large%20language%20model/LLM%EC%9D%98-%ED%99%9C%EC%9A%A9%EB%B0%A9%EB%B2%95/#25-%EF%B8%8F-peft-%EF%B8%8F)

ğŸ“œ **Github**

- [unsloth finetuning tutorial](https://github.com/unslothai/unsloth?tab=readme-ov-file)

ğŸŒˆ **Environment**

- **ëª¨ë¸**: Llama3.1 8B
- **ì‹¤ìŠµí™˜ê²½**: GPU - T4 (colab, kaggle)

## 1. Install

```python
%%capture
# Installs Unsloth, Xformers (Flash Attention) and all other packages!
!pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"
!pip install --no-deps "xformers<0.0.27" "trl<0.9.0" peft accelerate bitsandbytes
```

- **xformers**: PyTorchì—ì„œ Transformer ê¸°ë°˜ ëª¨ë¸ì˜ í•™ìŠµê³¼ ì¶”ë¡  ì„±ëŠ¥ì„ ìµœì í™”
- **trl(transformers reinforcement learning)**: ê°•í™” í•™ìŠµì„ Transformers ëª¨ë¸ê³¼ í†µí•©í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬, ì–¸ì–´ ëª¨ë¸ì„ ê°•í™” í•™ìŠµìœ¼ë¡œ í›ˆë ¨í•˜ê±°ë‚˜ ì¡°ì •í•˜ëŠ”ë° ìœ ìš©í•¨
- **peft(parameter efficient fine-tuning)**: ì–¸ì–´ ëª¨ë¸ì˜ ì¼ë¶€ íŒŒë¼ë¯¸í„°ë§Œ ë¯¸ì„¸ ì¡°ì •í•¨ìœ¼ë¡œì¨, ë” íš¨ìœ¨ì ìœ¼ë¡œ ëª¨ë¸ì„ íŠœë‹í•  ìˆ˜ ìˆê²Œ í•´ì¤Œ
- **accelerate**: Hugging Faceì—ì„œ ì œê³µí•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, PyTorch ëª¨ë¸ì„ ì—¬ëŸ¬ GPUì™€ TPUì—ì„œ ì†ì‰½ê²Œ ë³‘ë ¬ ì²˜ë¦¬í•  ìˆ˜ ìˆê²Œ í•¨
- **bitsandbytes**: 8bit ìˆ˜í•™ ì—°ì‚°ì„ ì§€ì›í•˜ì—¬, ëŒ€í˜• ëª¨ë¸ì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ì„ ì¤„ì´ê³  ì†ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ì£¼ë¡œ ë©”ëª¨ë¦¬ ì œì•½ì´ ìˆëŠ” í™˜ê²½ì—ì„œ ì‚¬ìš©í•¨

âœï¸  **bitë¥¼ ì¤„ì´ëŠ” ê²ƒì´ ì™œ í•„ìš”í• ê¹Œ?**

- ì»´í“¨í„°ì—ì„œ ë°ì´í„°ëŠ” ë¹„íŠ¸ ë‹¨ìœ„ë¡œ ì €ì¥ë˜ë©°, AI/ML ì˜ì—­ì˜ ëŒ€í‘œì ì¸ ë°ì´í„°ì¸ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ëŠ” 32 bit ë¶€ë™ì†Œìˆ˜ì ìœ¼ë¡œ í‘œí˜„
- ì´ë¥¼ 8bit ì •ìˆ˜ë¡œ í‘œí˜„í•˜ë©´, ë°ì´í„°ì˜ í¬ê¸°ê°€ 4ë¶„ì˜ 1ë¡œ ì¤„ì–´ë“¤ë©° ì´ëŠ” parameterê°€ ìˆ˜ë°±ë§Œì—ì„œ ìˆ˜ì‹­ì–µ ê°œ ì¡´ì¬í•  ê²½ìš° ë§¤ìš° íš¨ê³¼ì 
- ì €ì¥í•˜ëŠ” bitë¥¼ ì¤„ì´ëŠ” ê³¼ì •ì„ ì–‘ìí™”ë¼ê³  í•˜ë©°, ì´ë¡œì¸í•´ ëª¨ë¸ í¬ê¸°ê°€ ì‘ì•„ì ¸ ì‘ì€ ê·œëª¨ì˜ ì¸í”„ë¼ í™˜ê²½(*ë©”ëª¨ë¦¬*)ì—ì„œë„ ë™ì‘í•  ìˆ˜ ìˆê²Œ ë¨
- ë‹¨, ì—°ì‚°ì˜ ì •ë°€ë„ê°€ ë–¨ì–´ì ¸ ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆìœ¼ë©°, êµ¬í˜„ì´ ë³µì¡í•œ ë‹¨ì ì´ ìˆìŒ





```html
<div>
hello
<div>
	<div><!-- ì ìƒ‰ ë²„íŠ¼ --></div>
	<div><!-- í™©ìƒ‰ ë²„íŠ¼ --></div>
	<div><!-- ë…¹ìƒ‰ ë²„íŠ¼ --></div>
</div>

<pre>
print("hi")
</pre>
</div>
```



## ì˜ˆì œ ì½”ë“œ

```html
<!-- HTML ì½”ë“œ ë¸”ëŸ­ -->
<div class="code-container">
    <pre id="code-block">
        <code>
def hello_world():
    print("Hello, world!")
        </code>
    </pre>
    <button class="copy-button" onclick="copyToClipboard()">Copy</button>
</div>

<script>
function copyToClipboard() {
    var code = document.getElementById("code-block").innerText;
    navigator.clipboard.writeText(code).then(function() {
        alert("Copied to clipboard!");
    }, function(err) {
        alert("Failed to copy text: ", err);
    });
}
</script>
```

